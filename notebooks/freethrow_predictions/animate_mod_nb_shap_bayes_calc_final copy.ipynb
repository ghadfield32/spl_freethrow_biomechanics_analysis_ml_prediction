{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Directory Structure (notebooks for testing and src once build complete)\n",
    "\n",
    "\n",
    "By grouping:\n",
    "\n",
    "    Viewpoint and court functions into their own modules,\n",
    "    Plot initialization and element creation into a common module,\n",
    "    Animation update logic into one (or two) modules (with a “base” update for common elements and extensions for shot meter/feedback),\n",
    "    Shot meter feature engineering in its own module,\n",
    "    Bayesian and SHAP processing in another module, and\n",
    "    Feedback (angle meter and related visualizations) in a separate module,\n",
    "\n",
    "you create a clean, maintainable, and “pythonic” codebase. Adjustments in one area (say, updating the gauge) will only require you to change the functions in the feedback module without affecting the court drawing or the basic animation.\n",
    "\n",
    "After each change, you would run your tests (for example in your notebooks) to validate that the entire system continues to work smoothly.\n",
    "\n",
    "\n",
    "project/\n",
    "│\n",
    "├── notebooks/\n",
    "│    ├── free_throw_predictions/\n",
    "│        ├── animate_mod_nb.ipynb (we're here testing, will change the writefiles to ../src/freethrow_predictions/animate to get to being able to use with streamlit and such)\n",
    "│    │    └── animate/\n",
    "│    │        ├── __init__.py\n",
    "│    │        ├── viewpoints.py\n",
    "│    │        ├── court.py\n",
    "│    │        ├── elements.py\n",
    "│    │        ├── animation.py\n",
    "│    │        ├── angle_meter.py\n",
    "│    │        ├── animate_from_df.py\n",
    "│    │        ├── animate_from_df_with_shot_meters.py\n",
    "│    │        ├── bayes_angle_meter.py\n",
    "│    │        └── ...\n",
    "│\n",
    "├── src/\n",
    "|    ├── free_throw_predictions/\n",
    "│    │    └── animate/\n",
    "│    │        ├── __init__.py\n",
    "│    │        ├── viewpoints.py\n",
    "│    │        ├── court.py\n",
    "│    │        ├── elements.py\n",
    "│    │        ├── animation.py\n",
    "│    │        ├── angle_meter.py\n",
    "│    │        ├── animate_from_df.py\n",
    "│    │        ├── animate_from_df_with_shot_meters.py\n",
    "│    │        ├── bayes_angle_meter.py\n",
    "│    │        └── ...\n",
    "│\n",
    "├── data/\n",
    "│    └── processed/\n",
    "│         └── final_granular_dataset.csv\n",
    "└── ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a step‐by‐step plan to reorganize and refactor your repository so that it becomes efficient, automated, and cohesive. The idea is to group related functionality into modules, keep tests and development notebooks separate from the production code (in **src**), and ensure that each component is well‐documented and isolated so that changes in one area do not affect the rest of the codebase.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 1. Define a Clean Directory Structure**\n",
    "\n",
    "**Goal:** Separate development/testing notebooks from the production code that will eventually be imported (for example, by a Streamlit app).\n",
    "\n",
    "**Plan:**\n",
    "\n",
    "1. **Create Two Top-Level Directories:**\n",
    "   - **notebooks/** – For interactive testing and exploratory analysis.\n",
    "   - **src/** – For production-ready code.\n",
    "\n",
    "2. **Within the `src/` Directory:**\n",
    "   - Create a package named **free_throw_predictions**.\n",
    "   - Under that, create a subpackage called **animate**.\n",
    "\n",
    "3. **Proposed Structure:**\n",
    "\n",
    "   ```\n",
    "   project/\n",
    "   │\n",
    "   ├── notebooks/\n",
    "   │    └── free_throw_predictions/\n",
    "   │         └── animate_mod_nb.ipynb     # Your interactive testing notebook\n",
    "   │\n",
    "   ├── src/\n",
    "   │    └── free_throw_predictions/\n",
    "   │         └── animate/\n",
    "   │              ├── __init__.py        # Marks 'animate' as a package\n",
    "   │              ├── viewpoints.py      # Functions for retrieving camera viewpoints\n",
    "   │              ├── court.py           # Functions for court drawing and hoop position\n",
    "   │              ├── elements.py        # Plot initialization and element creation\n",
    "   │              ├── animation.py       # Core animation update logic\n",
    "   │              ├── angle_meter.py     # Functions for creating/updating angle meters\n",
    "   │              ├── shot_meter.py      # Shot meter feature engineering functions\n",
    "   │              ├── bayesian.py        # Bayesian and SHAP processing functions\n",
    "   │              └── feedback.py        # Feedback and gauge visualization functions\n",
    "   │\n",
    "   ├── data/\n",
    "   │    └── processed/\n",
    "   │         └── final_granular_dataset.csv\n",
    "   └── ...\n",
    "   ```\n",
    "\n",
    "*Note:* You can later add more modules (or even subpackages) as needed—for example, if you decide to separate testing utilities or configuration files.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 2. Group Functions by Their Purpose**\n",
    "\n",
    "**Goal:** Make each module responsible for one area of functionality. This minimizes cross-dependencies and makes testing easier.\n",
    "\n",
    "### **2.1. Viewpoint and Court Functions**\n",
    "\n",
    "- **`viewpoints.py`**  \n",
    "  *Contains:*  \n",
    "  - `get_viewpoint(name: str) -> dict`  \n",
    "  *Purpose:* Return preset camera settings (elevation and azimuth).\n",
    "\n",
    "- **`court.py`**  \n",
    "  *Contains:*  \n",
    "  - `get_hoop_position(...)`  \n",
    "  - `draw_court(...)`  \n",
    "  *Purpose:* Compute court parameters and render the court (and hoop).\n",
    "\n",
    "### **2.2. Plot Initialization and Element Creation**\n",
    "\n",
    "- **`elements.py`**  \n",
    "  *Contains:*  \n",
    "  - `initialize_plot(...)`  \n",
    "  - `initialize_elements(...)`  \n",
    "  *Purpose:* Set up a Matplotlib 3D plot, create the ball, lines for the player skeleton, and text annotations.\n",
    "\n",
    "### **2.3. Animation Update Logic**\n",
    "\n",
    "- **`animation.py`**  \n",
    "  *Contains:*  \n",
    "  - Core update functions such as a “base” update (e.g. `update_player_frame(...)`) and an extended update (e.g. `update_full_frame(...)` that calls the base update plus the shot meter/feedback updates).  \n",
    "  *Purpose:* Centralize all logic that updates the animation frame by frame.\n",
    "\n",
    "### **2.4. Shot Meter Feature Engineering**\n",
    "\n",
    "- **`shot_meter.py`**  \n",
    "  *Contains:*  \n",
    "  - Functions like `calculate_release_angles(...)`, `calculate_optimal_release_angle_ranges(...)`, and `calculate_optimal_max_angle_ranges(...)`  \n",
    "  *Purpose:* Process the raw data and add columns that compute release angles, optimal ranges, and shot classifications.\n",
    "\n",
    "### **2.5. Bayesian and SHAP Processing**\n",
    "\n",
    "- **`bayesian.py`**  \n",
    "  *Contains:*  \n",
    "  - Functions to load precalculated Bayesian metrics, add Bayesian ranges to the dataset, classify metrics, and merge them with granular shot data.  \n",
    "  *Purpose:* Encapsulate all logic related to Bayesian optimization and SHAP integration.\n",
    "\n",
    "### **2.6. Feedback and Angle Meter Visualizations**\n",
    "\n",
    "- **`feedback.py`**  \n",
    "  *Contains:*  \n",
    "  - Functions like `initialize_angle_meters(...)`, `update_angle_meter(...)`, `initialize_bar_meter(...)`, `initialize_line_graph(...)`, and helpers such as `generate_feedback_table_all_metrics(...)` and `display_combined_output(...)`.  \n",
    "  *Purpose:* Provide the feedback visualization components (e.g. updating gauges with calculated, bayesian, or SHAP information).\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 3. Refactor and Move Code into Modules**\n",
    "\n",
    "**Goal:** Incrementally move code into the new modules and update import statements accordingly.\n",
    "\n",
    "### **3.1. Create and Populate Modules**\n",
    "\n",
    "1. **`viewpoints.py` & `court.py`:**  \n",
    "   - Move the current content of your notebook cells (or files) for `get_viewpoint`, `get_hoop_position`, and `draw_court` into these modules.\n",
    "   - Verify that these functions import only what they need (e.g. `import numpy as np` and `import matplotlib.pyplot as plt`).\n",
    "\n",
    "2. **`elements.py`:**  \n",
    "   - Move the initialization functions for plots and elements.\n",
    "   - Ensure that functions like `initialize_plot(...)` and `initialize_elements(...)` have clear docstrings.\n",
    "\n",
    "3. **`animation.py`:**  \n",
    "   - Extract the common frame update logic (e.g. updating the ball, skeleton lines, and text) into a helper function such as `update_player_frame(...)`.\n",
    "   - Create a second function (e.g. `update_full_frame(...)`) that calls the common update and then updates any shot meter or feedback-related components.\n",
    "   - Update your notebook(s) to import these functions from `src/free_throw_predictions/animate/animation.py`.\n",
    "\n",
    "4. **`shot_meter.py`:**  \n",
    "   - Place all functions for shot meter feature engineering here.\n",
    "   - Include docstrings explaining the purpose of each function and any default parameters (e.g. percentiles).\n",
    "\n",
    "5. **`bayesian.py`:**  \n",
    "   - Move your bayesian metrics loading, merging, and classification functions here.\n",
    "   - For example, functions like `load_precalculated_bayesian_metrics(...)`, `add_bayesian_ranges_to_ml_dataset(...)`, `classify_metrics(...)`, and `merge_bayes_metrics_with_granular_data(...)`.\n",
    "\n",
    "6. **`feedback.py`:**  \n",
    "   - Place functions that handle the feedback display for the angle meter (e.g. `update_angle_meter(...)`, `initialize_bar_meter(...)`, `initialize_line_graph(...)`, `generate_feedback_table_all_metrics(...)`, etc.).\n",
    "   - These functions should be isolated so that if you need to change the feedback logic (for example, updating the gauge), you only modify this module.\n",
    "\n",
    "### **3.2. Update Import Statements**\n",
    "\n",
    "- As you move functions, update any import statements in your notebooks and in other modules to point to the new module paths.  \n",
    "  For example, in your notebook, you might now import:\n",
    "\n",
    "  ```python\n",
    "  from free_throw_predictions.animate.viewpoints import get_viewpoint\n",
    "  from free_throw_predictions.animate.court import draw_court, get_hoop_position\n",
    "  from free_throw_predictions.animate.elements import initialize_plot, initialize_elements\n",
    "  from free_throw_predictions.animate.animation import update_full_frame, update_player_frame\n",
    "  from free_throw_predictions.animate.shot_meter import calculate_release_angles, calculate_optimal_release_angle_ranges\n",
    "  from free_throw_predictions.animate.bayesian import load_precalculated_bayesian_metrics, add_bayesian_ranges_to_ml_dataset\n",
    "  from free_throw_predictions.animate.feedback import update_angle_meter, initialize_bar_meter, generate_feedback_table_all_metrics\n",
    "  ```\n",
    "\n",
    "- Test these changes using your interactive notebooks to ensure nothing is broken.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 4. Automate Testing and Build Processes**\n",
    "\n",
    "**Goal:** Ensure that after each refactor step, you can automatically run tests to validate the changes.\n",
    "\n",
    "### **4.1. Write Unit Tests**\n",
    "\n",
    "- Create a **tests/** folder at the project root (or under a dedicated testing folder) and add test modules (e.g. `test_viewpoints.py`, `test_court.py`, etc.) that import functions from your **src/** folder.\n",
    "- Use a testing framework (like `pytest`) to write tests that verify:\n",
    "  - Correct values are returned by `get_viewpoint()`.\n",
    "  - `draw_court()` and `get_hoop_position()` work without error.\n",
    "  - Plot initialization functions create figures with expected properties.\n",
    "  - Update functions correctly update Matplotlib objects when provided sample data.\n",
    "\n",
    "### **4.2. Continuous Integration (Optional but Recommended)**\n",
    "\n",
    "- Set up a CI pipeline (using GitHub Actions, Travis CI, etc.) that runs your tests on every commit. This ensures that your refactoring does not break existing functionality.\n",
    "\n",
    "### **4.3. Automation Scripts**\n",
    "\n",
    "- If needed, write automation scripts (e.g. a setup script) that package your **src/** folder so that it can be installed (for example, with `pip install -e .`).  \n",
    "- Create a `setup.py` or `pyproject.toml` file so that your package is installable and its dependencies are managed.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 5. Validate the Entire System**\n",
    "\n",
    "**Goal:** Make sure that after each module refactoring, you run the notebooks to verify that:\n",
    "- The animations still work as expected.\n",
    "- The court and viewpoint functions render correctly.\n",
    "- The shot meter feature engineering correctly adds new columns to your dataset.\n",
    "- The Bayesian and SHAP integrations are working and feedback displays are updated accordingly.\n",
    "\n",
    "*Tip:* Use your interactive notebook (e.g. `animate_mod_nb.ipynb`) to run end-to-end tests, and document any differences or adjustments needed.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 6. Summary of Steps to Replace Functions**\n",
    "\n",
    "When everything is working as expected, the following files in your **src/free_throw_predictions/animate/** folder will replace your old notebook writefiles:\n",
    "\n",
    "- **`viewpoints.py`** – Contains `get_viewpoint`\n",
    "- **`court.py`** – Contains `get_hoop_position` and `draw_court`\n",
    "- **`elements.py`** – Contains `initialize_plot` and `initialize_elements`\n",
    "- **`animation.py`** – Contains `update_player_frame` and `update_full_frame` (the animation update logic)\n",
    "- **`shot_meter.py`** – Contains all shot meter feature engineering functions\n",
    "- **`bayesian.py`** – Contains all Bayesian and SHAP processing functions\n",
    "- **`feedback.py`** – Contains all feedback and angle meter visualization functions\n",
    "\n",
    "After verifying each module with your tests and interactive notebooks, your production code will reside in **src/** while your testing and debugging remain in **notebooks/**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Final Thoughts**\n",
    "\n",
    "This modular approach gives you a cohesive, automated, and maintainable codebase. Each area of functionality is isolated; for example, changes in the angle meter feedback will only affect **feedback.py**. Automated tests (using `pytest` or a similar framework) and CI pipelines will ensure that the refactoring does not break functionality.\n",
    "\n",
    "By following these steps and organizing your repository as shown, you achieve an efficient, modular, and pythonic codebase ready for further integration (e.g. into a Streamlit app) or extension.\n",
    "\n",
    "Feel free to ask for more details on any particular module or step if needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "'widget' is not a recognised GUI loop or backend name",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/workspace/.venv/lib/python3.10/site-packages/matplotlib/backends/registry.py:407\u001b[0m, in \u001b[0;36mBackendRegistry.resolve_gui_or_backend\u001b[0;34m(self, gui_or_backend)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgui_or_backend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# KeyError ?\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/.venv/lib/python3.10/site-packages/matplotlib/backends/registry.py:369\u001b[0m, in \u001b[0;36mBackendRegistry.resolve_backend\u001b[0;34m(self, backend)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gui \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 369\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not a recognised backend name\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m backend, gui \u001b[38;5;28;01mif\u001b[39;00m gui \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheadless\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 'widget' is not a recognised backend name",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Prime example of adjustable views in 3D basketball court\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmatplotlib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwidget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2482\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2480\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2481\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2482\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2484\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2485\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2486\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/workspace/.venv/lib/python3.10/site-packages/IPython/core/magics/pylab.py:103\u001b[0m, in \u001b[0;36mPylabMagics.matplotlib\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable matplotlib backends: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;241m%\u001b[39m _list_matplotlib_backends_and_gui_loops()\n\u001b[1;32m    101\u001b[0m     )\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 103\u001b[0m     gui, backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_matplotlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_show_matplotlib_backend(args\u001b[38;5;241m.\u001b[39mgui, backend)\n",
      "File \u001b[0;32m/workspace/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3667\u001b[0m, in \u001b[0;36mInteractiveShell.enable_matplotlib\u001b[0;34m(self, gui)\u001b[0m\n\u001b[1;32m   3664\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib_inline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_inline\u001b[39;00m\n\u001b[1;32m   3666\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pylabtools \u001b[38;5;28;01mas\u001b[39;00m pt\n\u001b[0;32m-> 3667\u001b[0m gui, backend \u001b[38;5;241m=\u001b[39m \u001b[43mpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_gui_and_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgui\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpylab_gui_select\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gui \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3670\u001b[0m     \u001b[38;5;66;03m# If we have our first gui selection, store it\u001b[39;00m\n\u001b[1;32m   3671\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpylab_gui_select \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/workspace/.venv/lib/python3.10/site-packages/IPython/core/pylabtools.py:349\u001b[0m, in \u001b[0;36mfind_gui_and_backend\u001b[0;34m(gui, gui_select)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     gui \u001b[38;5;241m=\u001b[39m _convert_gui_to_matplotlib(gui)\n\u001b[0;32m--> 349\u001b[0m     backend, gui \u001b[38;5;241m=\u001b[39m \u001b[43mbackend_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve_gui_or_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgui\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m gui \u001b[38;5;241m=\u001b[39m _convert_gui_from_matplotlib(gui)\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gui, backend\n",
      "File \u001b[0;32m/workspace/.venv/lib/python3.10/site-packages/matplotlib/backends/registry.py:409\u001b[0m, in \u001b[0;36mBackendRegistry.resolve_gui_or_backend\u001b[0;34m(self, gui_or_backend)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_backend(gui_or_backend)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# KeyError ?\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgui_or_backend\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not a recognised GUI loop or backend name\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 'widget' is not a recognised GUI loop or backend name"
     ]
    }
   ],
   "source": [
    "# Prime example of adjustable views in 3D basketball court\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mplbasketball.court3d import draw_court_3d\n",
    "from mplbasketball.utils import transform\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib\n",
    "\n",
    "###############################################################################\n",
    "# 1) Create the 3D Court Figure Setup\n",
    "###############################################################################\n",
    "def create_3d_court_figure(\n",
    "    elev=30,\n",
    "    azim=45,\n",
    "    xlim=(-50, 50),\n",
    "    ylim=(-30, 30),\n",
    "    zlim=(0, 20)\n",
    "):\n",
    "    \"\"\"\n",
    "    Helper function to create a figure and 3D axes,\n",
    "    draw the basketball court, and set initial view/limits.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    elev : float\n",
    "        Initial elevation angle for the camera.\n",
    "    azim : float\n",
    "        Initial azimuth angle for the camera.\n",
    "    xlim, ylim, zlim : tuple\n",
    "        Axis limits in the 3D space.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    fig : matplotlib.figure.Figure\n",
    "        The created figure object.\n",
    "    ax : matplotlib.axes._subplots.Axes3DSubplot\n",
    "        The 3D axes on which the court is drawn.\n",
    "    \"\"\"\n",
    "    # Create the figure and 3D subplot\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Draw the 3D court\n",
    "    draw_court_3d(ax, origin=np.array([0.0, 0.0]), line_width=2)\n",
    "    \n",
    "    # Enforce fixed axis limits\n",
    "    ax.set_xlim(*xlim)\n",
    "    ax.set_ylim(*ylim)\n",
    "    ax.set_zlim(*zlim)\n",
    "    \n",
    "    # Set initial camera angles (these do not involve ax.dist)\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "    \n",
    "    print(\"Current backend:\", matplotlib.get_backend())\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 2) Rotation Only (No ax.dist zoom!)\n",
    "###############################################################################\n",
    "# We'll track the elevation/azimuth globally so button presses can modify them.\n",
    "camera_elev = 30\n",
    "camera_azim = 45\n",
    "\n",
    "def rotate_view(ax, elev_change=0, azim_change=0):\n",
    "    \"\"\"\n",
    "    Rotates/tilts the view by adjusting camera_elev and camera_azim.\n",
    "    This does NOT modify ax.dist at all.\n",
    "    \"\"\"\n",
    "    global camera_elev, camera_azim\n",
    "    \n",
    "    camera_elev += elev_change\n",
    "    camera_azim += azim_change\n",
    "    \n",
    "    ax.view_init(elev=camera_elev, azim=camera_azim)\n",
    "    ax.figure.canvas.draw_idle()\n",
    "    \n",
    "    \n",
    "###############################################################################\n",
    "# 3) Data-Limits Zoom (works in ipympl)\n",
    "###############################################################################\n",
    "def data_zoom(ax, zoom_factor=1.0):\n",
    "    \"\"\"\n",
    "    A 'zoom' that rescales x, y, and z limits around the center of the scene.\n",
    "    ipympl reliably honors this, so it's an effective solution in notebooks.\n",
    "    \"\"\"\n",
    "    x0, x1 = ax.get_xlim3d()\n",
    "    y0, y1 = ax.get_ylim3d()\n",
    "    z0, z1 = ax.get_zlim3d()\n",
    "    \n",
    "    x_center = (x0 + x1) / 2\n",
    "    y_center = (y0 + y1) / 2\n",
    "    z_center = (z0 + z1) / 2\n",
    "    \n",
    "    x_half_range = (x1 - x0)/2\n",
    "    y_half_range = (y1 - y0)/2\n",
    "    z_half_range = (z1 - z0)/2\n",
    "    \n",
    "    # We divide the half-range by zoom_factor to get a \"zoom in\" effect\n",
    "    new_x_half = x_half_range / zoom_factor\n",
    "    new_y_half = y_half_range / zoom_factor\n",
    "    new_z_half = z_half_range / zoom_factor\n",
    "    \n",
    "    ax.set_xlim3d([x_center - new_x_half, x_center + new_x_half])\n",
    "    ax.set_ylim3d([y_center - new_y_half, y_center + new_y_half])\n",
    "    ax.set_zlim3d([z_center - new_z_half, z_center + new_z_half])\n",
    "    \n",
    "    print(f\"[data_zoom] factor={zoom_factor}, new x-lim={ax.get_xlim3d()}\")\n",
    "    ax.figure.canvas.draw_idle()\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 4) Create Widgets for Rotation and Data Zoom\n",
    "###############################################################################\n",
    "def create_widgets(ax):\n",
    "    \"\"\"\n",
    "    Creates and returns the interactive widgets for:\n",
    "      - Rotating left/right\n",
    "      - Tilting up/down\n",
    "      - Data Zoom In/Out\n",
    "    \n",
    "    The returned widgets can be displayed together or separately.\n",
    "    \"\"\"\n",
    "    # --- Rotation/Tilt Buttons ---\n",
    "    btn_left  = widgets.Button(description='Rotate Left')\n",
    "    btn_right = widgets.Button(description='Rotate Right')\n",
    "    btn_up    = widgets.Button(description='Tilt Up')\n",
    "    btn_down  = widgets.Button(description='Tilt Down')\n",
    "    \n",
    "    # Bind callbacks\n",
    "    def on_rotate_left(b):\n",
    "        rotate_view(ax, azim_change=-5)\n",
    "    def on_rotate_right(b):\n",
    "        rotate_view(ax, azim_change=5)\n",
    "    def on_tilt_up(b):\n",
    "        rotate_view(ax, elev_change=5)\n",
    "    def on_tilt_down(b):\n",
    "        rotate_view(ax, elev_change=-5)\n",
    "    \n",
    "    btn_left.on_click(on_rotate_left)\n",
    "    btn_right.on_click(on_rotate_right)\n",
    "    btn_up.on_click(on_tilt_up)\n",
    "    btn_down.on_click(on_tilt_down)\n",
    "    \n",
    "    # --- Data Zoom Buttons ---\n",
    "    btn_alt_zoom_in  = widgets.Button(description='Data Zoom In')\n",
    "    btn_alt_zoom_out = widgets.Button(description='Data Zoom Out')\n",
    "    \n",
    "    def on_alt_zoom_in(b):\n",
    "        data_zoom(ax, zoom_factor=1.3)  # zoom in\n",
    "    def on_alt_zoom_out(b):\n",
    "        data_zoom(ax, zoom_factor=0.7)  # zoom out\n",
    "    \n",
    "    btn_alt_zoom_in.on_click(on_alt_zoom_in)\n",
    "    btn_alt_zoom_out.on_click(on_alt_zoom_out)\n",
    "    \n",
    "    # Pack them into horizontal boxes\n",
    "    row1 = widgets.HBox([btn_left, btn_right, btn_up, btn_down])\n",
    "    row2 = widgets.HBox([btn_alt_zoom_in, btn_alt_zoom_out])\n",
    "    \n",
    "    return row1, row2\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 5) Putting it all together in a single cell\n",
    "###############################################################################\n",
    "\n",
    "# A. Create the 3D court and retrieve the figure and axes\n",
    "fig, ax = create_3d_court_figure(elev=camera_elev, azim=camera_azim)\n",
    "\n",
    "# B. Add some sample data (unchanged from your original code)\n",
    "x = np.linspace(-40, 40, 100)\n",
    "y = np.linspace(-20, 20, 100)\n",
    "z = np.abs(np.sin(x * np.pi / 80) * 5)\n",
    "ax.plot(x, y, z, 'r-', lw=2, label='Player Trajectory')\n",
    "\n",
    "x_data = np.random.uniform(-40, 40, 50)\n",
    "y_data = np.random.uniform(-20, 20, 50)\n",
    "z_data = np.random.uniform(0, 20, 50)\n",
    "x_hl, y_hl = transform(x_data, y_data, fr=\"h\", to=\"hl\", origin=\"center\")\n",
    "ax.scatter(x_hl, y_hl, z_data, color='blue', marker='o', label='Shot Locations')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title(\"Controllable 3D Basketball Court View\\n(Rotation + Data Zoom)\")\n",
    "\n",
    "# C. Create the interactive widgets for rotation and data zoom\n",
    "row1, row2 = create_widgets(ax)\n",
    "\n",
    "# D. Display the widget controls\n",
    "display(row1)\n",
    "display(row2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting notebooks/freethrow_predictions/animate/interactive_3d_court_streamlit.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile notebooks/freethrow_predictions/animate/interactive_3d_court_streamlit.py\n",
    "import streamlit as st\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mplbasketball.court3d import draw_court_3d\n",
    "from mplbasketball.utils import transform\n",
    "\n",
    "# Initialize session state for camera controls\n",
    "if 'camera' not in st.session_state:\n",
    "    st.session_state.camera = {\n",
    "        'elev': 30,\n",
    "        'azim': 45,\n",
    "        'dist': 40,       # We'll keep this for reference, but not use it for zoom\n",
    "        'zoom_factor': 1.0\n",
    "    }\n",
    "\n",
    "# We also need a default for data_zoom if it doesn't exist yet\n",
    "if 'data_zoom' not in st.session_state:\n",
    "    st.session_state.data_zoom = 1.0\n",
    "\n",
    "def create_3d_court():\n",
    "    \"\"\"Create and configure the 3D basketball court visualization\"\"\"\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Draw court\n",
    "    draw_court_3d(ax, origin=np.array([0.0, 0.0]), line_width=1.5)\n",
    "    \n",
    "    # Set initial view\n",
    "    ax.view_init(\n",
    "        elev=st.session_state.camera['elev'],\n",
    "        azim=st.session_state.camera['azim']\n",
    "    )\n",
    "    # We'll still set ax.dist, but it won't actually zoom in Streamlit.\n",
    "    ax.dist = st.session_state.camera['dist']\n",
    "    \n",
    "    # Set axis limits\n",
    "    ax.set_xlim(-50, 50)\n",
    "    ax.set_ylim(-30, 30)\n",
    "    ax.set_zlim(0, 20)\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "def add_sample_data(ax):\n",
    "    \"\"\"Add sample trajectory and shot data\"\"\"\n",
    "    # Player trajectory\n",
    "    x = np.linspace(-40, 40, 100)\n",
    "    y = np.linspace(-20, 20, 100)\n",
    "    z = np.abs(np.sin(x * np.pi / 80) * 5)\n",
    "    ax.plot(x, y, z, 'r-', lw=2, label='Player Trajectory')\n",
    "    \n",
    "    # Shot locations\n",
    "    x_data = np.random.uniform(-40, 40, 50)\n",
    "    y_data = np.random.uniform(-20, 20, 50)\n",
    "    z_data = np.random.uniform(0, 20, 50)\n",
    "    x_hl, y_hl = transform(x_data, y_data, fr=\"h\", to=\"hl\", origin=\"center\")\n",
    "    ax.scatter(x_hl, y_hl, z_data, color='blue', marker='o', label='Shot Locations')\n",
    "\n",
    "###############################################################################\n",
    "# Streamlit UI\n",
    "###############################################################################\n",
    "st.title(\"3D Basketball Court Visualization\")\n",
    "\n",
    "# Create columns for the rotation/tilt/zoom buttons\n",
    "col1, col2, col3 = st.columns(3)\n",
    "\n",
    "with col1:\n",
    "    # Rotation controls\n",
    "    if st.button('Rotate Left'):\n",
    "        st.session_state.camera['azim'] -= 5\n",
    "    if st.button('Rotate Right'):\n",
    "        st.session_state.camera['azim'] += 5\n",
    "\n",
    "with col2:\n",
    "    # Elevation controls\n",
    "    if st.button('Tilt Up'):\n",
    "        st.session_state.camera['elev'] += 5\n",
    "    if st.button('Tilt Down'):\n",
    "        st.session_state.camera['elev'] -= 5\n",
    "\n",
    "with col3:\n",
    "    # CHANGED HERE: \"Zoom In\" & \"Zoom Out\" now update 'data_zoom'\n",
    "    if st.button('Zoom In'):\n",
    "        # Increase data_zoom but clamp to 2.0 max\n",
    "        st.session_state.data_zoom = min(2.0, st.session_state.data_zoom * 1.1)\n",
    "    if st.button('Zoom Out'):\n",
    "        # Decrease data_zoom but clamp to 0.5 min\n",
    "        st.session_state.data_zoom = max(0.5, st.session_state.data_zoom * 0.9)\n",
    "\n",
    "# Data limits zoom slider\n",
    "st.slider(\n",
    "    'Data Zoom Level', \n",
    "    0.5, \n",
    "    2.0, \n",
    "    1.0, \n",
    "    key='data_zoom',\n",
    "    help=\"Adjust the visible court area (0.5 = wide angle, 2.0 = close-up)\"\n",
    ")\n",
    "\n",
    "# Create and update visualization\n",
    "fig, ax = create_3d_court()\n",
    "add_sample_data(ax)\n",
    "\n",
    "# CHANGED HERE: Apply data-limits zoom with st.session_state.data_zoom\n",
    "current_zoom = st.session_state.data_zoom\n",
    "ax.set_xlim(-50/current_zoom, 50/current_zoom)\n",
    "ax.set_ylim(-30/current_zoom, 30/current_zoom)\n",
    "ax.set_zlim(0, 20/current_zoom)\n",
    "\n",
    "# Finalize plot\n",
    "ax.legend()\n",
    "ax.set_title(\"Interactive 3D Basketball Court\")\n",
    "\n",
    "st.pyplot(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting notebooks/freethrow_predictions/animate/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile notebooks/freethrow_predictions/animate/__init__.py\n",
    "# Create __init__.py in notebooks/animate/\n",
    "# Empty file to mark 'animate' as a package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting notebooks/freethrow_predictions/animate/viewpoints.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile notebooks/freethrow_predictions/animate/viewpoints.py\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define common viewpoints\n",
    "COMMON_VIEWPOINTS = {\n",
    "    \"side_view_right\": {\"elev\": 0, \"azim\": 90},\n",
    "    \"side_view_left\": {\"elev\": 0, \"azim\": -90},\n",
    "    \"top_down\": {\"elev\": 90, \"azim\": 0},\n",
    "    \"diagonal_view\": {\"elev\": 45, \"azim\": 45},\n",
    "    \"player_centric\": {\"elev\": 30, \"azim\": 0},\n",
    "    \"diagonal_player_centric\": {\"elev\": 30, \"azim\": 45},\n",
    "    \"inverse_player_centric\": {\"elev\": 30, \"azim\": 180}\n",
    "}\n",
    "\n",
    "def get_viewpoint(name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve viewpoint parameters by name.\n",
    "    \n",
    "    Parameters:\n",
    "      - name (str): The name of the viewpoint.\n",
    "      \n",
    "    Returns:\n",
    "      - dict: Dictionary containing 'elev' and 'azim'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        viewpoint = COMMON_VIEWPOINTS[name]\n",
    "        logger.debug(f\"Retrieved viewpoint '{name}': {viewpoint}\")\n",
    "        return viewpoint\n",
    "    except KeyError:\n",
    "        logger.error(f\"Viewpoint '{name}' not found. Available viewpoints: {list(COMMON_VIEWPOINTS.keys())}\")\n",
    "        raise ValueError(f\"Viewpoint '{name}' not found. Choose from {list(COMMON_VIEWPOINTS.keys())}\")\n",
    "\n",
    "def update_3d_view(ax: plt.Axes, elev: float, azim: float, data_zoom: float, zlim: float) -> None:\n",
    "    \"\"\"\n",
    "    Update the view of a 3D axis independently.\n",
    "    \n",
    "    This function sets the camera view (elevation and azimuth) and adjusts the axis\n",
    "    limits using the provided data_zoom factor and z-axis limit.\n",
    "    \n",
    "    Parameters:\n",
    "      - ax (plt.Axes): The 3D axis to update.\n",
    "      - elev (float): The elevation angle.\n",
    "      - azim (float): The azimuth angle.\n",
    "      - data_zoom (float): The zoom factor to adjust x, y, and z limits.\n",
    "      - zlim (float): The maximum value for the z-axis.\n",
    "    \n",
    "    Returns:\n",
    "      - None\n",
    "    \"\"\"\n",
    "    # Set the camera view\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "    \n",
    "    # Retrieve current x and y limits and adjust them based on the zoom factor.\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    ax.set_xlim([x_min / data_zoom, x_max / data_zoom])\n",
    "    ax.set_ylim([y_min / data_zoom, y_max / data_zoom])\n",
    "    # Set the z-axis limit from 0 to zlim adjusted by the zoom factor.\n",
    "    ax.set_zlim([0, zlim / data_zoom])\n",
    "    \n",
    "    logger.debug(f\"3D view updated: elev={elev}, azim={azim}, data_zoom={data_zoom}, zlim={zlim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting notebooks/freethrow_predictions/animate/court.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile notebooks/freethrow_predictions/animate/court.py\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mplbasketball.court3d import Court3D, draw_court_3d\n",
    "from typing import Dict\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def get_court_params(court_type: str = \"nba\", units: str = \"ft\", debug: bool = False) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Build and return court parameters directly from mplbasketball's Court3D.\n",
    "    Strictly uses the measurements provided by the library. No fallbacks.\n",
    "\n",
    "    Returns:\n",
    "        {\n",
    "            \"hoop_radius\": float,   # radius in the same coordinate units used by your Court3D\n",
    "        }\n",
    "    \"\"\"\n",
    "    try:\n",
    "        court = Court3D(court_type=court_type, units=units)\n",
    "        court_params = court.court_parameters\n",
    "        \n",
    "        if 'hoop_radius' not in court_params:\n",
    "            # We do NOT guess; we do NOT derive from diameter, etc. Hard error.\n",
    "            raise KeyError(\n",
    "                \"Court3D does not provide 'hoop_radius' in court_parameters. \"\n",
    "                \"Available keys: \" + str(list(court_params.keys()))\n",
    "            )\n",
    "        \n",
    "        hoop_radius = float(court_params['hoop_radius'])\n",
    "        \n",
    "        if debug:\n",
    "            logger.debug(f\"[court] type={court_type} units={units} hoop_radius={hoop_radius}\")\n",
    "        \n",
    "        return {\"hoop_radius\": hoop_radius}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error getting court parameters: {e}\")\n",
    "        raise\n",
    "\n",
    "def validate_court_params(court_params: Dict[str, float]) -> None:\n",
    "    \"\"\"\n",
    "    Validate presence of required measurements. No defaults, no fallbacks.\n",
    "    \"\"\"\n",
    "    missing = [k for k in (\"hoop_radius\",) if k not in court_params]\n",
    "    if missing:\n",
    "        raise KeyError(\n",
    "            f\"court_params missing required key(s): {missing}. \"\n",
    "            \"We only use the library-provided measurements; none are inferred.\"\n",
    "        )\n",
    "\n",
    "def get_hoop_position(court_type: str = \"nba\", units: str = \"ft\", debug: bool = False) -> (float, float, float):\n",
    "    \"\"\"\n",
    "    Calculate the 3D position of the basketball hoop based on court specifications.\n",
    "\n",
    "    Parameters:\n",
    "    - court_type (str): Type of the court ('nba', 'wnba', 'ncaa').\n",
    "    - units (str): Units of measurement ('ft' or 'm').\n",
    "    - debug (bool): Flag to enable debug logging.\n",
    "\n",
    "    Returns:\n",
    "    - x, y, z (float): Coordinates of the hoop in 3D space.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        court = Court3D(court_type=court_type, units=units)\n",
    "        params = court.court_parameters\n",
    "        # The hoop is located a certain distance from the edge of the court\n",
    "        x = params['court_dims'][0] / 2 - params['hoop_distance_from_edge']\n",
    "        y = 0.0  # Centered along the y-axis\n",
    "        z = params['hoop_height']\n",
    "        if debug:\n",
    "            logger.debug(f\"Calculated hoop position at (x={x}, y={y}, z={z}) for court type '{court_type}' in '{units}' units.\")\n",
    "        return x, y, z\n",
    "    except KeyError as e:\n",
    "        logger.error(f\"Key error when accessing court parameters: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error in get_hoop_position: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def draw_court(ax: plt.Axes, court_type: str = \"nba\", units: str = \"ft\", debug: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Draw the basketball court and hoops on the given axes.\n",
    "    Uses ONLY real measurements from mplbasketball. No fallbacks.\n",
    "\n",
    "    Parameters:\n",
    "    - ax (plt.Axes): The Matplotlib 3D axis object.\n",
    "    - court_type (str): Type of the court ('nba', 'wnba', 'ncaa').\n",
    "    - units (str): Units of measurement ('ft' or 'm').\n",
    "    - debug (bool): Flag to enable debug logging.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Draw the court using mplbasketball\n",
    "        draw_court_3d(ax, court_type=court_type, units=units, origin=np.array([0.0, 0.0]), line_width=2)\n",
    "        if debug:\n",
    "            logger.debug(\"Court drawn successfully using mplbasketball.\")\n",
    "\n",
    "        # Get court parameters using our validated function\n",
    "        court_params = get_court_params(court_type=court_type, units=units, debug=debug)\n",
    "        validate_court_params(court_params)\n",
    "        \n",
    "        if debug:\n",
    "            logger.debug(f\"Court Parameters in draw_court: {court_params}\")\n",
    "\n",
    "        # Get hoop position\n",
    "        hoop_x, hoop_y, hoop_z = get_hoop_position(court_type=court_type, units=units, debug=debug)\n",
    "\n",
    "        # Draw the hoop as a circle using the actual hoop_radius from the library\n",
    "        hoop_radius = float(court_params[\"hoop_radius\"])\n",
    "        theta_circle = np.linspace(0, 2 * np.pi, 100)\n",
    "        hoop_xs = hoop_x + hoop_radius * np.cos(theta_circle)\n",
    "        hoop_ys = hoop_y + hoop_radius * np.sin(theta_circle)\n",
    "        hoop_zs = np.full_like(hoop_xs, hoop_z)\n",
    "\n",
    "        ax.plot(hoop_xs, hoop_ys, hoop_zs, c='orange', lw=3)\n",
    "        if debug:\n",
    "            logger.debug(f\"Hoop drawn at position ({hoop_x}, {hoop_y}, {hoop_z}) with radius {hoop_radius}.\")\n",
    "\n",
    "        # Get full court parameters for additional features\n",
    "        court = Court3D(court_type=court_type, units=units)\n",
    "        full_court_params = court.court_parameters\n",
    "\n",
    "        # Plot half-court line\n",
    "        half_court_x = np.linspace(-full_court_params['court_dims'][0]/2, full_court_params['court_dims'][0]/2, 100)\n",
    "        half_court_y = np.full_like(half_court_x, 0.0)\n",
    "        half_court_z = np.full_like(half_court_x, 0.0)\n",
    "        ax.plot(half_court_x, half_court_y, half_court_z, c='black', lw=2, linestyle='--', label='Half-Court Line')\n",
    "        if debug:\n",
    "            logger.debug(\"Half-court line plotted.\")\n",
    "\n",
    "        # Plot sidelines\n",
    "        sideline_x = np.linspace(-full_court_params['court_dims'][0]/2, full_court_params['court_dims'][0]/2, 100)\n",
    "        sideline_y_positive = np.full_like(sideline_x, full_court_params['court_dims'][1]/2)\n",
    "        sideline_z = np.full_like(sideline_x, 0.0)\n",
    "        ax.plot(sideline_x, sideline_y_positive, sideline_z, c='blue', lw=2, label='Sideline')\n",
    "        if debug:\n",
    "            logger.debug(\"Positive sideline plotted.\")\n",
    "\n",
    "        sideline_y_negative = np.full_like(sideline_x, -full_court_params['court_dims'][1]/2)\n",
    "        ax.plot(sideline_x, sideline_y_negative, sideline_z, c='blue', lw=2, label='Sideline')\n",
    "        if debug:\n",
    "            logger.debug(\"Negative sideline plotted.\")\n",
    "\n",
    "        # Plot baselines\n",
    "        baseline_y = np.linspace(-full_court_params['court_dims'][1]/2, full_court_params['court_dims'][1]/2, 100)\n",
    "        baseline_z = np.full_like(baseline_y, 0.0)\n",
    "        ax.plot(full_court_params['court_dims'][0]/2, baseline_y, baseline_z, c='green', lw=2, label='Baseline')\n",
    "        if debug:\n",
    "            logger.debug(\"Positive baseline plotted.\")\n",
    "\n",
    "        ax.plot(-full_court_params['court_dims'][0]/2, baseline_y, baseline_z, c='green', lw=2, label='Baseline')\n",
    "        if debug:\n",
    "            logger.debug(\"Negative baseline plotted.\")\n",
    "\n",
    "        if debug:\n",
    "            logger.debug(\"Additional court features (half-court, sidelines, baselines) drawn successfully.\")\n",
    "    except KeyError as e:\n",
    "        logger.error(f\"Key error in draw_court: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error drawing court or hoop: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting notebooks/freethrow_predictions/animate/elements.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile notebooks/freethrow_predictions/animate/elements.py\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def initialize_elements(\n",
    "    ax: plt.Axes,\n",
    "    connections: list,\n",
    "    player_color: str,\n",
    "    player_lw: float,\n",
    "    ball_color: str,\n",
    "    ball_size: float,\n",
    "    debug: bool = False\n",
    ") -> (dict, plt.Line2D, plt.Text, plt.Text, plt.Text, dict):\n",
    "    \"\"\"\n",
    "    Initialize plot elements for the player skeleton, ball, text annotations,\n",
    "    and now also creates a marker (small dot) for every unique joint.\n",
    "    \n",
    "    Returns:\n",
    "        lines (dict): Dictionary of line objects for each connection.\n",
    "        ball (plt.Line2D): The ball plot object.\n",
    "        release_text (plt.Text): Text object for release point indicator.\n",
    "        motion_text (plt.Text): Text object for motion phase indicator.\n",
    "        distance_text (plt.Text): Text object for distance to hoop.\n",
    "        joint_markers (dict): Dictionary of marker objects for each unique joint.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1) SKELETON LINES\n",
    "        lines = {connection: ax.plot([], [], [], c=player_color, lw=player_lw)[0] for connection in connections}\n",
    "        \n",
    "        # 2) BALL MARKER\n",
    "        ball, = ax.plot([], [], [], \"o\", markersize=ball_size, c=ball_color)\n",
    "        \n",
    "        # 3) TEXT ELEMENTS\n",
    "        release_text = ax.text2D(0.05, 0.95, \"\", transform=ax.transAxes,\n",
    "                                 color=\"red\", fontsize=14, weight=\"bold\")\n",
    "        motion_text = ax.text2D(0.05, 0.90, \"\", transform=ax.transAxes,\n",
    "                                color=\"blue\", fontsize=12, weight=\"bold\")\n",
    "        distance_text = ax.text2D(0.05, 0.85, \"\", transform=ax.transAxes,\n",
    "                                  color=\"green\", fontsize=12, weight=\"bold\")\n",
    "        \n",
    "        # 4) NEW: JOINT MARKERS\n",
    "        # Create a set of all unique joint names from the connections list.\n",
    "        unique_joints = set()\n",
    "        for (joint_a, joint_b) in connections:\n",
    "            unique_joints.add(joint_a)\n",
    "            unique_joints.add(joint_b)\n",
    "        joint_markers = {}\n",
    "        for joint in unique_joints:\n",
    "            marker_line, = ax.plot([], [], [], \"o\", color=player_color, markersize=5)\n",
    "            joint_markers[joint] = marker_line\n",
    "\n",
    "        if debug:\n",
    "            logger.debug(\"Elements initialized (lines, ball, texts, and joint markers).\")\n",
    "        \n",
    "        return lines, ball, release_text, motion_text, distance_text, joint_markers\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error initializing elements: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def initialize_plot(zlim=20, elev=30, azim=60, figsize=(12, 10), debug=False):\n",
    "    \"\"\"\n",
    "    Initialize a 3D plot with specified view settings and outputs setup details.\n",
    "\n",
    "    Parameters:\n",
    "    - zlim (float): The limit for the z-axis (height).\n",
    "    - elev (float): Elevation angle in the z plane for the camera view.\n",
    "    - azim (float): Azimuth angle in the x,y plane for the camera view.\n",
    "    - figsize (tuple): Figure size.\n",
    "    - debug (bool): Flag to enable debug logging.\n",
    "\n",
    "    Returns:\n",
    "    - fig: The Matplotlib figure object.\n",
    "    - ax: The Matplotlib 3D axis object.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = fig.add_subplot(111, projection=\"3d\")\n",
    "        ax.set_zlim([0, zlim])\n",
    "        ax.set_box_aspect([1, 1, 1])\n",
    "        ax.view_init(elev=elev, azim=azim)\n",
    "        ax.xaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "        ax.yaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_zticks([])\n",
    "        if debug:\n",
    "            logger.debug(f\"Initialized 3D plot with Z limit: {zlim}, Elevation: {elev}, Azimuth: {azim}\")\n",
    "        return fig, ax\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to initialize plot: {e}\")\n",
    "        raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting notebooks/freethrow_predictions/animate/animate_from_df.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile notebooks/freethrow_predictions/animate/animate_from_df.py\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.lines import Line2D\n",
    "from IPython.display import HTML\n",
    "from mplbasketball.court3d import Court3D, draw_court_3d\n",
    "\n",
    "from animate.elements import initialize_elements, initialize_plot\n",
    "from animate.court import draw_court, get_hoop_position\n",
    "from animate.viewpoints import get_viewpoint\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def update_frame(\n",
    "    ax: plt.Axes,\n",
    "    frame: int,\n",
    "    df: pd.DataFrame,\n",
    "    release_frame: int,\n",
    "    lines: dict,\n",
    "    ball: plt.Line2D,\n",
    "    release_text: plt.Text,\n",
    "    motion_text: plt.Text,\n",
    "    connections: list,\n",
    "    ball_color: str,\n",
    "    highlight_color: str,\n",
    "    debug: bool = False\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Update function for each frame in the animation.\n",
    "\n",
    "    Parameters:\n",
    "    - ax (plt.Axes): The Matplotlib 3D axis object.\n",
    "    - frame (int): The current frame number.\n",
    "    - df (pd.DataFrame): DataFrame containing motion data.\n",
    "    - release_frame (int): Frame index of the release point.\n",
    "    - lines (dict): Dictionary of line objects for skeleton.\n",
    "    - ball (plt.Line2D): Ball object for animation.\n",
    "    - release_text (plt.Text): Text object for release point.\n",
    "    - motion_text (plt.Text): Text object for motion phase.\n",
    "    - connections (list): Joint connections.\n",
    "    - ball_color (str): Default ball color.\n",
    "    - highlight_color (str): Highlight color for release point.\n",
    "    - debug (bool): Flag to enable debug logging.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if debug and frame % 10 == 0:\n",
    "            logger.debug(f\"Updating frame {frame}\")\n",
    "\n",
    "        # Highlight the release frame\n",
    "        if frame == release_frame:\n",
    "            ball.set_color(highlight_color)\n",
    "            release_text.set_text(\"Release Point!\")\n",
    "            if debug:\n",
    "                logger.debug(f\"Frame {frame} is the release frame. Ball color changed to {highlight_color}.\")\n",
    "        else:\n",
    "            ball.set_color(ball_color)\n",
    "            release_text.set_text(\"\")\n",
    "\n",
    "        # Update motion phase text if 'shooting_motion' exists\n",
    "        if 'shooting_motion' in df.columns:\n",
    "            shooting_motion = df.at[frame, 'shooting_motion']\n",
    "            motion_text.set_text(\"Shooting Motion\" if shooting_motion == 1 else \"\")\n",
    "        else:\n",
    "            motion_text.set_text(\"\")\n",
    "\n",
    "        # Update lines for joints\n",
    "        for connection in connections:\n",
    "            part1, part2 = connection\n",
    "            if (f\"{part1}_x\" in df.columns and f\"{part2}_x\" in df.columns and\n",
    "                not pd.isna(df.at[frame, f\"{part1}_x\"]) and not pd.isna(df.at[frame, f\"{part2}_x\"])):\n",
    "                x = [df.at[frame, f\"{part1}_x\"], df.at[frame, f\"{part2}_x\"]]\n",
    "                y = [df.at[frame, f\"{part1}_y\"], df.at[frame, f\"{part2}_y\"]]\n",
    "                z = [df.at[frame, f\"{part1}_z\"], df.at[frame, f\"{part2}_z\"]]\n",
    "                lines[connection].set_data_3d(x, y, z)\n",
    "            else:\n",
    "                # If data is missing, hide the line\n",
    "                lines[connection].set_data([], [])\n",
    "                lines[connection].set_3d_properties([])\n",
    "\n",
    "        # Update ball position if ball coordinates exist\n",
    "        if 'ball_x' in df.columns and 'ball_y' in df.columns and 'ball_z' in df.columns:\n",
    "            ball_x = df.at[frame, 'ball_x']\n",
    "            ball_y = df.at[frame, 'ball_y']\n",
    "            ball_z = df.at[frame, 'ball_z']\n",
    "            if not (pd.isna(ball_x) or pd.isna(ball_y) or pd.isna(ball_z)):\n",
    "                ball.set_data_3d([ball_x], [ball_y], [ball_z])\n",
    "            else:\n",
    "                # Hide the ball if data is missing\n",
    "                ball.set_data([], [])\n",
    "                ball.set_3d_properties([])\n",
    "        else:\n",
    "            # Hide the ball if columns are missing\n",
    "            ball.set_data([], [])\n",
    "            ball.set_3d_properties([])\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error updating frame {frame}: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "\n",
    "def animate_trial_from_df(\n",
    "    df: pd.DataFrame,\n",
    "    release_frame: int,\n",
    "    viewpoint_name: str = \"side_view_right\",\n",
    "    connections: list = None,\n",
    "    zlim: float = 15.0,\n",
    "    player_color: str = \"purple\",\n",
    "    player_lw: float = 2.0,\n",
    "    ball_color: str = \"#ee6730\",\n",
    "    ball_size: float = 20.0,\n",
    "    highlight_color: str = \"red\",\n",
    "    show_court: bool = True,\n",
    "    court_type: str = \"nba\",\n",
    "    units: str = \"ft\",\n",
    "    notebook_mode: bool = True,\n",
    "    debug: bool = False\n",
    ") -> HTML:\n",
    "    \"\"\"\n",
    "    Animate a basketball trial from a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame containing motion data.\n",
    "    - release_frame (int): Frame index of the release point.\n",
    "    - viewpoint_name (str): Name of the predefined viewpoint.\n",
    "    - connections (list): List of joint connections.\n",
    "    - zlim (float): The limit for the z-axis (height).\n",
    "    - player_color (str): Color for player skeleton.\n",
    "    - player_lw (float): Line width for player skeleton.\n",
    "    - ball_color (str): Color for the ball.\n",
    "    - ball_size (float): Size of the ball marker.\n",
    "    - highlight_color (str): Highlight color for release point.\n",
    "    - show_court (bool): Whether to display the court.\n",
    "    - court_type (str): Type of the court ('nba', 'wnba', 'ncaa').\n",
    "    - units (str): Units of measurement ('ft' or 'm').\n",
    "    - notebook_mode (bool): Whether to display animation in Jupyter notebook.\n",
    "    - debug (bool): Flag to enable debug logging.\n",
    "\n",
    "    Returns:\n",
    "    - HTML: HTML representation of the animation for notebook display.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if connections is None:\n",
    "            logger.error(\"No connections provided for player skeleton.\")\n",
    "            raise ValueError(\"Connections list cannot be None.\")\n",
    "\n",
    "        # Close any existing figures to prevent duplicate animations\n",
    "        plt.close('all')\n",
    "\n",
    "        if debug:\n",
    "            logger.debug(\"Starting animation setup.\")\n",
    "            logger.debug(f\"Total frames in DataFrame: {len(df)}\")\n",
    "            logger.debug(f\"Release frame index provided: {release_frame}\")\n",
    "            logger.debug(f\"Selected viewpoint: {viewpoint_name}\")\n",
    "\n",
    "        # Retrieve elev and azim based on viewpoint_name\n",
    "        viewpoint = get_viewpoint(viewpoint_name)\n",
    "        elev = viewpoint['elev']\n",
    "        azim = viewpoint['azim']\n",
    "\n",
    "        # Plot setup with predefined viewpoint\n",
    "        fig, ax = initialize_plot(zlim=zlim, elev=elev, azim=azim, figsize=(12, 10), debug=debug)\n",
    "\n",
    "        # Draw court and get hoop position\n",
    "        if show_court:\n",
    "            draw_court(ax, court_type=court_type, units=units, debug=debug)\n",
    "            hoop_x, hoop_y, hoop_z = get_hoop_position(court_type=court_type, units=units, debug=debug)\n",
    "            if debug:\n",
    "                logger.debug(f\"Hoop position retrieved: ({hoop_x}, {hoop_y}, {hoop_z})\")\n",
    "        else:\n",
    "            hoop_x, hoop_y, hoop_z = None, None, None\n",
    "            if debug:\n",
    "                logger.debug(\"Court not shown. Hoop position set to None.\")\n",
    "\n",
    "        # Initialize elements for animation\n",
    "        lines, ball, release_text, motion_text, distance_text = initialize_elements(\n",
    "            ax, connections, player_color, player_lw, ball_color, ball_size, debug=debug\n",
    "        )\n",
    "\n",
    "        # Compute axes limits based on player data and hoop position\n",
    "        if debug:\n",
    "            logger.debug(\"Calculating axes limits to include player and hoop.\")\n",
    "\n",
    "        # Extract all x and y coordinates for the player\n",
    "        player_x_cols = [col for col in df.columns if col.endswith('_x')]\n",
    "        player_y_cols = [col for col in df.columns if col.endswith('_y')]\n",
    "\n",
    "        player_x = df[player_x_cols].values.flatten()\n",
    "        player_y = df[player_y_cols].values.flatten()\n",
    "\n",
    "        # Remove NaN values\n",
    "        player_x = player_x[~np.isnan(player_x)]\n",
    "        player_y = player_y[~np.isnan(player_y)]\n",
    "\n",
    "        if len(player_x) == 0 or len(player_y) == 0:\n",
    "            logger.warning(\"No player coordinates found. Axes limits may not be set correctly.\")\n",
    "\n",
    "        # Get court parameters\n",
    "        if show_court:\n",
    "            court = Court3D(court_type=court_type, units=units)\n",
    "            court_params = court.court_parameters\n",
    "        else:\n",
    "            court_params = {'court_length': 94.0, 'court_width': 50.0}  # Default values\n",
    "\n",
    "        # Initialize min and max with player coordinates\n",
    "        x_min = player_x.min() - 10.0 if len(player_x) > 0 else -court_params['court_length']/2\n",
    "        x_max = player_x.max() + 10.0 if len(player_x) > 0 else court_params['court_length']/2\n",
    "        y_min = player_y.min() - 10.0 if len(player_y) > 0 else -court_params['court_width']/2\n",
    "        y_max = player_y.max() + 10.0 if len(player_y) > 0 else court_params['court_width']/2\n",
    "\n",
    "        # Include hoop position in the limits if court is shown and hoop position is valid\n",
    "        if show_court and hoop_x is not None and hoop_y is not None:\n",
    "            x_min = min(x_min, hoop_x - 10.0)\n",
    "            x_max = max(x_max, hoop_x + 10.0)\n",
    "            y_min = min(y_min, hoop_y - 10.0)\n",
    "            y_max = max(y_max, hoop_y + 10.0)\n",
    "            if debug:\n",
    "                logger.debug(f\"Including hoop position in axes limits.\")\n",
    "\n",
    "        if debug:\n",
    "            logger.debug(f\"Player X range: {player_x.min()} to {player_x.max()}\")\n",
    "            logger.debug(f\"Player Y range: {player_y.min()} to {player_y.max()}\")\n",
    "            if show_court:\n",
    "                logger.debug(f\"Hoop position: ({hoop_x}, {hoop_y})\")\n",
    "            logger.debug(f\"Using xbuffer: 10.0, ybuffer: 10.0\")\n",
    "\n",
    "        # Set fixed axes limits\n",
    "        ax.set_xlim([x_min, x_max])\n",
    "        ax.set_ylim([y_min, y_max])\n",
    "\n",
    "        if debug:\n",
    "            logger.debug(f\"Set axes limits: x=({x_min}, {x_max}), y=({y_min}, {y_max})\")\n",
    "\n",
    "        # Set plot title to include the viewpoint name\n",
    "        ax.set_title(f\"Animation - {viewpoint_name}\", fontsize=16)\n",
    "        if debug: \n",
    "            logger.debug(f\"Set plot title to 'Animation - {viewpoint_name}'\")\n",
    "\n",
    "        # Create custom legend handles for static court features\n",
    "        hoop_handle = Line2D([0], [0], color='orange', lw=3, label='Hoop')\n",
    "        baseline_handle = Line2D([0], [0], color='blue', lw=2, label='Baseline')\n",
    "        sideline_handle = Line2D([0], [0], color='green', lw=2, label='Sideline')\n",
    "\n",
    "        # Create handles for dynamic elements\n",
    "        player_handle = Line2D([0], [0], color=player_color, lw=player_lw, label='Player')\n",
    "        ball_handle = Line2D([0], [0], marker='o', color='w', label='Ball',\n",
    "                             markerfacecolor=ball_color, markersize=10)\n",
    "\n",
    "        # Add legend with both static and dynamic elements (excluding distance)\n",
    "        ax.legend(handles=[\n",
    "            hoop_handle,  # Hoop in orange\n",
    "            sideline_handle,  # Sideline in green\n",
    "            baseline_handle,  # Baseline in blue\n",
    "            player_handle,  # Player skeleton in purple\n",
    "            ball_handle  # Ball in orange\n",
    "        ], loc='upper right')\n",
    "\n",
    "        if debug:\n",
    "            logger.debug(\"Legend added with static court features and dynamic elements.\")\n",
    "\n",
    "        # Update function for animation\n",
    "        def update_func(frame: int):\n",
    "            \"\"\"\n",
    "            Wrapper function for updating the frame in the animation.\n",
    "            \"\"\"\n",
    "            update_frame(\n",
    "                ax=ax,\n",
    "                frame=frame,\n",
    "                df=df,\n",
    "                release_frame=release_frame,\n",
    "                lines=lines,\n",
    "                ball=ball,\n",
    "                release_text=release_text,\n",
    "                motion_text=motion_text,\n",
    "                connections=connections,\n",
    "                ball_color=ball_color,\n",
    "                highlight_color=highlight_color,\n",
    "                debug=debug\n",
    "            )\n",
    "\n",
    "            # Update the distance text if available\n",
    "            if 'distance_to_hoop' in df.columns:\n",
    "                distance = df.at[frame, 'distance_to_hoop']\n",
    "                if not pd.isna(distance):\n",
    "                    distance_text.set_text(f\"Distance to Hoop: {distance:.2f} ft\")\n",
    "                else:\n",
    "                    distance_text.set_text(\"\")\n",
    "            else:\n",
    "                distance_text.set_text(\"\")\n",
    "\n",
    "        # Animation setup\n",
    "        anim = FuncAnimation(fig, update_func, frames=len(df), interval=1000 / 30, blit=False)\n",
    "\n",
    "        if notebook_mode:\n",
    "            if debug:\n",
    "                logger.debug(\"Returning animation for notebook display.\")\n",
    "            return HTML(anim.to_jshtml())\n",
    "        else:\n",
    "            if debug:\n",
    "                logger.debug(\"Returning animation object.\")\n",
    "            return anim\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during animation: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting notebooks/freethrow_predictions/animate/animate_from_df_main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile notebooks/freethrow_predictions/animate/animate_from_df_main.py\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from animate.animate_from_df import animate_trial_from_df\n",
    "\n",
    "joint_configs = [\n",
    "    {\n",
    "        'name': 'knee',\n",
    "        'min_angle_key': 'knee_max_angle_filtered_optimal_min',\n",
    "        'max_angle_key': 'knee_max_angle_filtered_optimal_max',\n",
    "        'release_min_angle_key': 'knee_release_angle_filtered_optimal_min',\n",
    "        'release_max_angle_key': 'knee_release_angle_filtered_optimal_max',\n",
    "        'angle_key': 'knee_angle',\n",
    "        'is_max_key': 'is_knee_max_angle',\n",
    "        'classification_key': 'knee_max_angle_shot_classification',\n",
    "        'release_classification_key': 'knee_release_angle_shot_classification'\n",
    "    },\n",
    "    {\n",
    "        'name': 'elbow',\n",
    "        'min_angle_key': 'elbow_max_angle_filtered_optimal_min',\n",
    "        'max_angle_key': 'elbow_max_angle_filtered_optimal_max',\n",
    "        'release_min_angle_key': 'elbow_release_angle_filtered_optimal_min',\n",
    "        'release_max_angle_key': 'elbow_release_angle_filtered_optimal_max',\n",
    "        'angle_key': 'elbow_angle',\n",
    "        'is_max_key': 'is_elbow_max_angle',\n",
    "        'classification_key': 'elbow_max_angle_shot_classification',\n",
    "        'release_classification_key': 'elbow_release_angle_shot_classification'\n",
    "    },\n",
    "    {\n",
    "        'name': 'wrist',\n",
    "        'min_angle_key': 'max_wrist_angle_filtered_optimal_min',\n",
    "        'max_angle_key': 'max_wrist_angle_filtered_optimal_max',\n",
    "        'release_min_angle_key': 'wrist_release_angle_filtered_optimal_min',\n",
    "        'release_max_angle_key': 'wrist_release_angle_filtered_optimal_max',\n",
    "        'angle_key': 'wrist_angle',\n",
    "        'is_max_key': 'is_max_wrist_angle',\n",
    "        'classification_key': 'max_wrist_angle_shot_classification',\n",
    "        'release_classification_key': 'wrist_release_angle_shot_classification'\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# Configure logging for debugging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Load data from the specified CSV file\n",
    "        data_path = \"../../data/processed/final_granular_dataset.csv\"\n",
    "        final_granular_df_with_stats = pd.read_csv(data_path)\n",
    "        logger.debug(f\"Loaded data from {data_path} with shape {final_granular_df_with_stats.shape}\")\n",
    "\n",
    "        # Define connections between joints\n",
    "        connections = [\n",
    "            (\"R_EYE\", \"L_EYE\"), (\"R_EYE\", \"NOSE\"), (\"L_EYE\", \"NOSE\"),\n",
    "            (\"R_EYE\", \"R_EAR\"), (\"L_EYE\", \"L_EAR\"), (\"R_SHOULDER\", \"L_SHOULDER\"),\n",
    "            (\"R_SHOULDER\", \"R_ELBOW\"), (\"L_SHOULDER\", \"L_ELBOW\"), (\"R_ELBOW\", \"R_WRIST\"),\n",
    "            (\"L_ELBOW\", \"L_WRIST\"), (\"R_SHOULDER\", \"R_HIP\"), (\"L_SHOULDER\", \"L_HIP\"),\n",
    "            (\"R_HIP\", \"L_HIP\"), (\"R_HIP\", \"R_KNEE\"), (\"L_HIP\", \"L_KNEE\"),\n",
    "            (\"R_KNEE\", \"R_ANKLE\"), (\"L_KNEE\", \"L_ANKLE\"), (\"R_WRIST\", \"R_1STFINGER\"),\n",
    "            (\"R_WRIST\", \"R_5THFINGER\"), (\"L_WRIST\", \"L_1STFINGER\"), (\"L_WRIST\", \"L_5THFINGER\"),\n",
    "            (\"R_ANKLE\", \"R_1STTOE\"), (\"R_ANKLE\", \"R_5THTOE\"), (\"L_ANKLE\", \"L_1STTOE\"),\n",
    "            (\"L_ANKLE\", \"L_5THTOE\"), (\"R_ANKLE\", \"R_CALC\"), (\"L_ANKLE\", \"L_CALC\"),\n",
    "            (\"R_1STTOE\", \"R_5THTOE\"), (\"L_1STTOE\", \"L_5THTOE\"), (\"R_1STTOE\", \"R_CALC\"),\n",
    "            (\"L_1STTOE\", \"L_CALC\"), (\"R_5THTOE\", \"R_CALC\"), (\"L_5THTOE\", \"L_CALC\"),\n",
    "            (\"R_1STFINGER\", \"R_5THFINGER\"), (\"L_1STFINGER\", \"L_5THFINGER\")\n",
    "        ]\n",
    "        logger.debug(\"Defined joint connections for player skeleton.\")\n",
    "\n",
    "        # Select a specific trial for visualization\n",
    "        trial_id_to_visualize = 'T0088'  # Replace with actual trial ID you want to visualize\n",
    "        trial_data = final_granular_df_with_stats[final_granular_df_with_stats['trial_id'] == trial_id_to_visualize]\n",
    "        trial_data = trial_data.sort_values(by='frame_time').reset_index(drop=True)\n",
    "        logger.debug(f\"Selected trial ID '{trial_id_to_visualize}' with {len(trial_data)} frames.\")\n",
    "\n",
    "        # Determine the release frame (the frame where release_point_filter is 1)\n",
    "        release_frames = trial_data.index[trial_data[\"release_point_filter\"] == 1].tolist()\n",
    "        release_frame = release_frames[0] if release_frames else None\n",
    "        if release_frame is not None:\n",
    "            logger.debug(f\"Release frame found at index {release_frame}.\")\n",
    "        else:\n",
    "            logger.warning(\"No release frame found in the trial data.\")\n",
    "\n",
    "        # Set parameters for visualization\n",
    "        viewpoint_name = \"diagonal_player_centric\"  # Choose from COMMON_VIEWPOINTS\n",
    "        zlim = 15        # Adjust for height\n",
    "\n",
    "\n",
    "        # Call the first animation function\n",
    "        animation_html = animate_trial_from_df(\n",
    "            df=trial_data,\n",
    "            release_frame=release_frame,\n",
    "            viewpoint_name=viewpoint_name,\n",
    "            connections=connections,\n",
    "            zlim=zlim,\n",
    "            player_color=\"purple\",\n",
    "            player_lw=2.0,\n",
    "            ball_color=\"#ee6730\",\n",
    "            ball_size=20.0,\n",
    "            highlight_color=\"red\",\n",
    "            show_court=True,\n",
    "            court_type=\"nba\",\n",
    "            units=\"ft\",\n",
    "            notebook_mode=True,\n",
    "            debug=True  # Enable detailed logging for troubleshooting\n",
    "        )\n",
    "        \n",
    "        # Display the first animation\n",
    "        display(animation_html)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred in main: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add on Shot meters\n",
    "\n",
    "- Basic logistic\n",
    "  - No predictions needed\n",
    "  - Take out the outliers and base it within the successful shots angles\n",
    "\n",
    "\n",
    "- Bayes optimized angles with Shap post recommendations, graphs, and trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add on shaps/bayes optimization angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting notebooks/freethrow_predictions/animate/calc_bayes_shap_feature_engineering.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile notebooks/freethrow_predictions/animate/calc_bayes_shap_feature_engineering.py\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import logging\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# add for if we ever want to recalculate the shap min and max values\n",
    "from ml.config.config_loader import load_config\n",
    "from ml.config.config_models import AppConfig\n",
    "from ml.shap.shap_utils import load_dataset, setup_logging, load_configuration, initialize_logger\n",
    "from ml.shap.predict_with_shap_usage import predict_and_shap\n",
    "    \n",
    "# ------------------------------------------------------------------------------\n",
    "# Logging configuration (used by bayesian metrics functions)\n",
    "# ------------------------------------------------------------------------------\n",
    "logger = logging.getLogger('combined_feature_engineering')\n",
    "if not logger.hasHandlers():\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    handler = logging.StreamHandler()\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "\n",
    "def round_numeric_columns(df: pd.DataFrame, decimals: int = 2) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Rounds all float columns in the DataFrame to the specified number of decimals.\n",
    "    \"\"\"\n",
    "    float_cols = df.select_dtypes(include=['float']).columns\n",
    "    df[float_cols] = df[float_cols].round(decimals)\n",
    "    return df\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# SHOT METER FEATURE ENGINEERING FUNCTIONS\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def calculate_release_angles(df: pd.DataFrame, handedness: str = \"R\", debug: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate and merge release angles (mean knee, wrist, and elbow angles) based on release_point_filter.\n",
    "    For right-handed shots, uses right-side columns; for left-handed, uses left-side columns.\n",
    "    The computed release angles are aggregated by trial_id and merged back into the original dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "      - df: Input DataFrame containing angle measurements and a 'release_point_filter' column.\n",
    "      - handedness: 'R' or 'L', indicating whether to use right-side or left-side measurements.\n",
    "      - debug: If True, prints debug information.\n",
    "    \n",
    "    Returns:\n",
    "      - df: DataFrame with new release angle columns merged in.\n",
    "    \"\"\"\n",
    "    # Check if the handedness is valid.\n",
    "    if handedness not in ['R', 'L']:\n",
    "        raise ValueError(\"Handedness must be 'R' for right-handed or 'L' for left-handed.\")\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Calculating release angles for {handedness}-handed shots.\")\n",
    "    \n",
    "    # Select the appropriate columns based on handedness.\n",
    "    if handedness == 'R':\n",
    "        df['knee_angle'] = df['R_KNEE_angle']\n",
    "        df['wrist_angle'] = df['R_WRIST_angle']\n",
    "        df['elbow_angle'] = df['R_ELBOW_angle']\n",
    "    else:\n",
    "        df['knee_angle'] = df['L_KNEE_angle']\n",
    "        df['wrist_angle'] = df['L_WRIST_angle']\n",
    "        df['elbow_angle'] = df['L_ELBOW_angle']\n",
    "    \n",
    "    # Filter rows where release_point_filter == 1.\n",
    "    release_df = df[df['release_point_filter'] == 1]\n",
    "    if debug:\n",
    "        print(f\"[calculate_release_angles] release_df shape: {release_df.shape}\")\n",
    "    \n",
    "    # Set new column names based on handedness.\n",
    "    if handedness == 'R':\n",
    "        new_names = {\n",
    "            'knee_angle': 'R_KNEE_release_angle',\n",
    "            'wrist_angle': 'R_WRIST_release_angle',\n",
    "            'elbow_angle': 'R_ELBOW_release_angle'\n",
    "        }\n",
    "    else:\n",
    "        new_names = {\n",
    "            'knee_angle': 'L_KNEE_release_angle',\n",
    "            'wrist_angle': 'L_WRIST_release_angle',\n",
    "            'elbow_angle': 'L_ELBOW_release_angle'\n",
    "        }\n",
    "    \n",
    "    # Group by trial_id and calculate the mean angles, then rename the aggregated columns.\n",
    "    release_angles = (\n",
    "        release_df.groupby('trial_id')\n",
    "        .agg({\n",
    "            'knee_angle': 'mean',\n",
    "            'wrist_angle': 'mean',\n",
    "            'elbow_angle': 'mean'\n",
    "        })\n",
    "        .rename(columns=new_names)\n",
    "    )\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"[calculate_release_angles] release_angles shape: {release_angles.shape}\")\n",
    "        print(f\"[calculate_release_angles] New columns: {list(release_angles.columns)}\")\n",
    "    \n",
    "    # Merge the release angles back into the original DataFrame.\n",
    "    df = df.merge(release_angles, on='trial_id', how='left')\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"[calculate_release_angles] Final df shape after merge: {df.shape}\")\n",
    "    else:\n",
    "        print(\"[calculate_release_angles] Step completed.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def calculate_optimal_release_angle_ranges(\n",
    "    df: pd.DataFrame,\n",
    "    debug: bool = False,\n",
    "    calc_feedback_range_percentile: float = 10  # single parameter for feedback range\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate initial and filtered optimal angle ranges for knee, wrist, and elbow at the release point.\n",
    "    \n",
    "    For each joint, the function computes the full range from the release data and calculates a symmetric margin:\n",
    "        margin = (orig_max - orig_min) * (calc_feedback_range_percentile / 100) / 2\n",
    "    \n",
    "    The filtered optimal range is then defined as:\n",
    "        filtered_optimal_min = optimal_value - margin\n",
    "        filtered_optimal_max = optimal_value + margin\n",
    "    \n",
    "    These boundaries are later used to classify each shot as 'Early', 'Late', or 'Good'.\n",
    "    \"\"\"\n",
    "    step = \"Optimal Release Angle Ranges\"\n",
    "    # Filter for rows where release_point_filter==1 and result==1.\n",
    "    release_df = df[(df['release_point_filter'] == 1) & (df['result'] == 1)]\n",
    "    if debug:\n",
    "        print(f\"[{step}] Filtered release_df shape: {release_df.shape}\")\n",
    "    else:\n",
    "        print(f\"[{step}] Filtering completed.\")\n",
    "    \n",
    "    # Prepare new columns (initialize as NaN).\n",
    "    new_cols = [\n",
    "        'knee_release_angle_initial_optimal_min', 'knee_release_angle_initial_optimal_max',\n",
    "        'wrist_release_angle_initial_optimal_min', 'wrist_release_angle_initial_optimal_max',\n",
    "        'elbow_release_angle_initial_optimal_min', 'elbow_release_angle_initial_optimal_max'\n",
    "    ]\n",
    "    for col in new_cols:\n",
    "        df[col] = float('nan')\n",
    "    \n",
    "    if not release_df.empty:\n",
    "        # --- Helper: Determine the correct release angle column names for each joint ---\n",
    "        def get_release_col(joint: str) -> str:\n",
    "            # Check for generic name first; if missing, try side-specific names.\n",
    "            generic = f\"release_{joint}_angle\"\n",
    "            right = f\"R_{joint.upper()}_release_angle\"\n",
    "            left = f\"L_{joint.upper()}_release_angle\"\n",
    "            if generic in df.columns:\n",
    "                return generic\n",
    "            elif right in df.columns:\n",
    "                return right\n",
    "            elif left in df.columns:\n",
    "                return left\n",
    "            else:\n",
    "                raise KeyError(f\"No release angle column found for joint: {joint}\")\n",
    "\n",
    "        knee_release_col = get_release_col(\"knee\")\n",
    "        wrist_release_col = get_release_col(\"wrist\")\n",
    "        elbow_release_col = get_release_col(\"elbow\")\n",
    "        \n",
    "        # --- Knee ---\n",
    "        orig_min_knee = release_df['knee_angle'].min()\n",
    "        orig_max_knee = release_df['knee_angle'].max()\n",
    "        full_range_knee = orig_max_knee - orig_min_knee\n",
    "        margin_knee = full_range_knee * (calc_feedback_range_percentile / 100.0) / 2.0\n",
    "        optimal_knee = df[knee_release_col].iloc[0]\n",
    "        knee_filtered_optimal_min = optimal_knee - margin_knee\n",
    "        knee_filtered_optimal_max = optimal_knee + margin_knee\n",
    "\n",
    "        # --- Wrist ---\n",
    "        orig_min_wrist = release_df['wrist_angle'].min()\n",
    "        orig_max_wrist = release_df['wrist_angle'].max()\n",
    "        full_range_wrist = orig_max_wrist - orig_min_wrist\n",
    "        margin_wrist = full_range_wrist * (calc_feedback_range_percentile / 100.0) / 2.0\n",
    "        optimal_wrist = df[wrist_release_col].iloc[0]\n",
    "        wrist_filtered_optimal_min = optimal_wrist - margin_wrist\n",
    "        wrist_filtered_optimal_max = optimal_wrist + margin_wrist\n",
    "\n",
    "        # --- Elbow ---\n",
    "        orig_min_elbow = release_df['elbow_angle'].min()\n",
    "        orig_max_elbow = release_df['elbow_angle'].max()\n",
    "        full_range_elbow = orig_max_elbow - orig_min_elbow\n",
    "        margin_elbow = full_range_elbow * (calc_feedback_range_percentile / 100.0) / 2.0\n",
    "        optimal_elbow = df[elbow_release_col].iloc[0]\n",
    "        elbow_filtered_optimal_min = optimal_elbow - margin_elbow\n",
    "        elbow_filtered_optimal_max = optimal_elbow + margin_elbow\n",
    "\n",
    "        if debug:\n",
    "            print(f\"[{step}] Computed feedback ranges using calc_feedback_range_percentile = {calc_feedback_range_percentile}%:\")\n",
    "            print(f\"         Knee: full_range={full_range_knee:.2f}, margin={margin_knee:.2f}, range=[{knee_filtered_optimal_min:.2f}, {knee_filtered_optimal_max:.2f}]\")\n",
    "            print(f\"         Wrist: full_range={full_range_wrist:.2f}, margin={margin_wrist:.2f}, range=[{wrist_filtered_optimal_min:.2f}, {wrist_filtered_optimal_max:.2f}]\")\n",
    "            print(f\"         Elbow: full_range={full_range_elbow:.2f}, margin={margin_elbow:.2f}, range=[{elbow_filtered_optimal_min:.2f}, {elbow_filtered_optimal_max:.2f}]\")\n",
    "        \n",
    "        # Save the computed optimal ranges.\n",
    "        df['knee_release_angle_filtered_optimal_min'] = knee_filtered_optimal_min\n",
    "        df['knee_release_angle_filtered_optimal_max'] = knee_filtered_optimal_max\n",
    "        df['wrist_release_angle_filtered_optimal_min'] = wrist_filtered_optimal_min\n",
    "        df['wrist_release_angle_filtered_optimal_max'] = wrist_filtered_optimal_max\n",
    "        df['elbow_release_angle_filtered_optimal_min'] = elbow_filtered_optimal_min\n",
    "        df['elbow_release_angle_filtered_optimal_max'] = elbow_filtered_optimal_max\n",
    "\n",
    "        # Define a helper function for classification.\n",
    "        def classify_joint(angle_value, min_val, max_val):\n",
    "            if angle_value < min_val:\n",
    "                return \"Early\"\n",
    "            elif angle_value > max_val:\n",
    "                return \"Late\"\n",
    "            else:\n",
    "                return \"Good\"\n",
    "\n",
    "        # Classify shots for each joint.\n",
    "        for joint, release_col in zip(\n",
    "            ['knee', 'wrist', 'elbow'],\n",
    "            [knee_release_col, wrist_release_col, elbow_release_col]\n",
    "        ):\n",
    "            optimal_min_col = f\"{joint}_release_angle_filtered_optimal_min\"\n",
    "            optimal_max_col = f\"{joint}_release_angle_filtered_optimal_max\"\n",
    "            classification_col = f\"{joint}_release_angle_shot_classification\"\n",
    "            df[classification_col] = df.apply(\n",
    "                lambda row: classify_joint(row[release_col], row[optimal_min_col], row[optimal_max_col]),\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "    else:\n",
    "        if debug:\n",
    "            print(f\"[{step}] No rows found with release_point_filter==1 and result==1.\")\n",
    "        else:\n",
    "            print(f\"[{step}] No valid rows; step completed.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_optimal_max_angle_ranges(\n",
    "    df: pd.DataFrame,\n",
    "    output_dir: str,\n",
    "    output_filename: str = \"final_granular_logistic_optimized_meter_dataset.csv\",\n",
    "    handedness: str = \"R\",  # New parameter to select side\n",
    "    debug: bool = False,\n",
    "    calc_feedback_range_percentile: float = 10\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculates optimal max angle ranges (for wrist, elbow, and knee) during active shooting motion.\n",
    "    For right-handed shots, uses right-side columns; for left-handed, uses left-side columns.\n",
    "    \n",
    "    The function:\n",
    "      - Selects the correct angle columns based on handedness.\n",
    "      - Filters for shooting motion rows.\n",
    "      - Computes the maximum angles per trial.\n",
    "      - Renames the columns to include a handedness prefix (e.g. \"R_WRIST_max_angle\").\n",
    "      - Computes symmetric feedback ranges based on a single percentile.\n",
    "      - Classifies each shot based on whether the angle is below, above, or within the computed range.\n",
    "    \"\"\"\n",
    "    step = \"Optimal Max Angle Ranges\"\n",
    "    \n",
    "    # Validate handedness parameter\n",
    "    if handedness not in ['R', 'L']:\n",
    "        raise ValueError(\"Handedness must be 'R' for right-handed or 'L' for left-handed.\")\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"[{step}] Calculating max angles for {handedness}-handed shots.\")\n",
    "        print(f\"[{step}] Initial df shape: {df.shape}\")\n",
    "    \n",
    "    # Select the appropriate columns based on handedness and assign a prefix.\n",
    "    if handedness == 'R':\n",
    "        df['knee_angle'] = df['R_KNEE_angle']\n",
    "        df['wrist_angle'] = df['R_WRIST_angle']\n",
    "        df['elbow_angle'] = df['R_ELBOW_angle']\n",
    "        prefix = 'R_'\n",
    "    else:\n",
    "        df['knee_angle'] = df['L_KNEE_angle']\n",
    "        df['wrist_angle'] = df['L_WRIST_angle']\n",
    "        df['elbow_angle'] = df['L_ELBOW_angle']\n",
    "        prefix = 'L_'\n",
    "    \n",
    "    # Filter the DataFrame for rows where shooting motion is active.\n",
    "    motion_df = df[df['shooting_motion'] == 1]\n",
    "    if debug:\n",
    "        print(f\"[{step}] Motion df shape: {motion_df.shape}\")\n",
    "    \n",
    "    # Calculate the maximum angles for each trial.\n",
    "    max_angles_per_trial = (\n",
    "        motion_df.groupby('trial_id')\n",
    "        .agg({'wrist_angle': 'max', 'elbow_angle': 'max', 'knee_angle': 'max'})\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    # Rename the aggregated columns to include the handedness prefix.\n",
    "    max_angles_per_trial.rename(columns={\n",
    "        'wrist_angle': f'{prefix}WRIST_max_angle',\n",
    "        'elbow_angle': f'{prefix}ELBOW_max_angle',\n",
    "        'knee_angle': f'{prefix}KNEE_max_angle'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"[{step}] Max angles columns after renaming: {max_angles_per_trial.columns.tolist()}\")\n",
    "    \n",
    "    # Merge the max angle values back into the motion data.\n",
    "    merged_df = motion_df.merge(max_angles_per_trial, on='trial_id', how='left')\n",
    "    \n",
    "    # Mark rows where the angle equals the computed max (for potential later use).\n",
    "    merged_df['is_wrist_max_angle'] = (merged_df['wrist_angle'] == merged_df[f'{prefix}WRIST_max_angle']).astype(int)\n",
    "    merged_df['is_elbow_max_angle'] = (merged_df['elbow_angle'] == merged_df[f'{prefix}ELBOW_max_angle']).astype(int)\n",
    "    merged_df['is_knee_max_angle'] = (merged_df['knee_angle'] == merged_df[f'{prefix}KNEE_max_angle']).astype(int)\n",
    "    \n",
    "    # Filter for successful shots.\n",
    "    successful_shots_df = merged_df[merged_df['result'] == 1]\n",
    "    if debug:\n",
    "        print(f\"[{step}] Successful shots df shape: {successful_shots_df.shape}\")\n",
    "    \n",
    "    # Dictionary to store computed optimal ranges for each joint.\n",
    "    stats = {}\n",
    "    for joint in ['WRIST', 'ELBOW', 'KNEE']:\n",
    "        angle_col = f\"{prefix}{joint}_max_angle\"\n",
    "        \n",
    "        # Check if the expected column exists.\n",
    "        if angle_col not in successful_shots_df.columns:\n",
    "            if debug:\n",
    "                print(f\"[{step}] Warning: Column {angle_col} not found in successful_shots_df\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate the full range and derive the symmetric margin.\n",
    "        orig_min = successful_shots_df[angle_col].min()\n",
    "        orig_max = successful_shots_df[angle_col].max()\n",
    "        full_range = orig_max - orig_min\n",
    "        feedback_diff = full_range * (calc_feedback_range_percentile / 100.0)\n",
    "        margin = feedback_diff / 2.0\n",
    "        optimal_value = successful_shots_df[angle_col].mean()\n",
    "        filtered_optimal_min = optimal_value - margin\n",
    "        filtered_optimal_max = optimal_value + margin\n",
    "        \n",
    "        # Save the computed optimal range for this joint.\n",
    "        stats[f\"{angle_col}_filtered_optimal_min\"] = filtered_optimal_min\n",
    "        stats[f\"{angle_col}_filtered_optimal_max\"] = filtered_optimal_max\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"[{step}] For {angle_col}: full_range={full_range:.2f}, margin={margin:.2f}, range=[{filtered_optimal_min:.2f}, {filtered_optimal_max:.2f}]\")\n",
    "    \n",
    "    # Insert the computed stats as constant columns in the merged DataFrame.\n",
    "    for key, value in stats.items():\n",
    "        merged_df[key] = value\n",
    "    \n",
    "    # Define a helper function to classify the joint angle.\n",
    "    def classify_joint(angle_value, min_val, max_val):\n",
    "        if angle_value < min_val:\n",
    "            return \"Early\"\n",
    "        elif angle_value > max_val:\n",
    "            return \"Late\"\n",
    "        else:\n",
    "            return \"Good\"\n",
    "    \n",
    "    # Apply classification to each joint using the computed optimal ranges.\n",
    "    for joint in ['WRIST', 'ELBOW', 'KNEE']:\n",
    "        angle_col = f\"{prefix}{joint}_max_angle\"\n",
    "        classification_col = f\"{angle_col}_shot_classification\"\n",
    "        min_col = f\"{angle_col}_filtered_optimal_min\"\n",
    "        max_col = f\"{angle_col}_filtered_optimal_max\"\n",
    "        \n",
    "        # Only classify if the stats were computed.\n",
    "        if min_col not in stats or max_col not in stats:\n",
    "            continue\n",
    "        \n",
    "        merged_df[classification_col] = merged_df.apply(\n",
    "            lambda row: classify_joint(row[angle_col], stats[min_col], stats[max_col]),\n",
    "            axis=1\n",
    "        )\n",
    "    \n",
    "    # Save the updated DataFrame to CSV (useful for inspection).\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    merged_df.to_csv(output_path, index=False)\n",
    "    if debug:\n",
    "        print(f\"[{step}] Updated dataset saved to {output_path}\")\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_features_from_pickle(pickle_path: str, y_variable: str = 'result') -> List[str]:\n",
    "    \"\"\"\n",
    "    Load features from a pickle file (list or DataFrame) and remove the y variable.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if pickle_path.startswith('http://') or pickle_path.startswith('https://'):\n",
    "            response = requests.get(pickle_path)\n",
    "            response.raise_for_status()\n",
    "            pickle_file = BytesIO(response.content)\n",
    "            features_data = pickle.load(pickle_file)\n",
    "        else:\n",
    "            with open(pickle_path, 'rb') as f:\n",
    "                features_data = pickle.load(f)\n",
    "        if isinstance(features_data, pd.DataFrame):\n",
    "            features = list(features_data.columns)\n",
    "        elif isinstance(features_data, list):\n",
    "            features = features_data\n",
    "        else:\n",
    "            raise ValueError(\"Pickle file must contain a list or a DataFrame of features.\")\n",
    "        if y_variable in features:\n",
    "            features.remove(y_variable)\n",
    "        logger.debug(f\"[load_features_from_pickle] Loaded features: {features}\")\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        logger.error(f\"[load_features_from_pickle] Error: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def load_precalculated_bayesian_metrics(\n",
    "    bayesian_metrics_file_path: str,\n",
    "    debug: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load precalculated bayesian metrics from a CSV file and rename the columns.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if debug:\n",
    "            logger.debug(f\"[load_precalculated_bayesian_metrics] Loading from {bayesian_metrics_file_path}...\")\n",
    "        df = pd.read_csv(bayesian_metrics_file_path)\n",
    "        required_columns = [\n",
    "            \"Parameter\",\n",
    "            \"Optimized (Candidate, Real)\",\n",
    "            \"Baseline (Real)\",\n",
    "            \"Min (Real)\",\n",
    "            \"Max (Real)\",\n",
    "            \"Success Rate (Baseline)\",\n",
    "            \"Success Rate (Candidate)\"\n",
    "        ]\n",
    "        df = df[required_columns]\n",
    "        df.rename(\n",
    "            columns={\n",
    "                \"Optimized (Candidate, Real)\": \"bayes_optimized\",\n",
    "                \"Baseline (Real)\": \"baseline\",\n",
    "                \"Min (Real)\": \"bayes_min\",\n",
    "                \"Max (Real)\": \"bayes_max\",\n",
    "                \"Success Rate (Baseline)\": \"baseline_success_rate\",\n",
    "                \"Success Rate (Candidate)\": \"bayes_success_rate\"\n",
    "            },\n",
    "            inplace=True\n",
    "        )\n",
    "        if debug:\n",
    "            logger.debug(f\"[load_precalculated_bayesian_metrics] DataFrame shape: {df.shape}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"[load_precalculated_bayesian_metrics] Error: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def add_bayesian_ranges_to_ml_dataset(\n",
    "    bayesian_metrics_data: pd.DataFrame,\n",
    "    final_ml_data_path: str,\n",
    "    output_dir: str,\n",
    "    bayes_min_max_range_percentile: float,       # new parameter, e.g., 10 for 10%\n",
    "    output_filename: str = \"ml_dataset_with_bayesian_metrics.csv\",\n",
    "    debug: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Append precalculated bayesian metrics (optimized, min, max) to the final ML dataset.\n",
    "\n",
    "    In this updated version, instead of basing bayes_min and bayes_max on quantiles\n",
    "    of the metric values, we use the full original range of the metric (bayes_orig_min and bayes_orig_max)\n",
    "    to determine a symmetric range. We calculate the difference as:\n",
    "    \n",
    "        bayes_min_max_diff = (bayes_orig_max - bayes_orig_min) * (bayes_min_max_range_percentile / 100)\n",
    "    \n",
    "    and define the margin as half of that difference. The bayesian range is then defined as:\n",
    "    \n",
    "        bayes_min = bayes_optimized - margin\n",
    "        bayes_max = bayes_optimized + margin\n",
    "    \n",
    "    Additionally, we add a constraint so that bayes_min cannot be lower than bayes_orig_min and\n",
    "    bayes_max cannot be higher than bayes_orig_max.\n",
    "    \n",
    "    The original min and max values are stored as bayes_orig_min and bayes_orig_max.\n",
    "    \"\"\"\n",
    "    step = \"Add Bayesian Ranges to ML Dataset\"\n",
    "    try:\n",
    "        # Map metric name (lowercase) to its bayes_optimized value.\n",
    "        opt_dict = pd.Series(\n",
    "            bayesian_metrics_data['bayes_optimized'].values,\n",
    "            index=bayesian_metrics_data['Parameter']\n",
    "        ).to_dict()\n",
    "        \n",
    "        if debug:\n",
    "            logger.debug(f\"[{step}] Loading final ML dataset from {final_ml_data_path}...\")\n",
    "        final_ml_data = pd.read_csv(final_ml_data_path)\n",
    "        \n",
    "        for metric, opt_value in opt_dict.items():\n",
    "            optimized_col = f\"{metric}_bayes_optimized\"\n",
    "            # Add the bayes_optimized value as a new column.\n",
    "            final_ml_data[optimized_col] = opt_value\n",
    "            if debug:\n",
    "                logger.debug(f\"[{step}] Added column '{optimized_col}' with value: {opt_value}\")\n",
    "            \n",
    "            if metric in final_ml_data.columns:\n",
    "                # Retrieve bayes_optimized value (assumed constant).\n",
    "                bayes_opt_val = final_ml_data[optimized_col].iloc[0]\n",
    "                \n",
    "                # Obtain the original full range of the metric.\n",
    "                orig_min = final_ml_data[metric].min()\n",
    "                orig_max = final_ml_data[metric].max()\n",
    "                full_range = orig_max - orig_min\n",
    "                \n",
    "                # Compute the bayes_min_max difference based on the new parameter.\n",
    "                bayes_min_max_diff = full_range * (bayes_min_max_range_percentile / 100.0)\n",
    "                # The margin is half of that difference.\n",
    "                margin = bayes_min_max_diff / 2.0\n",
    "                \n",
    "                # Define the new bayesian range centered on bayes_opt_val.\n",
    "                new_min = bayes_opt_val - margin\n",
    "                new_max = bayes_opt_val + margin\n",
    "                \n",
    "                # Constrain the range so it does not exceed the original bounds.\n",
    "                if new_min < orig_min:\n",
    "                    new_min = orig_min\n",
    "                if new_max > orig_max:\n",
    "                    new_max = orig_max\n",
    "                \n",
    "                # Save the computed bayesian range.\n",
    "                final_ml_data[f\"{metric}_bayes_min\"] = new_min\n",
    "                final_ml_data[f\"{metric}_bayes_max\"] = new_max\n",
    "                if debug:\n",
    "                    logger.debug(f\"[{step}] For metric '{metric}':\")\n",
    "                    logger.debug(f\"         bayes_opt_val: {bayes_opt_val}\")\n",
    "                    logger.debug(f\"         orig_min: {orig_min}, orig_max: {orig_max} (full_range: {full_range})\")\n",
    "                    logger.debug(f\"         bayes_min_max_diff (full_range * {bayes_min_max_range_percentile}%): {bayes_min_max_diff}\")\n",
    "                    logger.debug(f\"         margin (each side): {margin}\")\n",
    "                    logger.debug(f\"         Set bayes_min: {new_min}, bayes_max: {new_max}\")\n",
    "                \n",
    "                # Also store the original min and max values.\n",
    "                final_ml_data[f\"{metric}_bayes_orig_min\"] = orig_min\n",
    "                final_ml_data[f\"{metric}_bayes_orig_max\"] = orig_max\n",
    "            else:\n",
    "                if debug:\n",
    "                    logger.warning(f\"[{step}] Base metric column '{metric}' not found in final ML data; skipping bayesian range computation.\")\n",
    "        \n",
    "        # Round numeric columns.\n",
    "        final_ml_data = round_numeric_columns(final_ml_data, decimals=2)\n",
    "        \n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        final_ml_data.to_csv(output_path, index=False)\n",
    "        if debug:\n",
    "            logger.debug(f\"[{step}] Updated ML dataset saved to {output_path}\")\n",
    "        else:\n",
    "            print(f\"[{step}] Step completed.\")\n",
    "        return final_ml_data\n",
    "    except Exception as e:\n",
    "        logger.error(f\"[{step}] Error: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def classify_metrics(\n",
    "    final_ml_data: pd.DataFrame,\n",
    "    bayesian_metrics: List[str],\n",
    "    output_dir: str,\n",
    "    output_filename: str = \"classified_ml_dataset.csv\",\n",
    "    debug: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Classify each bayesian metric in the ML dataset as 'Early', 'Late', or 'Good'\n",
    "    based on the corresponding bayesian min/max values.\n",
    "    \n",
    "    This updated version accumulates new columns in a dictionary and then concatenates\n",
    "    them all at once to reduce DataFrame fragmentation.\n",
    "    \"\"\"\n",
    "    step = \"Classify Metrics\"\n",
    "    try:\n",
    "        # Create a dictionary to hold all new columns for batch addition.\n",
    "        new_cols = {}\n",
    "        \n",
    "        # Loop over each metric and compute the required new columns.\n",
    "        for metric in bayesian_metrics:\n",
    "            base_metric_col = metric\n",
    "            bayes_min_col = f\"{metric}_bayes_min\"\n",
    "            bayes_max_col = f\"{metric}_bayes_max\"\n",
    "            classification_col = f\"{metric}_bayes_classification\"\n",
    "            \n",
    "            # Skip metric if required bayesian range columns are missing.\n",
    "            if bayes_min_col not in final_ml_data.columns or bayes_max_col not in final_ml_data.columns:\n",
    "                if debug:\n",
    "                    logger.warning(f\"[{step}] Bayesian range columns for '{metric}' not found. Skipping classification.\")\n",
    "                continue\n",
    "            \n",
    "            # Compute the classification column using np.select.\n",
    "            new_cols[classification_col] = np.select(\n",
    "                [\n",
    "                    final_ml_data[base_metric_col] < final_ml_data[bayes_min_col],\n",
    "                    final_ml_data[base_metric_col] > final_ml_data[bayes_max_col]\n",
    "                ],\n",
    "                ['Early', 'Late'],\n",
    "                default='Good'\n",
    "            )\n",
    "            \n",
    "            # Compute the unit change column if the bayes optimized column exists.\n",
    "            bayes_optimized_col = f\"{metric}_bayes_optimized\"\n",
    "            if bayes_optimized_col in final_ml_data.columns:\n",
    "                new_cols[f\"{metric}_bayes_unit_change\"] = final_ml_data[base_metric_col] - final_ml_data[bayes_optimized_col]\n",
    "                if debug:\n",
    "                    logger.debug(f\"[{step}] Prepared column '{metric}_bayes_unit_change' computed as {base_metric_col} - {bayes_optimized_col}.\")\n",
    "            else:\n",
    "                if debug:\n",
    "                    logger.warning(f\"[{step}] Bayes optimized column '{bayes_optimized_col}' not found for metric '{metric}'.\")\n",
    "        \n",
    "        # After processing all metrics, create a DataFrame from the new columns dictionary.\n",
    "        new_cols_df = pd.DataFrame(new_cols, index=final_ml_data.index)\n",
    "        \n",
    "        # Concatenate the new columns with the original DataFrame.\n",
    "        final_ml_data = pd.concat([final_ml_data, new_cols_df], axis=1)\n",
    "        \n",
    "        # Use copy() to defragment the DataFrame.\n",
    "        final_ml_data = final_ml_data.copy()\n",
    "        \n",
    "        if debug:\n",
    "            logger.debug(f\"[{step}] Classification and bayesian unit change computation completed for all metrics.\")\n",
    "        \n",
    "        # Round numeric columns as before.\n",
    "        final_ml_data = round_numeric_columns(final_ml_data, decimals=2)\n",
    "        \n",
    "        # Save the updated dataset.\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        final_ml_data.to_csv(output_path, index=False)\n",
    "        if debug:\n",
    "            logger.debug(f\"[{step}] Classified dataset saved to {output_path}\")\n",
    "        else:\n",
    "            print(f\"[{step}] Step completed.\")\n",
    "        \n",
    "        return final_ml_data\n",
    "    except Exception as e:\n",
    "        logger.error(f\"[{step}] Error: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "\n",
    "def merge_bayes_metrics_with_granular_data(\n",
    "    granular_df: pd.DataFrame,\n",
    "    ml_df: pd.DataFrame,\n",
    "    bayesian_metrics: List[str],\n",
    "    output_dir: str,\n",
    "    output_filename: str = \"bayesian_shot_meter_granular_dataset.csv\",\n",
    "    debug: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merge the ML dataset (with bayesian metrics) with the granular dataset on 'trial_id'.\n",
    "    \"\"\"\n",
    "    step = \"Merge Bayesian Metrics with Granular Data\"\n",
    "    try:\n",
    "        if debug:\n",
    "            logger.debug(f\"[{step}] Granular df trial_id count: {granular_df['trial_id'].nunique()}\")\n",
    "            logger.debug(f\"[{step}] ML df trial_id count: {ml_df['trial_id'].nunique()}\")\n",
    "            logger.debug(f\"[{step}] Performing left join on 'trial_id'...\")\n",
    "        merged_dataset = granular_df.merge(ml_df, on='trial_id', how='left', suffixes=('', '_meter'))\n",
    "        merged_dataset = round_numeric_columns(merged_dataset, decimals=2)\n",
    "        \n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        merged_dataset.to_csv(output_path, index=False)\n",
    "        if debug:\n",
    "            logger.debug(f\"[{step}] Merged dataset shape: {merged_dataset.shape}\")\n",
    "            logger.debug(f\"[{step}] Merged dataset saved to {output_path}\")\n",
    "        else:\n",
    "            print(f\"[{step}] Step completed.\")\n",
    "        return merged_dataset\n",
    "    except Exception as e:\n",
    "        logger.error(f\"[{step}] Error: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def bayesian_optimized_granular_data_main(\n",
    "    bayesian_metrics_file_path: str = \"../../data/predictions/bayesian_optimization_results/bayesian_optimization_results.csv\",\n",
    "    final_ml_file_path: str = \"../../data/processed/final_ml_dataset.csv\",\n",
    "    final_ml_with_predictions_path: str = \"../../data/model/predictions/final_dataset_with_predictions_and_shap.csv\",\n",
    "    final_granular_file_path: str = \"../../data/processed/final_granular_dataset.csv\",\n",
    "    pickle_path: str = \"../../data/preprocessor/features_info/final_ml_df_selected_features_columns.pkl\",\n",
    "    y_variable: str = \"result\",\n",
    "    output_dir: str = \"../../data/model/shot_meter_docs/\",\n",
    "    debug: bool = False,\n",
    "    bayes_min_max_range_percentile: float = 10, \n",
    "    output_filename: str = \"bayesian_shot_meter_granular_dataset.csv\"\n",
    ") -> Tuple[pd.DataFrame, Dict[str, Dict[str, float]]]:\n",
    "    \"\"\"\n",
    "    Main function for bayesian optimization processing. Loads feature names,\n",
    "    bayesian metrics, adds these metrics to the ML dataset (with new bayesian min/max computed using the provided percentiles),\n",
    "    performs classification, and finally merges with the granular dataset.\n",
    "    \"\"\"\n",
    "    step = \"Bayesian Optimized Granular Data Main\"\n",
    "    try:\n",
    "        if debug:\n",
    "            logger.debug(f\"[{step}] Starting main function.\")\n",
    "\n",
    "        # Step 0: Load feature names from pickle\n",
    "        if debug:\n",
    "            logger.debug(f\"[{step}] Loading feature names from: {pickle_path}\")\n",
    "        bayesian_metrics = load_features_from_pickle(pickle_path=pickle_path, y_variable=y_variable)\n",
    "        if debug:\n",
    "            logger.debug(f\"[{step}] Loaded bayesian metrics: {bayesian_metrics}\")\n",
    "\n",
    "        # Step 1: Load precalculated bayesian metrics table\n",
    "        combined_data = load_precalculated_bayesian_metrics(\n",
    "            bayesian_metrics_file_path=bayesian_metrics_file_path,\n",
    "            debug=debug\n",
    "        )\n",
    "\n",
    "        # Step 2: Add bayesian ranges to the ML dataset.\n",
    "        final_ml_bayes_df = add_bayesian_ranges_to_ml_dataset(\n",
    "            bayesian_metrics_data=combined_data,\n",
    "            final_ml_data_path=final_ml_with_predictions_path,\n",
    "            output_dir=output_dir,\n",
    "            bayes_min_max_range_percentile=bayes_min_max_range_percentile,\n",
    "            debug=debug\n",
    "        )\n",
    "\n",
    "        # Step 3: Classify metrics in the ML dataset\n",
    "        final_ml_bayes_df = classify_metrics(\n",
    "            final_ml_data=final_ml_bayes_df,\n",
    "            bayesian_metrics=bayesian_metrics,\n",
    "            output_dir=output_dir,\n",
    "            debug=debug\n",
    "        )\n",
    "\n",
    "        # (Optional) Debug: Load original ML dataset to check columns\n",
    "        final_ml_data = pd.read_csv(final_ml_with_predictions_path)\n",
    "        if debug:\n",
    "            logger.debug(f\"[{step}] Final ML dataset columns: {final_ml_data.columns.to_list()}\")\n",
    "\n",
    "        # Step 4: Merge the ML dataset with the granular dataset\n",
    "        granular_df = pd.read_csv(final_granular_file_path)\n",
    "        merged_data = merge_bayes_metrics_with_granular_data(\n",
    "            granular_df=granular_df,\n",
    "            ml_df=final_ml_bayes_df,\n",
    "            bayesian_metrics=bayesian_metrics,\n",
    "            output_dir=output_dir,\n",
    "            debug=debug,\n",
    "            output_filename=output_filename\n",
    "        )\n",
    "\n",
    "        # Step 5: Build the bayesian_metrics_dict for downstream use\n",
    "        bayesian_metrics_dict = {}\n",
    "        for metric in bayesian_metrics:\n",
    "            optimized_metric_col = f\"{metric}_bayes_optimized\"\n",
    "            bayes_classification_col = f\"{metric}_bayes_classification\"\n",
    "            shap_importance_col = f\"shap_{metric}_importance\"\n",
    "            min_col = f\"{metric}_bayes_min\"\n",
    "            max_col = f\"{metric}_bayes_max\"\n",
    "            orig_min_col = f\"{metric}_bayes_orig_min\"\n",
    "            orig_max_col = f\"{metric}_bayes_orig_max\"\n",
    "            # Check that both the optimized and the base metric column exist\n",
    "            if optimized_metric_col in merged_data.columns and metric in merged_data.columns:\n",
    "                bayesian_metrics_dict[metric] = {\n",
    "                    'bayes_optimal': merged_data.at[0, optimized_metric_col],\n",
    "                    'bayes_original': merged_data.at[0, metric],\n",
    "                    'bayes_min': merged_data.at[0, min_col] if min_col in merged_data.columns else None,\n",
    "                    'bayes_max': merged_data.at[0, max_col] if max_col in merged_data.columns else None,\n",
    "                    'bayes_orig_min': merged_data.at[0, orig_min_col] if orig_min_col in merged_data.columns else None,\n",
    "                    'bayes_orig_max': merged_data.at[0, orig_max_col] if orig_max_col in merged_data.columns else None,\n",
    "                    'bayes_classification': merged_data.at[0, bayes_classification_col] if bayes_classification_col in merged_data.columns else \"Good\",\n",
    "                    'shap_importance': merged_data.at[0, shap_importance_col] if shap_importance_col in merged_data.columns else None\n",
    "                }\n",
    "            else:\n",
    "                if debug:\n",
    "                    logger.warning(f\"[{step}] Skipping metric '{metric}' because required columns are missing (base: '{metric}' and/or optimized: '{optimized_metric_col}').\")\n",
    "        no_change_list = [\"calculated_release_angle\", \"release_angle\"]\n",
    "        for metric, values in bayesian_metrics_dict.items():\n",
    "            filter_name = metric if metric in no_change_list else metric.replace(\"release_\", \"\").replace(\"_max\", \"\")\n",
    "            bayesian_metrics_dict[metric]['filter_name'] = filter_name\n",
    "\n",
    "        for metric in bayesian_metrics_dict.keys():\n",
    "            shap_direction_col = f\"shap_{metric}_direction\"\n",
    "            if shap_direction_col in merged_data.columns:\n",
    "                bayesian_metrics_dict[metric]['shap_direction'] = merged_data.at[0, shap_direction_col]\n",
    "                if debug:\n",
    "                    logger.debug(f\"[{step}] Extracted '{shap_direction_col}': {merged_data.at[0, shap_direction_col]}\")\n",
    "            else:\n",
    "                if debug:\n",
    "                    logger.warning(f\"[{step}] Missing shap_direction column '{shap_direction_col}' for metric '{metric}'.\")\n",
    "                bayesian_metrics_dict[metric]['shap_direction'] = None\n",
    "\n",
    "\n",
    "        if debug:\n",
    "            logger.debug(f\"[{step}] Bayesian Metrics Dictionary:\\n{json.dumps(bayesian_metrics_dict, indent=4)}\")\n",
    "\n",
    "        bayesian_metrics_output_path = os.path.join(output_dir, \"bayesian_metrics_dict.json\")\n",
    "        with open(bayesian_metrics_output_path, 'w') as f:\n",
    "            json.dump(bayesian_metrics_dict, f, indent=4)\n",
    "        if debug:\n",
    "            logger.debug(f\"[{step}] Bayesian metrics dictionary saved to {bayesian_metrics_output_path}\")\n",
    "        else:\n",
    "            print(f\"[{step}] Step completed.\")\n",
    "\n",
    "        return merged_data, bayesian_metrics_dict\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"[{step}] Error: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "\n",
    "def automated_bayes_shap_summary(\n",
    "    granular_data_path: str,\n",
    "    release_angles_output_dir: str,\n",
    "    max_angles_output_dir: str,\n",
    "    bayesian_metrics_file_path: str,\n",
    "    final_ml_file_path: str,\n",
    "    final_ml_with_predictions_path: str,\n",
    "    pickle_path: str,\n",
    "    y_variable: str,\n",
    "    bayes_min_max_range_percentile: float,\n",
    "    calc_feedback_range_percentile: float,\n",
    "    output_dir: str,\n",
    "    output_filename: str,\n",
    "    debug: bool = False,\n",
    "    # New parameters for reloading SHAP predictions:\n",
    "    reload_shap_data: bool = False,\n",
    "    new_shap_min_max_percentile: Optional[float] = None,\n",
    "    config: Optional[\"AppConfig\"] = None,  # Make sure to import AppConfig from your config module\n",
    "    streamlit_app_paths: bool = False\n",
    ") -> Tuple[pd.DataFrame, Dict[str, Dict[str, float]], Dict[str, Dict[str, int]]]:\n",
    "    \"\"\"\n",
    "    Automated summary function that runs the entire data merging and bayesian metrics\n",
    "    processing pipeline. It:\n",
    "      1. Loads the granular dataset.\n",
    "      2. Calculates release angles and optimal release angle ranges using the specified feedback range.\n",
    "      3. Saves an intermediate dataset (optional).\n",
    "      4. Calculates optimal max angle ranges using the specified feedback range.\n",
    "      5. Optionally reloads the SHAP predictions (via predict_and_shap) using a new metrics_percentile.\n",
    "      6. Runs the bayesian optimization merging and classification.\n",
    "      7. Summarizes the bayesian classification results (counts of 'Good', 'Early', 'Late')\n",
    "         for each metric.\n",
    "    \n",
    "    New Parameters:\n",
    "      - reload_shap_data: If True, re-run the predict_and_shap module to recalculate SHAP columns.\n",
    "      - new_shap_min_max_percentile: If provided (and reload_shap_data is True), use this percentile when\n",
    "          recalculating SHAP feedback.\n",
    "      - config: An AppConfig object required to run predict_and_shap. If not provided, you must load it before calling.\n",
    "    \n",
    "    Returns:\n",
    "      A tuple containing:\n",
    "        - The final merged DataFrame.\n",
    "        - The bayesian metrics dictionary.\n",
    "        - A summary dictionary with counts for each bayes_classification per metric.\n",
    "    \"\"\"\n",
    "    # 1. Load granular dataset\n",
    "    if debug:\n",
    "        print(\"[automated_bayes_shap_summary] Loading granular dataset...\")\n",
    "    df_granular = pd.read_csv(granular_data_path)\n",
    "    \n",
    "    # 2. Calculate release angles and optimal release angle ranges.\n",
    "    if debug:\n",
    "        print(\"[automated_bayes_shap_summary] Calculating release angles...\")\n",
    "    df_granular = calculate_release_angles(df_granular, debug=debug)\n",
    "    if debug:\n",
    "        print(\"[automated_bayes_shap_summary] Calculating optimal release angle ranges...\")\n",
    "    df_granular = calculate_optimal_release_angle_ranges(\n",
    "        df_granular,\n",
    "        debug=debug,\n",
    "        calc_feedback_range_percentile=calc_feedback_range_percentile\n",
    "    )\n",
    "    # Optionally save the intermediate release angles dataset.\n",
    "    release_angles_output_path = os.path.join(release_angles_output_dir, \"granular_with_release_angles.csv\")\n",
    "    df_granular.to_csv(release_angles_output_path, index=False)\n",
    "    if debug:\n",
    "        print(f\"[automated_bayes_shap_summary] Granular dataset with release angles saved to {release_angles_output_path}\")\n",
    "    \n",
    "    # 3. Calculate optimal max angle ranges.\n",
    "    if debug:\n",
    "        print(\"[automated_bayes_shap_summary] Calculating optimal max angle ranges...\")\n",
    "    max_angles_output_filename = \"final_granular_logistic_optimized_meter_dataset.csv\"\n",
    "    df_granular = calculate_optimal_max_angle_ranges(\n",
    "        df_granular,\n",
    "        output_dir=max_angles_output_dir,\n",
    "        output_filename=max_angles_output_filename,\n",
    "        debug=debug,\n",
    "        calc_feedback_range_percentile=calc_feedback_range_percentile\n",
    "    )\n",
    "    \n",
    "    # 4. Optionally, if requested, reload the SHAP predictions with an updated percentile.\n",
    "    #    This re-runs the predict_and_shap module so that the final ML dataset (with SHAP columns)\n",
    "    #    reflects the new metrics_percentile.\n",
    "    if reload_shap_data:\n",
    "        if config is None:\n",
    "            raise ValueError(\"To reload SHAP data, you must provide a valid AppConfig via the 'config' parameter.\")\n",
    "        # Use the new_shap_min_max_percentile if provided; otherwise, default to the original one.\n",
    "        reload_percentile = new_shap_min_max_percentile if new_shap_min_max_percentile is not None else 10.0\n",
    "        if debug:\n",
    "            print(f\"[automated_bayes_shap_summary] Reloading SHAP data with metrics_percentile = {reload_percentile}\")\n",
    "        # Here we assume that the raw data for prediction is available.\n",
    "        # For example, you might reload the raw dataset (or use the one already processed).\n",
    "        # In this example, we assume raw data is available at granular_data_path (adjust if needed).\n",
    "        df_predict = pd.read_csv(final_ml_file_path)\n",
    "        \n",
    "        if streamlit_app_paths:\n",
    "            ordinal_file=Path('data/preprocessor/features_info/ordinal_categoricals.pkl')\n",
    "            nominal_file=Path('data/preprocessor/features_info/nominal_categoricals.pkl')\n",
    "            numericals_file=Path('data/preprocessor/features_info/numericals.pkl')\n",
    "            y_variable_file=Path('data/preprocessor/features_info/y_variable.pkl')\n",
    "        else:\n",
    "            ordinal_file=Path('../../data/preprocessor/features_info/ordinal_categoricals.pkl')\n",
    "            nominal_file=Path('../../data/preprocessor/features_info/nominal_categoricals.pkl')\n",
    "            numericals_file=Path('../../data/preprocessor/features_info/numericals.pkl')\n",
    "            y_variable_file=Path('../../data/preprocessor/features_info/y_variable.pkl')\n",
    "        # We choose a temporary output directory for the reloaded SHAP data.\n",
    "        predictions_output_path = Path(config.paths.predictions_output_dir).resolve() / \"shap_results\"\n",
    "        model_output_dir = predictions_output_path \n",
    "        shap_results = predict_and_shap(\n",
    "            config=config,\n",
    "            df_input=df_predict,\n",
    "            save_dir=model_output_dir,\n",
    "            columns_to_add=['trial_id'],\n",
    "            generate_summary_plot=True,\n",
    "            generate_dependence_plots=True,\n",
    "            generate_force_plots=True,\n",
    "            force_plot_indices=[0],\n",
    "            top_n_features=10,\n",
    "            use_mad=False,\n",
    "            logger=logger,\n",
    "            features_file=(Path(config.paths.data_dir) / config.paths.features_metadata_file).resolve(),\n",
    "            ordinal_file=ordinal_file,\n",
    "            nominal_file=nominal_file,\n",
    "            numericals_file=numericals_file,\n",
    "            y_variable_file=y_variable_file,\n",
    "            model_save_dir_override=Path(config.paths.model_save_base_dir),\n",
    "            transformers_dir_override=Path(config.paths.transformers_save_base_dir),\n",
    "            metrics_percentile=reload_percentile\n",
    "        )\n",
    "\n",
    "    # 5. Run bayesian optimized granular data processing.\n",
    "    merged_data, bayesian_metrics_dict = bayesian_optimized_granular_data_main(\n",
    "        bayesian_metrics_file_path=bayesian_metrics_file_path,\n",
    "        final_ml_file_path=final_ml_file_path,\n",
    "        final_ml_with_predictions_path=final_ml_with_predictions_path,\n",
    "        final_granular_file_path=os.path.join(max_angles_output_dir, max_angles_output_filename),\n",
    "        pickle_path=pickle_path,\n",
    "        y_variable=y_variable,\n",
    "        output_dir=output_dir,\n",
    "        debug=debug,\n",
    "        bayes_min_max_range_percentile=bayes_min_max_range_percentile,\n",
    "        output_filename=output_filename\n",
    "    )\n",
    "    \n",
    "    # 6. Summarize bayesian classification results: count how many 'Good', 'Early', 'Late' per metric.\n",
    "    classification_summary = {}\n",
    "    for metric in bayesian_metrics_dict.keys():\n",
    "        col = f\"{metric}_bayes_classification\"\n",
    "        if col in merged_data.columns:\n",
    "            classification_summary[metric] = merged_data[col].value_counts().to_dict()\n",
    "        else:\n",
    "            classification_summary[metric] = {\"Error\": \"Column not found\"}\n",
    "    \n",
    "    return merged_data, bayesian_metrics_dict, classification_summary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Main Block (Example usage)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # # ------------------------------------------------------------------------------\n",
    "    # # Import configuration loader and models\n",
    "\n",
    "    # # Predict with shap so we can adjust the percentile if we ever want to\n",
    "    # # Main testing block for trying multiple models.\n",
    "    config_path = Path('../../data/model/preprocessor_config/preprocessor_config.yaml')\n",
    "    try:\n",
    "        config: AppConfig = load_config(config_path)\n",
    "        print(f\"Configuration loaded successfully from {config_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to load configuration: {e}\")\n",
    "        exit(1)\n",
    "        \n",
    "    # ------------------------------------------------------------------------------\n",
    "    # Bayesian Shap calc merge    \n",
    "    # Example file paths and parameters (adjust these as needed)\n",
    "    granular_data_path = \"../../data/processed/final_granular_dataset.csv\"\n",
    "    release_angles_output_dir = \"../../data/model/shot_meter_docs/\"\n",
    "    max_angles_output_dir = \"../../data/model/shot_meter_docs/\"\n",
    "    bayesian_metrics_file_path = \"../../data/predictions/bayesian_optimization_results/bayesian_optimization_results.csv\"\n",
    "    final_ml_file_path = \"../../data/processed/final_ml_dataset.csv\"\n",
    "    final_ml_with_predictions_path = \"../../data/predictions/shap_results/final_predictions_with_shap.csv\"\n",
    "    pickle_path = \"../../data/preprocessor/features_info/final_ml_df_selected_features_columns.pkl\"\n",
    "    y_variable = \"result\"\n",
    "    bayes_min_max_range_percentile = 10\n",
    "    calc_feedback_range_percentile = 10\n",
    "    new_shap_min_max_percentile = 10\n",
    "    output_dir = \"../../data/model/shot_meter_docs/\"\n",
    "    output_filename = \"bayesian_shot_meter_granular_dataset.csv\"\n",
    "    debug = True\n",
    "    \n",
    "    # Run the automated summary function\n",
    "    merged_data, bayesian_metrics_dict, classification_summary = automated_bayes_shap_summary(\n",
    "        granular_data_path=granular_data_path,\n",
    "        release_angles_output_dir=release_angles_output_dir,\n",
    "        max_angles_output_dir=max_angles_output_dir,\n",
    "        bayesian_metrics_file_path=bayesian_metrics_file_path,\n",
    "        final_ml_file_path=final_ml_file_path,\n",
    "        final_ml_with_predictions_path=final_ml_with_predictions_path,\n",
    "        pickle_path=pickle_path,\n",
    "        y_variable=y_variable,\n",
    "        bayes_min_max_range_percentile=bayes_min_max_range_percentile,\n",
    "        output_dir=output_dir,\n",
    "        output_filename=output_filename,\n",
    "        debug=debug,\n",
    "        calc_feedback_range_percentile=calc_feedback_range_percentile,\n",
    "        #Only needed if we want to reload the shap data\n",
    "        reload_shap_data=True,\n",
    "        new_shap_min_max_percentile=new_shap_min_max_percentile,\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    # Print out a summary of bayesian classifications\n",
    "    print(\"Bayesian Classification Summary (counts per metric):\")\n",
    "    for metric, counts in classification_summary.items():\n",
    "        print(f\"{metric}: {counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting notebooks/freethrow_predictions/animate/animation_dataframe_addons.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile notebooks/freethrow_predictions/animate/animation_dataframe_addons.py\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.lines import Line2D\n",
    "from IPython.display import HTML\n",
    "from mplbasketball.court3d import Court3D, draw_court_3d\n",
    "\n",
    "# Configure logging for debugging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define common viewpoints\n",
    "COMMON_VIEWPOINTS = {\n",
    "    \"side_view_right\": {\"elev\": 0, \"azim\": 90},\n",
    "    \"side_view_left\": {\"elev\": 0, \"azim\": -90},\n",
    "    \"top_down\": {\"elev\": 90, \"azim\": 0},\n",
    "    \"diagonal_view\": {\"elev\": 45, \"azim\": 45},\n",
    "    \"player_centric\": {\"elev\": 30, \"azim\": 0},\n",
    "    \"diagonal_player_centric\": {\"elev\": 30, \"azim\": 45},\n",
    "    \"inverse_player_centric\": {\"elev\": 30, \"azim\": 180}\n",
    "}\n",
    "\n",
    "def get_viewpoint(name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve viewpoint parameters by name.\n",
    "    \n",
    "    Parameters:\n",
    "    - name (str): The name of the viewpoint.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Dictionary containing 'elev' and 'azim'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        viewpoint = COMMON_VIEWPOINTS[name]\n",
    "        logger.debug(f\"Retrieved viewpoint '{name}': {viewpoint}\")\n",
    "        return viewpoint\n",
    "    except KeyError:\n",
    "        logger.error(f\"Viewpoint '{name}' not found. Available viewpoints: {list(COMMON_VIEWPOINTS.keys())}\")\n",
    "        raise ValueError(f\"Viewpoint '{name}' not found. Choose from {list(COMMON_VIEWPOINTS.keys())}\")\n",
    "\n",
    "# Define the connections between joints\n",
    "CONNECTIONS = [\n",
    "    # Skeletal connections for visualization\n",
    "    (\"R_EYE\", \"L_EYE\"), (\"R_EYE\", \"NOSE\"), (\"L_EYE\", \"NOSE\"),\n",
    "    (\"R_EYE\", \"R_EAR\"), (\"L_EYE\", \"L_EAR\"), (\"R_SHOULDER\", \"L_SHOULDER\"),\n",
    "    (\"R_SHOULDER\", \"R_ELBOW\"), (\"L_SHOULDER\", \"L_ELBOW\"), (\"R_ELBOW\", \"R_WRIST\"),\n",
    "    (\"L_ELBOW\", \"L_WRIST\"), (\"R_SHOULDER\", \"R_HIP\"), (\"L_SHOULDER\", \"L_HIP\"),\n",
    "    (\"R_HIP\", \"L_HIP\"), (\"R_HIP\", \"R_KNEE\"), (\"L_HIP\", \"L_KNEE\"),\n",
    "    (\"R_KNEE\", \"R_ANKLE\"), (\"L_KNEE\", \"L_ANKLE\"), (\"R_WRIST\", \"R_1STFINGER\"),\n",
    "    (\"R_WRIST\", \"R_5THFINGER\"), (\"L_WRIST\", \"L_1STFINGER\"), (\"L_WRIST\", \"L_5THFINGER\"),\n",
    "    (\"R_ANKLE\", \"R_1STTOE\"), (\"R_ANKLE\", \"R_5THTOE\"), (\"L_ANKLE\", \"L_1STTOE\"),\n",
    "    (\"L_ANKLE\", \"L_5THTOE\"), (\"R_ANKLE\", \"R_CALC\"), (\"L_ANKLE\", \"L_CALC\"),\n",
    "    (\"R_1STTOE\", \"R_5THTOE\"), (\"L_1STTOE\", \"L_5THTOE\"), (\"R_1STTOE\", \"R_CALC\"),\n",
    "    (\"L_1STTOE\", \"L_CALC\"), (\"R_5THTOE\", \"R_CALC\"), (\"L_5THTOE\", \"L_CALC\"),\n",
    "    (\"R_1STFINGER\", \"R_5THFINGER\"), (\"L_1STFINGER\", \"L_5THFINGER\")\n",
    "]\n",
    "\n",
    "def initialize_plot(viewpoint_name: str, zlim: float, figsize=(10, 8), debug: bool = False) -> (plt.Figure, plt.Axes):\n",
    "    \"\"\"\n",
    "    Initialize a 3D plot with specified viewpoint settings and outputs setup details.\n",
    "\n",
    "    Parameters:\n",
    "    - viewpoint_name (str): Name of the predefined viewpoint.\n",
    "    - zlim (float): The limit for the z-axis (height).\n",
    "    - figsize (tuple): Size of the figure.\n",
    "    - debug (bool): Flag to enable debug logging.\n",
    "\n",
    "    Returns:\n",
    "    - fig: The Matplotlib figure object.\n",
    "    - ax: The Matplotlib 3D axis object.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Retrieve elev and azim from viewpoint name\n",
    "        viewpoint = get_viewpoint(viewpoint_name)\n",
    "        elev = viewpoint[\"elev\"]\n",
    "        azim = viewpoint[\"azim\"]\n",
    "\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = fig.add_subplot(111, projection=\"3d\")\n",
    "        ax.set_zlim([0, zlim])\n",
    "        ax.set_box_aspect([1, 1, 1])\n",
    "        ax.view_init(elev=elev, azim=azim)\n",
    "        ax.xaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "        ax.yaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_zticks([])\n",
    "        if debug:\n",
    "            logger.debug(f\"Initialized 3D plot with Z limit: {zlim}, Elevation: {elev}, Azimuth: {azim}\")\n",
    "        return fig, ax\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to initialize plot: {e}\")\n",
    "        raise\n",
    "\n",
    "def get_hoop_position(court_type: str = \"nba\", units: str = \"ft\", debug: bool = False) -> (float, float, float):\n",
    "    \"\"\"\n",
    "    Calculate the 3D position of the basketball hoop based on court specifications.\n",
    "\n",
    "    Parameters:\n",
    "    - court_type (str): Type of the court ('nba', 'wnba', 'ncaa').\n",
    "    - units (str): Units of measurement ('ft' or 'm').\n",
    "    - debug (bool): Flag to enable debug logging.\n",
    "\n",
    "    Returns:\n",
    "    - x, y, z (float): Coordinates of the hoop in 3D space.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        court = Court3D(court_type=court_type, units=units)\n",
    "        params = court.court_parameters\n",
    "        # The hoop is located a certain distance from the edge of the court\n",
    "        x = params['court_dims'][0] / 2 - params['hoop_distance_from_edge']\n",
    "        y = 0.0  # Centered along the y-axis\n",
    "        z = params['hoop_height']\n",
    "        if debug:\n",
    "            logger.debug(f\"Calculated hoop position at (x={x}, y={y}, z={z}) for court type '{court_type}' in '{units}' units.\")\n",
    "        return x, y, z\n",
    "    except KeyError as e:\n",
    "        logger.error(f\"Key error when accessing court parameters: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error in get_hoop_position: {e}\")\n",
    "        raise\n",
    "\n",
    "def draw_court(ax: plt.Axes, court_type: str = \"nba\", units: str = \"ft\", debug: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Draw the basketball court and hoop on the given axes.\n",
    "\n",
    "    Parameters:\n",
    "    - ax (plt.Axes): The Matplotlib 3D axis object.\n",
    "    - court_type (str): Type of the court ('nba', 'wnba', 'ncaa').\n",
    "    - units (str): Units of measurement ('ft' or 'm').\n",
    "    - debug (bool): Flag to enable debug logging.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Draw the court using mplbasketball\n",
    "        draw_court_3d(ax, court_type=court_type, units=units, origin=np.array([0.0, 0.0]), line_width=2)\n",
    "        if debug:\n",
    "            logger.debug(\"Court drawn successfully.\")\n",
    "\n",
    "        # Get court parameters\n",
    "        court = Court3D(court_type=court_type, units=units)\n",
    "        court_params = court.court_parameters\n",
    "        if debug:\n",
    "            logger.debug(f\"Court Parameters in draw_court: {court_params}\")\n",
    "\n",
    "        # Get hoop position\n",
    "        hoop_x, hoop_y, hoop_z = get_hoop_position(court_type=court_type, units=units, debug=debug)\n",
    "\n",
    "        # Draw the hoop as a circle using the actual hoop_radius from the library\n",
    "        if 'hoop_radius' not in court_params:\n",
    "            raise KeyError(\n",
    "                \"Court3D does not provide 'hoop_radius' in court_parameters. \"\n",
    "                \"Available keys: \" + str(list(court_params.keys()))\n",
    "            )\n",
    "        hoop_radius = float(court_params['hoop_radius'])\n",
    "        theta_circle = np.linspace(0, 2 * np.pi, 100)\n",
    "        hoop_xs = hoop_x + hoop_radius * np.cos(theta_circle)\n",
    "        hoop_ys = hoop_y + hoop_radius * np.sin(theta_circle)\n",
    "        hoop_zs = np.full_like(hoop_xs, hoop_z)\n",
    "\n",
    "        ax.plot(hoop_xs, hoop_ys, hoop_zs, c='orange', lw=3)\n",
    "        if debug:\n",
    "            logger.debug(f\"Hoop drawn at position ({hoop_x}, {hoop_y}, {hoop_z}) with radius {hoop_radius}.\")\n",
    "\n",
    "        # Plot half-court line\n",
    "        half_court_x = np.linspace(-court_params['court_dims'][0]/2, court_params['court_dims'][0]/2, 100)\n",
    "        half_court_y = np.full_like(half_court_x, 0.0)\n",
    "        half_court_z = np.full_like(half_court_x, 0.0)\n",
    "        ax.plot(half_court_x, half_court_y, half_court_z, c='black', lw=2, linestyle='--')\n",
    "\n",
    "        # Plot three-point arc\n",
    "        three_point_arc_angle = np.deg2rad(court_params['three_point_arc_angle'])  # Convert to radians\n",
    "        theta_arc = np.linspace(-three_point_arc_angle, three_point_arc_angle, 150)  # -75° to +75°\n",
    "        three_point_radius = court_params['three_point_arc_diameter'] / 2  # 23.75 ft\n",
    "        three_point_x = hoop_x + three_point_radius * np.cos(theta_arc)\n",
    "        three_point_y = hoop_y + three_point_radius * np.sin(theta_arc)\n",
    "        three_point_z = np.full_like(three_point_x, 0.0)\n",
    "        ax.plot(three_point_x, three_point_y, three_point_z, c='purple', lw=2)\n",
    "\n",
    "        # Plot straight lines (corners) of the three-point line\n",
    "        # Calculate the end points of the arc at theta = ±75 degrees\n",
    "        end_x_positive = hoop_x + three_point_radius * np.cos(three_point_arc_angle)\n",
    "        end_y_positive = hoop_y + three_point_radius * np.sin(three_point_arc_angle)\n",
    "        end_x_negative = hoop_x + three_point_radius * np.cos(-three_point_arc_angle)\n",
    "        end_y_negative = hoop_y + three_point_radius * np.sin(-three_point_arc_angle)\n",
    "\n",
    "        # Baseline x position\n",
    "        baseline_x = court_params['court_dims'][0]/2  # 47 ft\n",
    "\n",
    "        # Straight lines from arc end to sideline (approx. 1.25 ft)\n",
    "        straight_line_y_positive = np.linspace(end_y_positive, court_params['court_dims'][1]/2, 50)\n",
    "        straight_line_x_positive = np.full_like(straight_line_y_positive, baseline_x)\n",
    "        straight_line_z_positive = np.full_like(straight_line_y_positive, 0.0)\n",
    "        ax.plot(straight_line_x_positive, straight_line_y_positive, straight_line_z_positive, c='purple', lw=2)\n",
    "\n",
    "        straight_line_y_negative = np.linspace(end_y_negative, -court_params['court_dims'][1]/2, 50)\n",
    "        straight_line_x_negative = np.full_like(straight_line_y_negative, baseline_x)\n",
    "        straight_line_z_negative = np.full_like(straight_line_y_negative, 0.0)\n",
    "        ax.plot(straight_line_x_negative, straight_line_y_negative, straight_line_z_negative, c='purple', lw=2)\n",
    "\n",
    "        # Plot sidelines\n",
    "        sideline_x = np.linspace(-court_params['court_dims'][0]/2, court_params['court_dims'][0]/2, 100)\n",
    "        sideline_y_positive = np.full_like(sideline_x, court_params['court_dims'][1]/2)\n",
    "        sideline_z = np.full_like(sideline_x, 0.0)\n",
    "        ax.plot(sideline_x, sideline_y_positive, sideline_z, c='blue', lw=2)\n",
    "\n",
    "        sideline_y_negative = np.full_like(sideline_x, -court_params['court_dims'][1]/2)\n",
    "        ax.plot(sideline_x, sideline_y_negative, sideline_z, c='blue', lw=2)\n",
    "\n",
    "        # Plot baselines\n",
    "        baseline_x_positive = np.full_like(court_params['court_dims'][1]/2, court_params['court_dims'][0]/2)\n",
    "        baseline_y = np.linspace(-court_params['court_dims'][1]/2, court_params['court_dims'][1]/2, 100)\n",
    "        baseline_z = np.full_like(baseline_y, 0.0)\n",
    "        ax.plot(court_params['court_dims'][0]/2, baseline_y, baseline_z, c='green', lw=2)\n",
    "\n",
    "        baseline_x_negative = np.full_like(court_params['court_dims'][1]/2, -court_params['court_dims'][0]/2)\n",
    "        ax.plot(-court_params['court_dims'][0]/2, baseline_y, baseline_z, c='green', lw=2)\n",
    "\n",
    "        if debug:\n",
    "            logger.debug(\"Additional court features (half-court, three-point lines, sidelines, baselines) drawn successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error drawing court or hoop: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def initialize_elements(\n",
    "    ax: plt.Axes,\n",
    "    connections: list,\n",
    "    player_color: str,\n",
    "    player_lw: float,\n",
    "    ball_color: str,\n",
    "    ball_size: float,\n",
    "    debug: bool = False\n",
    ") -> (dict, plt.Line2D, plt.Text, plt.Text, plt.Text):\n",
    "    \"\"\"\n",
    "    Initialize plot elements such as lines for the player skeleton and the ball.\n",
    "\n",
    "    Returns:\n",
    "    - lines (dict): Dictionary of line objects for each connection.\n",
    "    - ball (plt.Line2D): The ball plot object.\n",
    "    - release_text (plt.Text): Text object for release point indicator.\n",
    "    - motion_text (plt.Text): Text object for motion phase indicator.\n",
    "    - distance_text (plt.Text): Text object for distance to hoop.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize lines for each body connection\n",
    "        lines = {connection: ax.plot([], [], [], c=player_color, lw=player_lw)[0] for connection in connections}\n",
    "        \n",
    "        # Initialize the ball as a point\n",
    "        ball, = ax.plot([], [], [], \"o\", markersize=ball_size, c=ball_color)\n",
    "        \n",
    "        # Text elements for annotations\n",
    "        release_text = ax.text2D(0.05, 0.95, \"\", transform=ax.transAxes, color=\"red\", fontsize=14, weight=\"bold\")\n",
    "        motion_text = ax.text2D(0.05, 0.90, \"\", transform=ax.transAxes, color=\"blue\", fontsize=12, weight=\"bold\")\n",
    "        \n",
    "        # New text element for distance (positioned below motion_text)\n",
    "        distance_text = ax.text2D(0.05, 0.85, \"\", transform=ax.transAxes, color=\"green\", fontsize=12, weight=\"bold\")\n",
    "        \n",
    "        if debug:\n",
    "            logger.debug(\"Elements initialized (lines, ball, text labels).\")\n",
    "        \n",
    "        return lines, ball, release_text, motion_text, distance_text\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error initializing elements: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "\n",
    "def update_frame(\n",
    "    ax: plt.Axes,\n",
    "    frame: int,\n",
    "    df: pd.DataFrame,\n",
    "    release_frame: int,\n",
    "    lines: dict,\n",
    "    ball: plt.Line2D,\n",
    "    release_text: plt.Text,\n",
    "    motion_text: plt.Text,\n",
    "    connections: list,\n",
    "    xbuffer: float,\n",
    "    ybuffer: float,\n",
    "    ball_color: str,\n",
    "    highlight_color: str,\n",
    "    debug: bool = False\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Update function for each frame in the animation.\n",
    "\n",
    "    Parameters:\n",
    "    - ax (plt.Axes): The Matplotlib 3D axis object.\n",
    "    - frame (int): The current frame number.\n",
    "    - df (pd.DataFrame): DataFrame containing motion data.\n",
    "    - release_frame (int): Frame index of the release point.\n",
    "    - lines (dict): Dictionary of line objects for skeleton.\n",
    "    - ball (plt.Line2D): Ball object for animation.\n",
    "    - release_text (plt.Text): Text object for release point.\n",
    "    - motion_text (plt.Text): Text object for motion phase.\n",
    "    - connections (list): Joint connections.\n",
    "    - xbuffer (float): Horizontal axis buffer (not used in fixed axes mode).\n",
    "    - ybuffer (float): Vertical axis buffer (not used in fixed axes mode).\n",
    "    - ball_color (str): Default ball color.\n",
    "    - highlight_color (str): Highlight color for release point.\n",
    "    - debug (bool): Flag to enable debug logging.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if debug and frame % 10 == 0:\n",
    "            logger.debug(f\"Updating frame {frame}\")\n",
    "\n",
    "        # Highlight the release frame\n",
    "        if frame == release_frame:\n",
    "            ball.set_color(highlight_color)\n",
    "            release_text.set_text(\"Release Point!\")\n",
    "            if debug:\n",
    "                logger.debug(f\"Frame {frame} is the release frame. Ball color changed to {highlight_color}.\")\n",
    "        else:\n",
    "            ball.set_color(ball_color)\n",
    "            release_text.set_text(\"\")\n",
    "\n",
    "        # Update motion phase text if 'shooting_motion' exists\n",
    "        if 'shooting_motion' in df.columns:\n",
    "            shooting_motion = df.at[frame, 'shooting_motion']\n",
    "            motion_text.set_text(\"Shooting Motion\" if shooting_motion == 1 else \"\")\n",
    "        else:\n",
    "            motion_text.set_text(\"\")\n",
    "\n",
    "        # Update lines for joints\n",
    "        for connection in connections:\n",
    "            part1, part2 = connection\n",
    "            if (f\"{part1}_x\" in df.columns and f\"{part2}_x\" in df.columns and\n",
    "                not pd.isna(df.at[frame, f\"{part1}_x\"]) and not pd.isna(df.at[frame, f\"{part2}_x\"])):\n",
    "                x = [df.at[frame, f\"{part1}_x\"], df.at[frame, f\"{part2}_x\"]]\n",
    "                y = [df.at[frame, f\"{part1}_y\"], df.at[frame, f\"{part2}_y\"]]\n",
    "                z = [df.at[frame, f\"{part1}_z\"], df.at[frame, f\"{part2}_z\"]]\n",
    "                lines[connection].set_data_3d(x, y, z)\n",
    "            else:\n",
    "                # If data is missing, hide the line\n",
    "                lines[connection].set_data([], [])\n",
    "                lines[connection].set_3d_properties([])\n",
    "\n",
    "        # Update ball position if ball coordinates exist\n",
    "        if 'ball_x' in df.columns and 'ball_y' in df.columns and 'ball_z' in df.columns:\n",
    "            ball_x = df.at[frame, 'ball_x']\n",
    "            ball_y = df.at[frame, 'ball_y']\n",
    "            ball_z = df.at[frame, 'ball_z']\n",
    "            if not (pd.isna(ball_x) or pd.isna(ball_y) or pd.isna(ball_z)):\n",
    "                ball.set_data_3d([ball_x], [ball_y], [ball_z])\n",
    "            else:\n",
    "                # Hide the ball if data is missing\n",
    "                ball.set_data([], [])\n",
    "                ball.set_3d_properties([])\n",
    "        else:\n",
    "            # Hide the ball if columns are missing\n",
    "            ball.set_data([], [])\n",
    "            ball.set_3d_properties([])\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error updating frame {frame}: {e}\")\n",
    "        raise\n",
    "    \n",
    "    \n",
    "def animate_trial_from_df(\n",
    "    df: pd.DataFrame,\n",
    "    release_frame: int,\n",
    "    viewpoint_name: str = \"side_view_right\",  # New parameter for viewpoint\n",
    "    connections: list = CONNECTIONS,\n",
    "    xbuffer: float = 4.0,\n",
    "    ybuffer: float = 4.0,\n",
    "    zlim: float = 15.0,\n",
    "    player_color: str = \"purple\",\n",
    "    player_lw: float = 2.0,\n",
    "    ball_color: str = \"#ee6730\",\n",
    "    ball_size: float = 20.0,\n",
    "    highlight_color: str = \"red\",\n",
    "    show_court: bool = True,\n",
    "    court_type: str = \"nba\",\n",
    "    units: str = \"ft\",\n",
    "    notebook_mode: bool = True,\n",
    "    debug: bool = False\n",
    ") -> HTML:\n",
    "    \"\"\"\n",
    "    Animate the trial from the provided DataFrame, showing the player's motion and the ball.\n",
    "\n",
    "    Returns:\n",
    "    - HTML: The animation in HTML format for notebook display or the animation object.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Close any existing figures to prevent duplicate animations\n",
    "        plt.close('all')\n",
    "\n",
    "        if debug:\n",
    "            logger.debug(\"Starting animation setup.\")\n",
    "            logger.debug(f\"Total frames in DataFrame: {len(df)}\")\n",
    "            logger.debug(f\"Release frame index provided: {release_frame}\")\n",
    "            logger.debug(f\"Selected viewpoint: {viewpoint_name}\")\n",
    "\n",
    "        # Plot setup with predefined viewpoint\n",
    "        fig, ax = initialize_plot(viewpoint_name, zlim, figsize=(12, 10), debug=debug)\n",
    "\n",
    "        # Draw court and get hoop position\n",
    "        if show_court:\n",
    "            draw_court(ax, court_type=court_type, units=units, debug=debug)\n",
    "            hoop_x, hoop_y, hoop_z = get_hoop_position(court_type=court_type, units=units, debug=debug)\n",
    "        else:\n",
    "            hoop_x, hoop_y, hoop_z = None, None, None\n",
    "\n",
    "        # Initialize elements for animation (modified to capture distance_text)\n",
    "        lines, ball, release_text, motion_text, distance_text = initialize_elements(\n",
    "            ax, connections, player_color, player_lw, ball_color, ball_size, debug=debug\n",
    "        )\n",
    "\n",
    "        # Compute axes limits\n",
    "        if debug:\n",
    "            logger.debug(\"Calculating axes limits to include player and hoop.\")\n",
    "\n",
    "        # Extract all x and y coordinates for the player\n",
    "        player_x_cols = [col for col in df.columns if col.endswith('_x')]\n",
    "        player_y_cols = [col for col in df.columns if col.endswith('_y')]\n",
    "\n",
    "        player_x = df[player_x_cols].values.flatten()\n",
    "        player_y = df[player_y_cols].values.flatten()\n",
    "\n",
    "        # Remove NaN values\n",
    "        player_x = player_x[~np.isnan(player_x)]\n",
    "        player_y = player_y[~np.isnan(player_y)]\n",
    "\n",
    "        # Initialize min and max with player coordinates\n",
    "        x_min = player_x.min() - xbuffer\n",
    "        x_max = player_x.max() + xbuffer\n",
    "        y_min = player_y.min() - ybuffer\n",
    "        y_max = player_y.max() + ybuffer\n",
    "\n",
    "        # Include hoop position in the limits if court is shown and hoop position is valid\n",
    "        if show_court and hoop_x is not None and hoop_y is not None:\n",
    "            x_min = min(x_min, hoop_x - xbuffer)\n",
    "            x_max = max(x_max, hoop_x + xbuffer)\n",
    "            y_min = min(y_min, hoop_y - ybuffer)\n",
    "            y_max = max(y_max, hoop_y + ybuffer)\n",
    "\n",
    "        if debug:\n",
    "            logger.debug(f\"Player X range: {player_x.min()} to {player_x.max()}\")\n",
    "            logger.debug(f\"Player Y range: {player_y.min()} to {player_y.max()}\")\n",
    "            if show_court:\n",
    "                logger.debug(f\"Hoop position: ({hoop_x}, {hoop_y})\")\n",
    "            logger.debug(f\"Using xbuffer: {xbuffer}, ybuffer: {ybuffer}\")\n",
    "\n",
    "        # Set fixed axes limits\n",
    "        ax.set_xlim([x_min, x_max])\n",
    "        ax.set_ylim([y_min, y_max])\n",
    "\n",
    "        if debug:\n",
    "            logger.debug(f\"Set axes limits: x=({x_min}, {x_max}), y=({y_min}, {y_max})\")\n",
    "\n",
    "        # Set plot title to include the viewpoint name\n",
    "        ax.set_title(f\"Animation - {viewpoint_name}\", fontsize=16)\n",
    "        if debug:\n",
    "            logger.debug(f\"Set plot title to 'Animation - {viewpoint_name}'\")\n",
    "\n",
    "        # Create custom legend handles for static court features\n",
    "        hoop_handle = Line2D([0], [0], color='orange', lw=3, label='Hoop')\n",
    "        three_point_handle = Line2D([0], [0], color='purple', lw=2, label='Three-Point Line')\n",
    "        half_court_handle = Line2D([0], [0], color='black', lw=2, linestyle='--', label='Half-Court Line')\n",
    "        baseline_handle = Line2D([0], [0], color='blue', lw=2, label='Baseline')\n",
    "\n",
    "        # Create handles for dynamic elements\n",
    "        player_handle = Line2D([0], [0], color=player_color, lw=player_lw, label='Player')\n",
    "        ball_handle = Line2D([0], [0], marker='o', color='w', label='Ball',\n",
    "                             markerfacecolor=ball_color, markersize=10)\n",
    "\n",
    "        # Add legend with both static and dynamic elements (excluding distance)\n",
    "        ax.legend(handles=[hoop_handle, three_point_handle, half_court_handle, baseline_handle,\n",
    "                           player_handle, ball_handle], loc='upper right')\n",
    "\n",
    "        if debug:\n",
    "            logger.debug(\"Legend added with static court features and dynamic elements.\")\n",
    "\n",
    "        # Update function for animation\n",
    "        def update(frame: int):\n",
    "            \"\"\"\n",
    "            Wrapper function for updating the frame in the animation.\n",
    "            \"\"\"\n",
    "            update_frame(\n",
    "                ax=ax,  # The 3D axis object\n",
    "                frame=frame,  # Current frame number\n",
    "                df=df,  # DataFrame containing motion data\n",
    "                release_frame=release_frame,  # Frame index of the release point\n",
    "                lines=lines,  # Dictionary of line objects for skeleton\n",
    "                ball=ball,  # Ball object for animation\n",
    "                release_text=release_text,  # Text object for release point\n",
    "                motion_text=motion_text,  # Text object for motion phase\n",
    "                connections=connections,  # Joint connections\n",
    "                xbuffer=xbuffer,  # Horizontal axis buffer (not used here)\n",
    "                ybuffer=ybuffer,  # Vertical axis buffer (not used here)\n",
    "                ball_color=ball_color,  # Default ball color\n",
    "                highlight_color=highlight_color,  # Highlight color for release point\n",
    "                debug=debug  # Debugging flag\n",
    "            )\n",
    "\n",
    "            # Update the distance text\n",
    "            if 'distance_to_hoop' in df.columns:\n",
    "                distance = df.at[frame, 'distance_to_hoop']\n",
    "                if not pd.isna(distance):\n",
    "                    distance_text.set_text(f\"Distance to Hoop: {distance:.2f} ft\")\n",
    "                else:\n",
    "                    distance_text.set_text(\"\")\n",
    "            else:\n",
    "                distance_text.set_text(\"\")\n",
    "\n",
    "        # Animation setup\n",
    "        anim = FuncAnimation(fig, update, frames=len(df), interval=1000 / 30, blit=False)\n",
    "\n",
    "        if notebook_mode:\n",
    "            if debug:\n",
    "                logger.debug(\"Returning animation for notebook display.\")\n",
    "            return HTML(anim.to_jshtml())\n",
    "        else:\n",
    "            if debug:\n",
    "                logger.debug(\"Returning animation object.\")\n",
    "            return anim\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during animation: {e}\")\n",
    "        raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive buttons for the streamlit like the example at the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting notebooks/freethrow_predictions/animate_calc_bayes_shap.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile notebooks/freethrow_predictions/animate_calc_bayes_shap.py\n",
    "\"\"\"\"\n",
    "Updated to unify calculated, bayesian, and shap feedback logic in update_meter_with_mode.\n",
    "Introduces a polar subplot for the angle meter with angular ticks and a dynamic line graph.\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "import pandas as pd \n",
    "import json\n",
    "from IPython.display import HTML, display\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from mplbasketball.court3d import Court3D, draw_court_3d\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "# add for if we ever want to recalculate the shap min and max values\n",
    "from ml.config.config_loader import load_config\n",
    "from ml.config.config_models import AppConfig\n",
    "from ml.shap.shap_utils import load_dataset, setup_logging, load_configuration, initialize_logger\n",
    "from ml.shap.predict_with_shap_usage import predict_and_shap\n",
    "\n",
    "from animate.court import draw_court, get_hoop_position\n",
    "from animate.viewpoints import get_viewpoint\n",
    "from matplotlib.patches import Wedge\n",
    "\n",
    "from animate.calc_bayes_shap_feature_engineering import automated_bayes_shap_summary\n",
    "# Configure logging\n",
    "logger = logging.getLogger('bayes_animate')\n",
    "if not logger.hasHandlers():\n",
    "    logger.setLevel(logging.DEBUG)  # Set to DEBUG to capture all logs\n",
    "    handler = logging.StreamHandler()\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "# Increase the animation embed limit to 30 MB\n",
    "mpl.rcParams['animation.embed_limit'] = 30.0  # Value is in MB\n",
    "# Global constant for converting degrees to radians\n",
    "DEG_TO_RAD = np.pi / 180.0\n",
    "\n",
    "\n",
    "def display_separate_outputs(feedback_table, animation_html, feedback_mode):\n",
    "    \"\"\"\n",
    "    Displays the feedback table and the animation in two separate outputs\n",
    "    so they do not overlap in a single HTML container.\n",
    "    \n",
    "    Parameters:\n",
    "      - feedback_table (pd.DataFrame): The feedback metrics table.\n",
    "      - animation_html (IPython.display.HTML): The animation HTML object.\n",
    "      - feedback_mode (str): The current feedback mode (for labeling purposes).\n",
    "    \n",
    "    This function is useful in Jupyter notebooks where the table might otherwise\n",
    "    block interaction with the animation.\n",
    "    \"\"\"\n",
    "    from IPython.display import display\n",
    "    \n",
    "    # Display the feedback table in its own block.\n",
    "    print(f\"Feedback Table ({feedback_mode.capitalize()} Mode):\")\n",
    "    display(feedback_table)\n",
    "    \n",
    "    # Display the animation in a separate output block.\n",
    "    print(\"\\nAnimation:\")\n",
    "    display(animation_html)\n",
    "\n",
    "\n",
    "\n",
    "def load_bayesian_metrics_dict(\n",
    "    json_path: str,\n",
    "    debug: bool = False\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Load the Bayesian metrics dictionary from a JSON file.\n",
    "\n",
    "    Parameters:\n",
    "        json_path (str): Path to the JSON file.\n",
    "        debug (bool): Whether to print debug information. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        dict: Bayesian metrics dictionary without 'filter_name'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(json_path, 'r') as f:\n",
    "            bayesian_metrics_dict = json.load(f)\n",
    "        \n",
    "        if debug:\n",
    "            logger.debug(f\"Loaded Bayesian metrics dictionary from {json_path}\")\n",
    "            logger.debug(json.dumps(bayesian_metrics_dict, indent=4))\n",
    "        return bayesian_metrics_dict\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"Bayesian metrics JSON file not found at {json_path}\")\n",
    "        raise\n",
    "    except json.JSONDecodeError:\n",
    "        logger.error(f\"JSON decoding failed for file {json_path}\")\n",
    "        raise\n",
    "\n",
    "def generate_feedback_table_all_metrics(feedback_mode, bayesian_metrics_dict, trial_data, debug=False):\n",
    "    \"\"\"\n",
    "    Generates a comprehensive feedback table for all metrics based on the feedback mode.\n",
    "    \n",
    "    Parameters:\n",
    "        feedback_mode (str): The mode of feedback ('bayesian', 'shap', 'calculated').\n",
    "        bayesian_metrics_dict (dict): Dictionary containing Bayesian metrics for all selected metrics.\n",
    "        trial_data (pd.DataFrame): DataFrame containing the trial data.\n",
    "        debug (bool): If True, outputs debugging information.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the feedback data for all metrics, including the actual metric value\n",
    "                      ('actual_value') for comparison with the classification.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        feedback_records = []\n",
    "        if debug:\n",
    "            logger.debug(\"Trial data columns: %s\", trial_data.columns.tolist())\n",
    "\n",
    "        for metric_key, metric_info in bayesian_metrics_dict.items():\n",
    "            # Use the metric key as the selected metric.\n",
    "            selected_metric = metric_key  # e.g., 'release_ball_direction_x'\n",
    "            filter_name = metric_info.get('filter_name', selected_metric)\n",
    "\n",
    "            record = {\n",
    "                'Metric_Key': metric_key,\n",
    "                'Ongoing Metric Name': filter_name\n",
    "            }\n",
    "            if debug:\n",
    "                logger.debug(f\"Processing metric: {metric_key} (Filter: {filter_name})\")\n",
    "            \n",
    "            # Define columns based on feedback mode.\n",
    "            if feedback_mode.lower() == \"bayesian\":\n",
    "                columns = {\n",
    "                    'bayes_classification': f\"{selected_metric}_bayes_classification\",\n",
    "                    'bayes_optimized': f\"{selected_metric}_bayes_optimized\",\n",
    "                    'bayes_max': f\"{selected_metric}_bayes_max\",\n",
    "                    'bayes_min': f\"{selected_metric}_bayes_min\",\n",
    "                    'bayes_unit_change': f\"{selected_metric}_bayes_unit_change\",\n",
    "                    'shap_importance': f\"shap_{selected_metric}_importance\"  # included even for bayesian\n",
    "                }\n",
    "            elif feedback_mode.lower() == \"shap\":\n",
    "                columns = {\n",
    "                    'shap_unit_change': f\"shap_{selected_metric}_unit_change\",\n",
    "                    'shap_unit': f\"shap_{selected_metric}_unit\",\n",
    "                    'shap_direction': f\"shap_{selected_metric}_direction\",\n",
    "                    'shap_importance': f\"shap_{selected_metric}_importance\",\n",
    "                    'shap_goal': f\"shap_{selected_metric}_goal\",\n",
    "                    'shap_min': f\"shap_{selected_metric}_min\",\n",
    "                    'shap_max': f\"shap_{selected_metric}_max\",\n",
    "                    'shap_classification': f\"shap_{selected_metric}_classification\"\n",
    "                }\n",
    "            elif feedback_mode.lower() == \"calculated\":\n",
    "                columns = {\n",
    "                    'filtered_optimal_min': f\"{selected_metric}_filtered_optimal_min\",\n",
    "                    'filtered_optimal_max': f\"{selected_metric}_filtered_optimal_max\",\n",
    "                    'shot_classification': f\"{selected_metric}_shot_classification\"\n",
    "                }\n",
    "            else:\n",
    "                raise ValueError(\"Invalid feedback mode selected.\")\n",
    "\n",
    "            # Extract values from trial_data for the defined columns.\n",
    "            for key, col in columns.items():\n",
    "                if col in trial_data.columns:\n",
    "                    value = trial_data.at[0, col]\n",
    "                    record[key] = value\n",
    "                    if debug:\n",
    "                        logger.debug(f\"  {key}: {value}\")\n",
    "                else:\n",
    "                    record[key] = np.nan\n",
    "                    logger.warning(f\"  Missing column: {col}\")\n",
    "\n",
    "            # NEW: Add the actual metric value from trial_data for comparison.\n",
    "            if selected_metric in trial_data.columns:\n",
    "                record['actual_value'] = trial_data.at[0, selected_metric]\n",
    "                if debug:\n",
    "                    logger.debug(f\"  actual_value: {record['actual_value']}\")\n",
    "            else:\n",
    "                record['actual_value'] = np.nan\n",
    "                logger.warning(f\"  Missing ongoing metric column: {selected_metric}\")\n",
    "            \n",
    "            feedback_records.append(record)\n",
    "\n",
    "        # Create DataFrame from records\n",
    "        feedback_df = pd.DataFrame(feedback_records)\n",
    "\n",
    "        # NEW FEATURE: Ensure 'shap_importance' column exists.\n",
    "        if 'shap_importance' not in feedback_df.columns:\n",
    "            # If the column is missing, add it with default NaN values.\n",
    "            feedback_df['shap_importance'] = np.nan\n",
    "            if debug:\n",
    "                logger.debug(\"Added missing 'shap_importance' column with default NaN values.\")\n",
    "        else:\n",
    "            # Convert to numeric if possible so that sorting works correctly.\n",
    "            feedback_df['shap_importance'] = pd.to_numeric(feedback_df['shap_importance'], errors='coerce')\n",
    "\n",
    "        # NEW FEATURE: Sort the feedback table by 'shap_importance'\n",
    "        feedback_df = feedback_df.sort_values(by='shap_importance', na_position='last', ascending=False)\n",
    "        if debug:\n",
    "            logger.debug(\"Feedback table sorted by 'shap_importance'.\")\n",
    "            logger.debug(feedback_df.head())\n",
    "\n",
    "        return feedback_df\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in generate_feedback_table_all_metrics: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_bayes_optimal_lines(\n",
    "    ax: plt.Axes,\n",
    "    min_angle: float,\n",
    "    max_angle: float,\n",
    "    feedback_mode: str = None,  # new\n",
    "    debug: bool = False\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Add optimal min and max lines to the angle meter, including release min and max angles.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert angles to radians\n",
    "        min_angle_rad = min_angle * np.pi / 180\n",
    "        max_angle_rad = max_angle * np.pi / 180\n",
    "\n",
    "        # Check if lines already exist\n",
    "        if not hasattr(ax, 'optimal_min_line'):\n",
    "            ax.optimal_min_line, = ax.plot(\n",
    "                [0, min_angle_rad], [0, 1], color='blue', lw=2, linestyle=\"--\", label='Bayes Min'\n",
    "            )\n",
    "        if not hasattr(ax, 'optimal_max_line'):\n",
    "            ax.optimal_max_line, = ax.plot(\n",
    "                [0, max_angle_rad], [0, 1], color='green', lw=2, linestyle=\"--\", label='Bayes Max'\n",
    "            )\n",
    "\n",
    "        if debug:\n",
    "            logger.debug(\n",
    "                f\"Added optimal lines at {min_angle}°, {max_angle}° with labels 'Bayes Min' and 'Bayes Max'.\"\n",
    "            )\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in add_bayes_optimal_lines: {e}\")\n",
    "        raise\n",
    "\n",
    "def add_bayes_optimal_lines_to_bar(ax_bar, min_val, max_val, selected_metric: str, feedback_mode: str, debug=False):\n",
    "    try:\n",
    "        # Determine the labels based on the feedback mode:\n",
    "        if feedback_mode.lower() == \"shap\":\n",
    "            min_label = f\"{selected_metric} SHAP Min\"\n",
    "            max_label = f\"{selected_metric} SHAP Max\"\n",
    "        elif feedback_mode.lower() == \"calculated\":\n",
    "            min_label = f\"{selected_metric} Calc Min\"\n",
    "            max_label = f\"{selected_metric} Calc Max\"\n",
    "        else:  # Assume bayesian or default\n",
    "            min_label = f\"{selected_metric} Bayes Min\"\n",
    "            max_label = f\"{selected_metric} Bayes Max\"\n",
    "\n",
    "        if not hasattr(ax_bar, 'bar_min_line'):\n",
    "            ax_bar.bar_min_line = ax_bar.axvline(x=min_val, color='blue', lw=2, linestyle='--', label=min_label)\n",
    "        if not hasattr(ax_bar, 'bar_max_line'):\n",
    "            ax_bar.bar_max_line = ax_bar.axvline(x=max_val, color='green', lw=2, linestyle='--', label=max_label)\n",
    "        if debug:\n",
    "            logger.debug(f\"Added bar optimal lines at {min_val} and {max_val} with labels '{min_label}' and '{max_label}'.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in add_bayes_optimal_lines_to_bar: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def initialize_bayes_elements(\n",
    "    ax: plt.Axes,\n",
    "    connections: list,\n",
    "    player_color: str,\n",
    "    player_lw: float,\n",
    "    ball_color: str,\n",
    "    ball_size: float,\n",
    "    debug: bool = False\n",
    ") -> (dict, plt.Line2D, plt.Text, plt.Text, plt.Text):\n",
    "    \"\"\"\n",
    "    Initialize plot elements such as lines for the player skeleton and the ball.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize lines for each body connection\n",
    "        lines = {connection: ax.plot([], [], [], c=player_color, lw=player_lw)[0] for connection in connections}\n",
    "        \n",
    "        # Initialize the ball as a point\n",
    "        ball, = ax.plot([], [], [], \"o\", markersize=ball_size, c=ball_color)\n",
    "        \n",
    "        # Text elements for annotations\n",
    "        release_text = ax.text2D(0.05, 0.95, \"\", transform=ax.transAxes, color=\"red\", fontsize=14, weight=\"bold\")\n",
    "        motion_text = ax.text2D(0.05, 0.90, \"\", transform=ax.transAxes, color=\"blue\", fontsize=12, weight=\"bold\")\n",
    "        \n",
    "        # New text element for distance (positioned below motion_text)\n",
    "        distance_text = ax.text2D(0.05, 0.85, \"\", transform=ax.transAxes, color=\"green\", fontsize=12, weight=\"bold\")\n",
    "        \n",
    "        if debug:\n",
    "            logger.debug(\"Elements initialized (lines, ball, text labels).\")\n",
    "        \n",
    "        return lines, ball, release_text, motion_text, distance_text\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error initializing elements: {e}\")\n",
    "        raise\n",
    "\n",
    "def update_bayes_frame(\n",
    "    ax: plt.Axes,\n",
    "    frame: int,\n",
    "    df: pd.DataFrame,\n",
    "    release_frame: int,\n",
    "    lines: dict,\n",
    "    ball: plt.Line2D,\n",
    "    release_text: plt.Text,\n",
    "    motion_text: plt.Text,\n",
    "    connections: list,\n",
    "    ball_color: str,\n",
    "    highlight_color: str,\n",
    "    debug: bool = False,\n",
    "    selected_metric: str = None,\n",
    "    selected_metric_filter_name: str = None,\n",
    "    joint_markers: dict = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Update the player's skeleton, ball position, text annotations, and joint markers.\n",
    "    If joint_markers is provided, each joint marker is updated with the current frame's x, y, z data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Update skeleton lines\n",
    "        for connection in connections:\n",
    "            joint_start, joint_end = connection\n",
    "            x_start = df.at[frame, f\"{joint_start}_x\"]\n",
    "            y_start = df.at[frame, f\"{joint_start}_y\"]\n",
    "            z_start = df.at[frame, f\"{joint_start}_z\"]\n",
    "            x_end = df.at[frame, f\"{joint_end}_x\"]\n",
    "            y_end = df.at[frame, f\"{joint_end}_y\"]\n",
    "            z_end = df.at[frame, f\"{joint_end}_z\"]\n",
    "            lines[connection].set_data([x_start, x_end], [y_start, y_end])\n",
    "            lines[connection].set_3d_properties([z_start, z_end])\n",
    "        \n",
    "        # Update ball position\n",
    "        ball_x = df.at[frame, \"ball_x\"]\n",
    "        ball_y = df.at[frame, \"ball_y\"]\n",
    "        ball_z = df.at[frame, \"ball_z\"]\n",
    "        ball.set_data([ball_x], [ball_y])\n",
    "        ball.set_3d_properties([ball_z])\n",
    "        \n",
    "        # Update text annotations\n",
    "        if frame == release_frame:\n",
    "            release_text.set_text(\"Release Point\")\n",
    "            release_text.set_color(highlight_color)\n",
    "        else:\n",
    "            release_text.set_text(\"\")\n",
    "        \n",
    "        if df.at[frame, \"shooting_motion\"] == 1:\n",
    "            motion_text.set_text(\"Shooting Motion\")\n",
    "        else:\n",
    "            motion_text.set_text(\"\")\n",
    "        \n",
    "        # NEW: Update joint markers if provided\n",
    "        if joint_markers is not None:\n",
    "            for joint, marker_line in joint_markers.items():\n",
    "                x_joint = df.at[frame, f\"{joint}_x\"]\n",
    "                y_joint = df.at[frame, f\"{joint}_y\"]\n",
    "                z_joint = df.at[frame, f\"{joint}_z\"]\n",
    "                marker_line.set_data([x_joint], [y_joint])\n",
    "                marker_line.set_3d_properties([z_joint])\n",
    "        \n",
    "        if debug:\n",
    "            logger.debug(f\"Updated frame {frame}: Player, ball, texts, and joint markers updated.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error updating frame {frame}: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def update_meter_with_mode(\n",
    "    ax_meter,\n",
    "    df,\n",
    "    frame,\n",
    "    needle,\n",
    "    one_liner,  # single text element for combined information\n",
    "    angle_key: str,\n",
    "    feedback_key: str,\n",
    "    feedback_mode: str = \"calculated\",\n",
    "    bayesian_metrics_dict: dict = None,\n",
    "    debug: bool = False,\n",
    "    conditional_max: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Update the polar angle meter based on the chosen feedback mode.\n",
    "    This version updates the dynamic text element (one_liner) and rotates the needle.\n",
    "    The gauge_fill wedge (red fill) is updated to span from 0° to the current angle.\n",
    "    \n",
    "    Efficiency improvements:\n",
    "      - Uses the global DEG_TO_RAD constant.\n",
    "      - Minimizes repeated conversions.\n",
    "      - Re-calls legend only on frame 0.\n",
    "    \n",
    "    Parameters:\n",
    "      - ax_meter: The polar axes.\n",
    "      - df: DataFrame with the current frame data.\n",
    "      - frame: The current frame index.\n",
    "      - needle: The dynamic needle line.\n",
    "      - one_liner: The text element for displaying combined information.\n",
    "      - angle_key: Column name for the ongoing angle.\n",
    "      - feedback_key: Key used to look up the metric.\n",
    "      - feedback_mode: \"calculated\", \"bayesian\", or \"shap\".\n",
    "      - bayesian_metrics_dict: Dictionary with metric info.\n",
    "      - debug: If True, print debug information.\n",
    "      - conditional_max: If True, apply conditional logic for max lines.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get the current angle (in degrees) and convert to radians using the precomputed constant.\n",
    "        current_angle_degs = df.loc[frame, angle_key]\n",
    "        rad = current_angle_degs * DEG_TO_RAD\n",
    "        # Update the needle to point at the current angle.\n",
    "        needle.set_data([rad, rad], [0, 0.8])\n",
    "        \n",
    "        # Update the gauge fill wedge so that its theta2 equals the current angle.\n",
    "        if hasattr(ax_meter, 'gauge_fill'):\n",
    "            ax_meter.gauge_fill.theta2 = current_angle_degs\n",
    "            if debug:\n",
    "                print(f\"Gauge fill updated: theta2 set to {current_angle_degs}°.\")\n",
    "        \n",
    "        # Build the info string for the one-liner text.\n",
    "        info = f\"Ongoing {angle_key}: {current_angle_degs:.1f}°\"\n",
    "        \n",
    "        # --- Feedback mode-specific logic (calculated, bayesian, shap) remains unchanged ---\n",
    "        if feedback_mode.lower() == \"calculated\":\n",
    "            if selected_metric := feedback_key:  # fallback to selected metric name\n",
    "                if selected_metric in df.columns:\n",
    "                    calc_min_col = f\"{feedback_key}_filtered_optimal_min\"\n",
    "                    calc_max_col = f\"{feedback_key}_filtered_optimal_max\"\n",
    "                    calc_min = df.loc[frame, calc_min_col] if calc_min_col in df.columns else np.nan\n",
    "                    calc_max = df.loc[frame, calc_max_col] if calc_max_col in df.columns else np.nan\n",
    "                    if debug:\n",
    "                        print(f\"Using fallback columns: {calc_min_col} and {calc_max_col}.\")\n",
    "            else:\n",
    "                raise ValueError(\"Selected metric not found in DataFrame.\")\n",
    "            \n",
    "            if not hasattr(ax_meter, 'calc_min_line'):\n",
    "                calc_min_rad = calc_min * DEG_TO_RAD\n",
    "                ax_meter.calc_min_line, = ax_meter.plot([0, calc_min_rad], [0, 1],\n",
    "                                                        color='blue', lw=2, linestyle='--',\n",
    "                                                        label=f\"{angle_key} Calc Min\")\n",
    "                if debug:\n",
    "                    print(f\"Created Calculated Min line at {calc_min:.1f}°.\")\n",
    "            else:\n",
    "                calc_min_rad = calc_min * DEG_TO_RAD\n",
    "                ax_meter.calc_min_line.set_data([0, calc_min_rad], [0, 1])\n",
    "                if debug:\n",
    "                    print(f\"Updated Calculated Min line to {calc_min:.1f}°.\")\n",
    "            if not hasattr(ax_meter, 'calc_max_line'):\n",
    "                calc_max_rad = calc_max * DEG_TO_RAD\n",
    "                if (not conditional_max) or (current_angle_degs >= calc_max):\n",
    "                    ax_meter.calc_max_line, = ax_meter.plot([0, calc_max_rad], [0, 1],\n",
    "                                                            color='green', lw=2, linestyle='--',\n",
    "                                                            label=f\"{angle_key} Calc Max\")\n",
    "                    if debug:\n",
    "                        print(f\"Created Calculated Max line at {calc_max:.1f}°.\")\n",
    "            else:\n",
    "                calc_max_rad = calc_max * DEG_TO_RAD\n",
    "                if (not conditional_max) or (current_angle_degs >= calc_max):\n",
    "                    ax_meter.calc_max_line.set_data([0, calc_max_rad], [0, 1])\n",
    "                    if debug:\n",
    "                        print(f\"Updated Calculated Max line to {calc_max:.1f}°.\")\n",
    "            \n",
    "            shot_class_col = f\"{feedback_key}_shot_classification\"\n",
    "            if shot_class_col in df.columns:\n",
    "                shot_classification = df.loc[frame, shot_class_col]\n",
    "                info += f\" | Shot Class: {shot_classification}\"\n",
    "            else:\n",
    "                info += \" | Shot Class: N/A\"\n",
    "        \n",
    "        elif feedback_mode.lower() == \"bayesian\":\n",
    "            bayes_min_col = f\"{feedback_key}_bayes_min\"\n",
    "            bayes_max_col = f\"{feedback_key}_bayes_max\"\n",
    "            bayes_class_col = f\"{feedback_key}_bayes_classification\"\n",
    "            if bayes_min_col in df.columns:\n",
    "                bayes_min = df.loc[frame, bayes_min_col]\n",
    "            else:\n",
    "                bayes_min = bayesian_metrics_dict.get(feedback_key.lower(), {}).get(\"bayes_min\", 0)\n",
    "            if bayes_max_col in df.columns:\n",
    "                bayes_max = df.loc[frame, bayes_max_col]\n",
    "            else:\n",
    "                bayes_max = bayesian_metrics_dict.get(feedback_key.lower(), {}).get(\"bayes_max\", 180)\n",
    "            if not hasattr(ax_meter, 'bayes_min_line'):\n",
    "                ax_meter.bayes_min_line, = ax_meter.plot(\n",
    "                    [0, bayes_min * DEG_TO_RAD], [0, 1],\n",
    "                    color='blue', lw=2, linestyle='--', label=f\"{angle_key} Bayes Min\"\n",
    "                )\n",
    "                if debug:\n",
    "                    print(f\"Created Bayes Min line at {bayes_min:.1f}°.\")\n",
    "            else:\n",
    "                ax_meter.bayes_min_line.set_data([0, bayes_min * DEG_TO_RAD], [0, 1])\n",
    "                if debug:\n",
    "                    print(f\"Updated Bayes Min line to {bayes_min:.1f}°.\")\n",
    "            if (not conditional_max) or (current_angle_degs >= bayes_max):\n",
    "                if not hasattr(ax_meter, 'bayes_max_line'):\n",
    "                    ax_meter.bayes_max_line, = ax_meter.plot(\n",
    "                        [0, bayes_max * DEG_TO_RAD], [0, 1],\n",
    "                        color='green', lw=2, linestyle='--', label=f\"{angle_key} Bayes Max\"\n",
    "                    )\n",
    "                    if debug:\n",
    "                        print(f\"Created Bayes Max line at {bayes_max:.1f}°.\")\n",
    "                else:\n",
    "                    ax_meter.bayes_max_line.set_data([0, bayes_max * DEG_TO_RAD], [0, 1])\n",
    "                    if debug:\n",
    "                        print(f\"Updated Bayes Max line to {bayes_max:.1f}°.\")\n",
    "            if bayes_class_col in df.columns:\n",
    "                bayes_classification = df.loc[frame, bayes_class_col]\n",
    "            else:\n",
    "                bayes_classification = bayesian_metrics_dict.get(feedback_key.lower(), {}).get(\"bayes_classification\", \"N/A\")\n",
    "            info += f\" | Bayes Class: {bayes_classification}\"\n",
    "        \n",
    "        elif feedback_mode.lower() == \"shap\":\n",
    "            selected_metric = feedback_key  # for consistency\n",
    "            shap_class_col = f\"shap_{selected_metric}_classification\"\n",
    "            shap_unit_change_col = f\"shap_{selected_metric}_unit_change\"\n",
    "            shap_unit_col = f\"shap_{selected_metric}_unit\"\n",
    "            shap_direction_col = f\"shap_{selected_metric}_direction\"\n",
    "            shap_imp_col = f\"shap_{selected_metric}_importance\"\n",
    "            shap_class = df.loc[frame, shap_class_col] if shap_class_col in df.columns else \"N/A\"\n",
    "            shap_unit_change = df.loc[frame, shap_unit_change_col] if shap_unit_change_col in df.columns else \"N/A\"\n",
    "            shap_unit = df.loc[frame, shap_unit_col] if shap_unit_col in df.columns else \"\"\n",
    "            shap_direction = df.loc[frame, shap_direction_col] if shap_direction_col in df.columns else \"N/A\"\n",
    "            if shap_imp_col in df.columns:\n",
    "                shap_imp = df.loc[frame, shap_imp_col]\n",
    "                try:\n",
    "                    shap_importance = f\"{float(shap_imp):.3f}\"\n",
    "                except (ValueError, TypeError):\n",
    "                    shap_importance = shap_imp\n",
    "            else:\n",
    "                shap_importance = \"N/A\"\n",
    "            shap_min_col = f\"shap_{selected_metric}_min\"\n",
    "            shap_max_col = f\"shap_{selected_metric}_max\"\n",
    "            if shap_min_col in df.columns:\n",
    "                shap_min = df.loc[frame, shap_min_col]\n",
    "            else:\n",
    "                shap_min = 0\n",
    "            if shap_max_col in df.columns:\n",
    "                shap_max = df.loc[frame, shap_max_col]\n",
    "            else:\n",
    "                shap_max = 180\n",
    "            shap_min_rad = shap_min * DEG_TO_RAD\n",
    "            shap_max_rad = shap_max * DEG_TO_RAD\n",
    "            if not hasattr(ax_meter, 'shap_min_line'):\n",
    "                ax_meter.shap_min_line, = ax_meter.plot(\n",
    "                    [0, shap_min_rad], [0, 1],\n",
    "                    color='blue', lw=2, linestyle='--', label=f\"{angle_key} SHAP Min\"\n",
    "                )\n",
    "            else:\n",
    "                ax_meter.shap_min_line.set_data([0, shap_min_rad], [0, 1])\n",
    "            if (not conditional_max) or (current_angle_degs >= shap_max):\n",
    "                if not hasattr(ax_meter, 'shap_max_line'):\n",
    "                    ax_meter.shap_max_line, = ax_meter.plot(\n",
    "                        [0, shap_max_rad], [0, 1],\n",
    "                        color='green', lw=2, linestyle='--', label=f\"{angle_key} SHAP Max\"\n",
    "                    )\n",
    "                else:\n",
    "                    ax_meter.shap_max_line.set_data([0, shap_max_rad], [0, 1])\n",
    "            one_liner_str = (f\"Ongoing {angle_key}: {df.loc[frame, angle_key]:.1f}° | \"\n",
    "                             f\"SHAP Class: {shap_class} |\\n \"\n",
    "                             f\"Direction: {shap_direction} | SHAP Imp: {shap_importance}\")\n",
    "        \n",
    "        else:\n",
    "            logger.warning(f\"Unknown feedback mode: {feedback_mode}\")\n",
    "            info += \" | Class: N/A | SHAP: N/A | Direction: N/A\"\n",
    "            if debug:\n",
    "                print(\"Set default one-liner info to N/A for unknown feedback mode.\")\n",
    "        \n",
    "        # Set the one-liner text based on the mode.\n",
    "        one_liner.set_text(info if feedback_mode.lower() != \"shap\" else one_liner_str)\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"Frame={frame}, feedback_mode='{feedback_mode}' => {one_liner.get_text()}\")\n",
    "        \n",
    "        # Re-call legend on frame 0 to include any new lines.\n",
    "        if frame == 0:\n",
    "            ax_meter.legend(loc='upper right')\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in update_meter_with_mode: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def initialize_bar_meter(ax_bar, min_val, max_val):\n",
    "    \"\"\"\n",
    "    Initializes a horizontal bar to represent the angle from min_val to max_val.\n",
    "    Returns the bar container so you can update it each frame.\n",
    "    \"\"\"\n",
    "    ax_bar.set_xlim([min_val, max_val])\n",
    "    ax_bar.set_ylim([-0.5, 0.5])  # Just enough space for a single bar\n",
    "    ax_bar.set_xlabel(\"Angle (degrees)\")\n",
    "    ax_bar.set_yticks([])\n",
    "\n",
    "    # Draw a single bar initially at zero\n",
    "    bar_container = ax_bar.barh(\n",
    "        y=0, width=0, height=0.4, color='red', align='center'\n",
    "    )\n",
    "\n",
    "    return bar_container\n",
    "\n",
    "def update_bar_meter(bar_container, current_angle, min_val=0, max_val=180):\n",
    "    \"\"\"\n",
    "    Updates the bar's width so that it visually represents the current_angle.\n",
    "    \"\"\"\n",
    "    # bar_container is usually a list with a single bar (bar_container[0])\n",
    "    bar = bar_container[0]\n",
    "    \n",
    "    # Constrain/clip angle if needed (optional).\n",
    "    clipped_angle = max(min_val, min(current_angle, max_val))\n",
    "    \n",
    "    # Update the bar width\n",
    "    bar.set_width(clipped_angle)\n",
    "\n",
    "\n",
    "\n",
    "def initialize_line_graph(\n",
    "    ax_line,\n",
    "    static_min: float,\n",
    "    static_max: float,\n",
    "    selected_metric_filter_name: str,\n",
    "    selected_metric: str,\n",
    "    feedback_mode: str,\n",
    "    debug=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Initialize the line graph subplot with dynamic metric tracking.\n",
    "    The dynamic (ongoing) metric line is drawn in red.\n",
    "    \n",
    "    CHANGES:\n",
    "      - The title now includes the metric name.\n",
    "      - The red ongoing line’s label is now set to the metric name in lowercase.\n",
    "      - Static min and max lines are labeled based on the chosen feedback mode.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ax_line.set_title(f\"Metric Over Time: {selected_metric}\", fontsize=14, pad=20)\n",
    "        ax_line.set_xlabel(\"Frame\", fontsize=12)\n",
    "        ax_line.set_ylabel(f\"{selected_metric} (degrees)\", fontsize=12)\n",
    "\n",
    "        # Dynamic (ongoing) metric line in red with a lowercase label\n",
    "        line_metric, = ax_line.plot([], [], lw=2, color='red',\n",
    "                                    label=f\"{selected_metric.lower()} Ongoing\")  # <--- CHANGED here!\n",
    "\n",
    "        # Determine labels for the static min/max lines based on feedback mode\n",
    "        if feedback_mode.lower() == \"shap\":\n",
    "            min_label = f\"{selected_metric} SHAP Min\"\n",
    "            max_label = f\"{selected_metric} SHAP Max\"\n",
    "        elif feedback_mode.lower() == \"calculated\":\n",
    "            min_label = f\"{selected_metric} Calc Min\"\n",
    "            max_label = f\"{selected_metric} Calc Max\"\n",
    "        else:  # bayesian or default\n",
    "            min_label = f\"{selected_metric} Bayes Min\"\n",
    "            max_label = f\"{selected_metric} Bayes Max\"\n",
    "\n",
    "        # Draw static min and max lines\n",
    "        line_min = ax_line.axhline(y=static_min, color='blue', linestyle='--', label=min_label)\n",
    "        line_max = ax_line.axhline(y=static_max, color='green', linestyle='--', label=max_label)\n",
    "\n",
    "        # Optional trial max line (initially invisible)\n",
    "        line_trial_max, = ax_line.plot([], [], lw=2, color='red', linestyle='--',\n",
    "                                       label=f\"{selected_metric} Trial Max\")\n",
    "        line_trial_max.set_visible(False)\n",
    "\n",
    "        data_frames = []\n",
    "        data_values = []\n",
    "\n",
    "        # Set initial y-limits with a small padding\n",
    "        initial_lower = static_min - 5\n",
    "        initial_upper = static_max + 5\n",
    "        ax_line.set_ylim(initial_lower, initial_upper)\n",
    "\n",
    "        # Create the legend\n",
    "        ax_line.legend(loc='upper right')\n",
    "\n",
    "        if debug:\n",
    "            logger.debug(\"Line graph initialized with dynamic metric tracking.\")\n",
    "\n",
    "        return {\n",
    "            'line_metric': line_metric,\n",
    "            'line_min': line_min,\n",
    "            'line_max': line_max,\n",
    "            'line_trial_max': line_trial_max,\n",
    "            'data_frames': data_frames,\n",
    "            'data_values': data_values,\n",
    "            'current_ymin': initial_lower,\n",
    "            'current_ymax': initial_upper,\n",
    "            'current_trial_max': static_max,\n",
    "            'trial_max_reached': False\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error initializing line graph: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def animate_trial_with_calc_bayes_shap_angle_meter(\n",
    "    df: pd.DataFrame,\n",
    "    release_frame: int,\n",
    "    selected_metric: str,\n",
    "    bayesian_metrics_dict: dict,\n",
    "    feedback_mode: str = \"bayesian\",\n",
    "    viewpoint_name: str = \"side_view_right\",\n",
    "    connections: list = None,\n",
    "    zlim: float = 15.0,\n",
    "    player_color: str = \"purple\",\n",
    "    player_lw: float = 2.0,\n",
    "    ball_color: str = \"#ee6730\",\n",
    "    ball_size: float = 10.0, \n",
    "    highlight_color: str = \"red\",\n",
    "    show_court: bool = True,\n",
    "    court_type: str = \"nba\",\n",
    "    units: str = \"ft\",\n",
    "    debug: bool = False,\n",
    "    frames_to_animate: list = None,\n",
    "    show_selected_metric: bool = False,  \n",
    "    polar_plot: bool = True,\n",
    "    bar_plot: bool = True,\n",
    "    line_plot: bool = True,\n",
    "    save_path: Optional[str] = None,\n",
    "    notebook_mode: bool = False,\n",
    "    figure_width: float = 6,\n",
    "    height_3d: float = 7.0,\n",
    "    height_polar: float = 5.0,\n",
    "    height_bar: float = 2.0,\n",
    "    height_line: float = 2.0,\n",
    "    space_3d_polar: float = 0.00001,    # vertical gap between 3D and polar\n",
    "    space_polar_bar: float = 0.00001,    # vertical gap between polar and bar\n",
    "    space_bar_line: float = 1.0,          # vertical gap between bar and line\n",
    "    # New camera control parameters\n",
    "    custom_elev: Optional[float] = None,\n",
    "    custom_azim: Optional[float] = None,\n",
    "    data_zoom: float = 1.0\n",
    ") -> HTML:\n",
    "    \"\"\"\n",
    "    Animate a basketball trial with integrated angle/line/polar/bar subplots.\n",
    "    \n",
    "    Additional efficiency improvements:\n",
    "      - Caches frequently accessed DataFrame columns as NumPy arrays.\n",
    "      - Precomputes frequently built column names and stores them in a dictionary.\n",
    "      - Uses local variable caching to reduce attribute lookups.\n",
    "      - Updates dynamic axis limits for the line graph only every 10 frames.\n",
    "      - Uses the global DEG_TO_RAD constant.\n",
    "    \n",
    "    New features:\n",
    "      - The ball size is now smaller.\n",
    "      - The created 3D axis is stored in a global variable (global_ax_3d) so that the viewpoint can be updated without reloading everything.\n",
    "      - Use the separate function change_viewpoint(new_elev, new_azim) to update the view.\n",
    "    \n",
    "    New: Independent vertical spacing between subplots.\n",
    "    \"\"\"\n",
    "    global global_ax_3d  # Declare the global variable so we can store the 3D axis.\n",
    "    try:\n",
    "        from IPython.display import HTML\n",
    "        import numpy as np\n",
    "        import matplotlib.pyplot as plt\n",
    "        from matplotlib.animation import FuncAnimation\n",
    "        from matplotlib.gridspec import GridSpec\n",
    "        from matplotlib.lines import Line2D\n",
    "        from matplotlib.patches import Wedge\n",
    "\n",
    "        if connections is None:\n",
    "            raise ValueError(\"connections list cannot be None.\")\n",
    "\n",
    "        if debug:\n",
    "            logger.debug(\"Starting animation setup.\")\n",
    "            logger.debug(f\"Total frames in df: {len(df)}; Release frame: {release_frame}\")\n",
    "            logger.debug(f\"Viewpoint: {viewpoint_name}, Metric: {selected_metric}\")\n",
    "\n",
    "        # Get viewpoint information.\n",
    "        # Modified viewpoint handling\n",
    "        if custom_elev is not None and custom_azim is not None:\n",
    "            elev, azim = custom_elev, custom_azim\n",
    "        else:\n",
    "            viewpoint = get_viewpoint(viewpoint_name)\n",
    "            elev, azim = viewpoint[\"elev\"], viewpoint[\"azim\"]\n",
    "\n",
    "        # Build height ratios for the figure layout.\n",
    "        height_ratios = [height_3d]\n",
    "        if polar_plot:\n",
    "            height_ratios += [space_3d_polar, height_polar]\n",
    "        if bar_plot:\n",
    "            gap_to_use = space_polar_bar if polar_plot else space_3d_polar\n",
    "            height_ratios += [gap_to_use, height_bar]\n",
    "        if line_plot:\n",
    "            gap_to_use = space_bar_line if bar_plot else (space_polar_bar if polar_plot else space_3d_polar)\n",
    "            height_ratios += [gap_to_use, height_line]\n",
    "        figure_height = sum(height_ratios)\n",
    "\n",
    "        # Create the figure.\n",
    "        fig = plt.figure(figsize=(figure_width, figure_height))\n",
    "        fig.tight_layout(pad=1.0, h_pad=1.0, w_pad=1.0, rect=[0, 0, 1, 1])\n",
    "        row_count = len(height_ratios)\n",
    "        gs = GridSpec(row_count, 1, figure=fig, height_ratios=height_ratios)\n",
    "\n",
    "        # Place subplots.\n",
    "        row_idx = 0\n",
    "        ax_3d = fig.add_subplot(gs[row_idx, 0], projection='3d')\n",
    "        ax_3d.view_init(elev=elev, azim=azim)\n",
    "        ax_3d.set_zlim([0, zlim])\n",
    "        ax_3d.set_box_aspect((2, 2, 1))\n",
    "        # Store the 3D axis in the global variable for dynamic viewpoint changes.\n",
    "        global_ax_3d = ax_3d\n",
    "\n",
    "        ax_meter = None\n",
    "        if polar_plot:\n",
    "            row_idx += 2\n",
    "            ax_meter = fig.add_subplot(gs[row_idx, 0], polar=True)\n",
    "\n",
    "        ax_bar = None\n",
    "        if bar_plot:\n",
    "            row_idx += 2\n",
    "            ax_bar = fig.add_subplot(gs[row_idx, 0])\n",
    "\n",
    "        ax_line = None\n",
    "        if line_plot:\n",
    "            row_idx += 2\n",
    "            ax_line = fig.add_subplot(gs[row_idx, 0])\n",
    "\n",
    "        # Draw the court.\n",
    "        if show_court:\n",
    "            draw_court(ax_3d, court_type=court_type, units=units, debug=debug)\n",
    "            _hoopx, _hoopy, _hoopz = get_hoop_position(court_type=court_type, units=units, debug=debug)\n",
    "\n",
    "        # NEW: After drawing the court, update axis limits using data_zoom.\n",
    "        # Get current limits (which may have been set by the court drawing)\n",
    "        x_min, x_max = ax_3d.get_xlim()\n",
    "        y_min, y_max = ax_3d.get_ylim()\n",
    "        # Apply zoom factor to x, y, and z limits.\n",
    "        ax_3d.set_xlim([x_min / data_zoom, x_max / data_zoom])\n",
    "        ax_3d.set_ylim([y_min / data_zoom, y_max / data_zoom])\n",
    "        ax_3d.set_zlim([0, zlim / data_zoom])\n",
    "        \n",
    "        # Initialize 3D elements.\n",
    "        lines, ball, release_text, motion_text, distance_text = initialize_bayes_elements(\n",
    "            ax=ax_3d,\n",
    "            connections=connections,\n",
    "            player_color=player_color,\n",
    "            player_lw=player_lw,\n",
    "            ball_color=ball_color,\n",
    "            ball_size=ball_size,\n",
    "            debug=debug\n",
    "        )\n",
    "\n",
    "        # Retrieve selected metric filter name.\n",
    "        metric_info = bayesian_metrics_dict.get(selected_metric)\n",
    "        if not metric_info:\n",
    "            raise ValueError(f\"Metric '{selected_metric}' not found in bayesian_metrics_dict.\")\n",
    "        selected_metric_filter_name = metric_info.get(\"filter_name\", selected_metric)\n",
    "\n",
    "        # Determine static min/max.\n",
    "        if feedback_mode.lower() == \"shap\":\n",
    "            shap_min_col = f\"shap_{selected_metric}_min\"\n",
    "            shap_max_col = f\"shap_{selected_metric}_max\"\n",
    "            static_min = df.at[0, shap_min_col] if shap_min_col in df.columns else 0\n",
    "            static_max = df.at[0, shap_max_col] if shap_max_col in df.columns else 180\n",
    "        elif feedback_mode.lower() == \"calculated\":\n",
    "            calc_min_col = f\"{selected_metric}_filtered_optimal_min\"\n",
    "            calc_max_col = f\"{selected_metric}_filtered_optimal_max\"\n",
    "            static_min = df.at[0, calc_min_col] if calc_min_col in df.columns else 0\n",
    "            static_max = df.at[0, calc_max_col] if calc_max_col in df.columns else 180\n",
    "        else:\n",
    "            static_min = metric_info.get(\"bayes_min\", 0)\n",
    "            static_max = metric_info.get(\"bayes_max\", 180)\n",
    "\n",
    "        # ---------- POLAR METER SETUP ----------\n",
    "        angle_meter_obj = None\n",
    "        if polar_plot and ax_meter is not None:\n",
    "            for deg in range(0, 181, 30):\n",
    "                deg_rad = np.deg2rad(deg)\n",
    "                ax_meter.plot([deg_rad, deg_rad], [0, 1],\n",
    "                              color='gray', linewidth=0.5, alpha=0.4, zorder=0)\n",
    "            if not hasattr(ax_meter, 'gauge_fill'):\n",
    "                ax_meter.gauge_fill = Wedge(center=(0, 0), r=1.0, theta1=0, theta2=0,\n",
    "                                            facecolor='red', alpha=0.3, transform=ax_meter.transData)\n",
    "                ax_meter.add_patch(ax_meter.gauge_fill)\n",
    "            needle, = ax_meter.plot([0, 0], [0, 0.8],\n",
    "                                    lw=3, color='red',\n",
    "                                    label=f\"{selected_metric.lower()} Ongoing\")\n",
    "            ax_meter.gauge_fill.set_zorder(1)\n",
    "            needle.set_zorder(2)\n",
    "            ax_meter.set_title(f\"Polar Angle Meter: {selected_metric}\", fontsize=14, pad=20)\n",
    "            one_liner = ax_meter.text(0.5, 0.25, \"\", transform=ax_meter.transAxes,\n",
    "                                      ha='center', va='center', fontsize=10, color='red', zorder=12)\n",
    "            ax_meter.set_theta_offset(np.pi)\n",
    "            ax_meter.set_theta_direction(-1)\n",
    "            angle_ticks = np.linspace(0, np.pi, 6)\n",
    "            angle_labels = [f'{int(deg)}°' for deg in np.linspace(0, 180, 6)]\n",
    "            ax_meter.set_xticks(angle_ticks)\n",
    "            ax_meter.set_xticklabels(angle_labels)\n",
    "            ax_meter.set_yticklabels([])\n",
    "            ax_meter.grid(False)\n",
    "            ax_meter.set_ylim(0, 1)\n",
    "            ax_meter.fill_between(np.linspace(np.pi, 2*np.pi, 100), 0, 1, color=\"white\", zorder=10)\n",
    "            ax_meter.spines['polar'].set_visible(False)\n",
    "            ax_meter.plot([0, np.pi], [0, 1], color='black', lw=1)\n",
    "            if show_selected_metric:\n",
    "                selected_value = df[selected_metric].iloc[0]\n",
    "                selected_value_rad = selected_value * DEG_TO_RAD\n",
    "                if not hasattr(ax_meter, 'selected_metric_line'):\n",
    "                    ax_meter.selected_metric_line, = ax_meter.plot(\n",
    "                        [0, selected_value_rad], [0, 1],\n",
    "                        color='black', lw=2, linestyle='-', label=f\"{selected_metric} Selected\"\n",
    "                    )\n",
    "            ax_meter.legend(loc='upper right')\n",
    "            angle_meter_obj = {'ax_meter': ax_meter, 'needle': needle, 'one_liner': one_liner}\n",
    "\n",
    "        # ---------- BAR METER SETUP ----------\n",
    "        bar_container = None\n",
    "        bar_ongoing_text = None\n",
    "        if bar_plot and ax_bar is not None:\n",
    "            ax_bar.set_title(f\"Bar Meter: {selected_metric}\", fontsize=14, pad=30)\n",
    "            bar_ongoing_text = ax_bar.text(0.5, 1.02, \"\", transform=ax_bar.transAxes,\n",
    "                                           ha='center', va='bottom', fontsize=10, color='red')\n",
    "            bar_container = initialize_bar_meter(ax_bar, min_val=0, max_val=180)\n",
    "            add_bayes_optimal_lines_to_bar(ax_bar, static_min, static_max, \n",
    "                                           selected_metric_filter_name, feedback_mode, debug)\n",
    "            bar_container[0].set_label(f\"{selected_metric.lower()} Ongoing\")\n",
    "            first_val = df[selected_metric].iloc[0]\n",
    "            if not hasattr(ax_bar, 'selected_metric_line'):\n",
    "                ax_bar.selected_metric_line = ax_bar.axvline(\n",
    "                    x=first_val, color='black', lw=2, linestyle='-',\n",
    "                    label=f\"{selected_metric} Selected\"\n",
    "                )\n",
    "            bar_handles = [bar_container[0]]\n",
    "            if hasattr(ax_bar, 'bar_min_line'):\n",
    "                bar_handles.append(ax_bar.bar_min_line)\n",
    "            if hasattr(ax_bar, 'bar_max_line'):\n",
    "                bar_handles.append(ax_bar.bar_max_line)\n",
    "            if hasattr(ax_bar, 'selected_metric_line'):\n",
    "                bar_handles.append(ax_bar.selected_metric_line)\n",
    "            ax_bar.legend(handles=bar_handles, loc='upper right')\n",
    "\n",
    "        # ---------- LINE GRAPH SETUP ----------\n",
    "        line_graph_obj = None\n",
    "        line_ongoing_text = None\n",
    "        if line_plot and ax_line is not None:\n",
    "            line_graph_obj = initialize_line_graph(ax_line, static_min, static_max,\n",
    "                                                   selected_metric_filter_name, selected_metric,\n",
    "                                                   feedback_mode, debug)\n",
    "            line_ongoing_text = ax_line.text(0.5, 1.02, \"\", transform=ax_line.transAxes,\n",
    "                                             ha='center', va='bottom', fontsize=10, color='red')\n",
    "            if show_selected_metric:\n",
    "                selected_value = df[selected_metric].iloc[0]\n",
    "                line_graph_obj['selected_metric_line'] = ax_line.axhline(\n",
    "                    y=selected_value, color='black', linestyle='-', lw=2, label=f\"{selected_metric_filter_name} Selected\"\n",
    "                )\n",
    "                line_handles = [\n",
    "                    line_graph_obj['line_min'],\n",
    "                    line_graph_obj['line_max'],\n",
    "                    line_graph_obj['line_metric'],\n",
    "                    line_graph_obj['selected_metric_line']\n",
    "                ]\n",
    "                ax_line.legend(handles=line_handles, loc='upper right')\n",
    "\n",
    "        # ---------- 3D Legend ----------\n",
    "        player_handle = Line2D([0], [0], color=player_color, lw=player_lw, label='Player')\n",
    "        ball_handle = Line2D([0], [0], marker='o', color='w', markerfacecolor=ball_color, label='Ball')\n",
    "        ax_3d.legend(handles=[player_handle, ball_handle], loc='upper right')\n",
    "\n",
    "        if release_frame < 0 or release_frame >= len(df):\n",
    "            release_frame = 0\n",
    "        if debug:\n",
    "            logger.debug(f\"Final release_frame used: {release_frame}\")\n",
    "\n",
    "        if 'release_point_filter' in df.columns and release_frame < len(df):\n",
    "            trial_release = (\n",
    "                df.loc[release_frame, selected_metric_filter_name] \n",
    "                if df.loc[release_frame, 'release_point_filter'] == 1 else None\n",
    "            )\n",
    "        else:\n",
    "            trial_release = None\n",
    "\n",
    "        # ---------- Cache Frequently Accessed Data ----------\n",
    "        selected_metric_values = df[selected_metric_filter_name].to_numpy()\n",
    "        distance_to_basket = df['distance_to_basket'].to_numpy() if 'distance_to_basket' in df.columns else None\n",
    "        shooting_motion = df['shooting_motion'].to_numpy() if 'shooting_motion' in df.columns else None\n",
    "\n",
    "        # Precompute frequently built column names.\n",
    "        col_names = {}\n",
    "        if feedback_mode.lower() == \"bayesian\":\n",
    "            col_names[\"bayes_min\"] = f\"{selected_metric}_bayes_min\"\n",
    "            col_names[\"bayes_max\"] = f\"{selected_metric}_bayes_max\"\n",
    "            col_names[\"bayes_class\"] = f\"{selected_metric}_bayes_classification\"\n",
    "            col_names[\"bayes_unit\"] = f\"{selected_metric}_bayes_unit_change\"\n",
    "        elif feedback_mode.lower() == \"shap\":\n",
    "            col_names[\"shap_class\"] = f\"shap_{selected_metric}_classification\"\n",
    "            col_names[\"shap_unit\"] = f\"shap_{selected_metric}_unit_change\"\n",
    "            col_names[\"shap_direction\"] = f\"shap_{selected_metric}_direction\"\n",
    "            col_names[\"shap_imp\"] = f\"shap_{selected_metric}_importance\"\n",
    "        elif feedback_mode.lower() == \"calculated\":\n",
    "            col_names[\"shot_class\"] = f\"{selected_metric}_shot_classification\"\n",
    "\n",
    "        # ---------- Update Function ----------\n",
    "        def update_func(frame: int):\n",
    "            # Use local variables for axes.\n",
    "            local_ax_line = ax_line\n",
    "\n",
    "            # Update 3D elements.\n",
    "            update_bayes_frame(\n",
    "                ax=ax_3d,\n",
    "                frame=frame,\n",
    "                df=df,\n",
    "                release_frame=release_frame,\n",
    "                lines=lines,\n",
    "                ball=ball,\n",
    "                release_text=release_text,\n",
    "                motion_text=motion_text,\n",
    "                connections=connections,\n",
    "                ball_color=ball_color,\n",
    "                highlight_color=highlight_color,\n",
    "                debug=debug,\n",
    "                selected_metric=selected_metric,\n",
    "                selected_metric_filter_name=selected_metric_filter_name\n",
    "            )\n",
    "            # Update polar meter.\n",
    "            if polar_plot and angle_meter_obj is not None:\n",
    "                update_meter_with_mode(\n",
    "                    ax_meter=angle_meter_obj['ax_meter'],\n",
    "                    df=df,\n",
    "                    frame=frame,\n",
    "                    needle=angle_meter_obj['needle'],\n",
    "                    one_liner=angle_meter_obj['one_liner'],\n",
    "                    angle_key=selected_metric_filter_name,\n",
    "                    feedback_key=selected_metric,\n",
    "                    feedback_mode=feedback_mode,\n",
    "                    bayesian_metrics_dict=bayesian_metrics_dict,\n",
    "                    debug=debug\n",
    "                )\n",
    "            # Update bar meter.\n",
    "            current_val = selected_metric_values[frame]\n",
    "            if bar_container is not None:\n",
    "                update_bar_meter(bar_container, current_angle=current_val, min_val=0, max_val=180)\n",
    "\n",
    "            # Update one-liner text based on feedback mode.\n",
    "            if feedback_mode.lower() == \"bayesian\":\n",
    "                bayes_class = df.loc[frame, col_names.get(\"bayes_class\", \"N/A\")] if col_names.get(\"bayes_class\") in df.columns else \"N/A\"\n",
    "                bayes_unit = df.loc[frame, col_names.get(\"bayes_unit\", \"N/A\")] if col_names.get(\"bayes_unit\") in df.columns else \"N/A\"\n",
    "                one_liner_str = (f\"Ongoing {selected_metric_filter_name}: {current_val:.1f}° | \"\n",
    "                                 f\"Bayes Class: {bayes_class} | Unit Change: {bayes_unit}\")\n",
    "            elif feedback_mode.lower() == \"shap\":\n",
    "                shap_class = df.loc[frame, col_names.get(\"shap_class\", \"N/A\")] if col_names.get(\"shap_class\") in df.columns else \"N/A\"\n",
    "                shap_unit = df.loc[frame, col_names.get(\"shap_unit\", \"N/A\")] if col_names.get(\"shap_unit\") in df.columns else \"\"\n",
    "                shap_direction = df.loc[frame, col_names.get(\"shap_direction\", \"N/A\")] if col_names.get(\"shap_direction\") in df.columns else \"N/A\"\n",
    "                if col_names.get(\"shap_imp\") in df.columns:\n",
    "                    shap_imp = df.loc[frame, col_names.get(\"shap_imp\")]\n",
    "                    try:\n",
    "                        shap_importance = f\"{float(shap_imp):.3f}\"\n",
    "                    except:\n",
    "                        shap_importance = shap_imp\n",
    "                else:\n",
    "                    shap_importance = \"N/A\"\n",
    "                one_liner_str = (\n",
    "                    f\"Ongoing {selected_metric_filter_name}: {current_val:.1f}° | \"\n",
    "                    f\"SHAP Class: {shap_class} | Direction: {shap_direction} | SHAP Imp: {shap_importance}\"\n",
    "                )\n",
    "            elif feedback_mode.lower() == \"calculated\":\n",
    "                shot_class = df.loc[frame, col_names.get(\"shot_class\", \"N/A\")] if col_names.get(\"shot_class\") in df.columns else \"N/A\"\n",
    "                one_liner_str = (f\"Ongoing {selected_metric_filter_name}: {current_val:.1f}° | \"\n",
    "                                 f\"Shot Class: {shot_class}\")\n",
    "            else:\n",
    "                one_liner_str = f\"Ongoing {selected_metric_filter_name}: {current_val:.1f}°\"\n",
    "\n",
    "            if bar_ongoing_text:\n",
    "                bar_ongoing_text.set_text(one_liner_str)\n",
    "\n",
    "            if distance_to_basket is not None:\n",
    "                dist = distance_to_basket[frame]\n",
    "                distance_text.set_text(f\"Distance to Basket: {dist:.2f} ft\" if not np.isnan(dist) else \"\")\n",
    "            else:\n",
    "                distance_text.set_text(\"\")\n",
    "\n",
    "            # Update the line graph; update y-axis limits only every 10 frames.\n",
    "            if line_graph_obj is not None:\n",
    "                frame_num = frame\n",
    "                line_graph_obj['data_frames'].append(frame_num)\n",
    "                line_graph_obj['data_values'].append(current_val)\n",
    "                line_graph_obj['line_metric'].set_data(line_graph_obj['data_frames'],\n",
    "                                                       line_graph_obj['data_values'])\n",
    "                local_ax_line.set_xlim(left=0, right=max(line_graph_obj['data_frames']) + 1)\n",
    "                if frame % 10 == 0:\n",
    "                    cmin = min(line_graph_obj['data_values']) - 5\n",
    "                    cmax = max(line_graph_obj['data_values']) + 5\n",
    "                    if cmin < line_graph_obj['current_ymin'] or cmax > line_graph_obj['current_ymax']:\n",
    "                        local_ax_line.set_ylim(cmin, cmax)\n",
    "                        line_graph_obj['current_ymin'] = cmin\n",
    "                        line_graph_obj['current_ymax'] = cmax\n",
    "\n",
    "                if \"max_\" in selected_metric:\n",
    "                    if current_val > line_graph_obj['current_trial_max']:\n",
    "                        line_graph_obj['current_trial_max'] = current_val\n",
    "                        if not hasattr(line_graph_obj['line_trial_max'], 'xdata'):\n",
    "                            line_graph_obj['line_trial_max'].set_data([frame_num], [current_val])\n",
    "                        else:\n",
    "                            oldx = line_graph_obj['line_trial_max'].get_xdata()\n",
    "                            oldy = line_graph_obj['line_trial_max'].get_ydata()\n",
    "                            new_x = np.append(oldx, frame_num)\n",
    "                            new_y = np.append(oldy, current_val)\n",
    "                            line_graph_obj['line_trial_max'].set_data(new_x, new_y)\n",
    "                        line_graph_obj['line_trial_max'].set_visible(True)\n",
    "                else:\n",
    "                    line_graph_obj['line_trial_max'].set_visible(False)\n",
    "\n",
    "                if trial_release is not None and frame >= release_frame:\n",
    "                    if \"release_\" in selected_metric and 'trial_release_line' in line_graph_obj:\n",
    "                        line_graph_obj['trial_release_line'].set_visible(True)\n",
    "\n",
    "                if line_ongoing_text:\n",
    "                    line_ongoing_text.set_text(one_liner_str)\n",
    "\n",
    "            fig.canvas.draw_idle()\n",
    "\n",
    "        # Build the animation.\n",
    "        frames_iter = frames_to_animate if frames_to_animate else range(len(df))\n",
    "        # Optionally, try blit=True if supported.\n",
    "        anim = FuncAnimation(fig, update_func, frames=frames_iter, interval=1000/30, blit=False)\n",
    "        inline_html = anim.to_jshtml() or \"<p>Error: No animation output generated.</p>\"\n",
    "        wrapped_html = f\"\"\"<div style=\"width: 100%; margin: 0; padding: 0;\">{inline_html}</div>\"\"\"\n",
    "\n",
    "        if save_path is not None:\n",
    "            if save_path.endswith(\".html\"):\n",
    "                with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(wrapped_html)\n",
    "            elif save_path.endswith(\".gif\"):\n",
    "                anim.save(save_path, writer='pillow')\n",
    "            elif save_path.endswith(\".mp4\"):\n",
    "                anim.save(save_path, writer='ffmpeg')\n",
    "\n",
    "        if notebook_mode:\n",
    "            return HTML(wrapped_html)\n",
    "        else:\n",
    "            return wrapped_html\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in animate_trial_with_calc_bayes_shap_angle_meter: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# %matplotlib notebook\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def display_combined_output(feedback_table, animation_html, feedback_mode):\n",
    "    \"\"\"\n",
    "    Displays the feedback table and animation side by side.\n",
    "\n",
    "    Parameters:\n",
    "        feedback_table (pd.DataFrame): The feedback metrics table.\n",
    "        animation_html (IPython.display.HTML): The animation HTML object.\n",
    "        feedback_mode (str): The current feedback mode for labeling purposes.\n",
    "    \"\"\"\n",
    "    # Convert Feedback Table to HTML\n",
    "    feedback_table_html = feedback_table.to_html(index=False)\n",
    "\n",
    "    # Create an HTML layout to display both the table and the animation side by side\n",
    "    combined_html = f\"\"\"\n",
    "    <div style=\"display: flex; justify-content: space-between;\">\n",
    "        <div style=\"width: 50%;\">\n",
    "            <h3>Feedback Table ({feedback_mode.capitalize()} Mode)</h3>\n",
    "            {feedback_table_html}\n",
    "        </div>\n",
    "        <div style=\"width: 45%;\">\n",
    "            <h3>Animation</h3>\n",
    "            {animation_html.data}\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "    # Display the combined layout\n",
    "    display(HTML(combined_html))\n",
    "\n",
    "\n",
    "def run_shot_meter_animation(\n",
    "    bayesian_metrics_json_path: str,\n",
    "    merged_data_path: str,\n",
    "    trial_id: str,\n",
    "    selected_metric: str,\n",
    "    feedback_mode: str = \"bayesian\",\n",
    "    viewpoint_name: str = \"diagonal_player_centric\",\n",
    "    connections: list = [\n",
    "        (\"R_EYE\", \"L_EYE\"), (\"R_EYE\", \"NOSE\"), (\"L_EYE\", \"NOSE\"),\n",
    "        (\"R_EYE\", \"R_EAR\"), (\"L_EYE\", \"L_EAR\"), (\"R_SHOULDER\", \"L_SHOULDER\"),\n",
    "        (\"R_SHOULDER\", \"R_ELBOW\"), (\"L_SHOULDER\", \"L_ELBOW\"), (\"R_ELBOW\", \"R_WRIST\"),\n",
    "        (\"L_ELBOW\", \"L_WRIST\"), (\"R_SHOULDER\", \"R_HIP\"), (\"L_SHOULDER\", \"L_HIP\"),\n",
    "        (\"R_HIP\", \"L_HIP\"), (\"R_HIP\", \"R_KNEE\"), (\"L_HIP\", \"L_KNEE\"),\n",
    "        (\"R_KNEE\", \"R_ANKLE\"), (\"L_KNEE\", \"L_ANKLE\"), (\"R_WRIST\", \"R_1STFINGER\"),\n",
    "        (\"R_WRIST\", \"R_5THFINGER\"), (\"L_WRIST\", \"L_1STFINGER\"), (\"L_WRIST\", \"L_5THFINGER\"),\n",
    "        (\"R_ANKLE\", \"R_1STTOE\"), (\"R_ANKLE\", \"R_5THTOE\"), (\"L_ANKLE\", \"L_1STTOE\"),\n",
    "        (\"L_ANKLE\", \"L_5THTOE\"), (\"R_ANKLE\", \"R_CALC\"), (\"L_ANKLE\", \"L_CALC\"),\n",
    "        (\"R_1STTOE\", \"R_5THTOE\"), (\"L_1STTOE\", \"L_5THTOE\"), (\"R_1STTOE\", \"R_CALC\"),\n",
    "        (\"L_1STTOE\", \"L_CALC\"), (\"R_5THTOE\", \"R_CALC\"), (\"L_5THTOE\", \"L_CALC\"),\n",
    "        (\"R_1STFINGER\", \"R_5THFINGER\"), (\"L_1STFINGER\", \"L_5THFINGER\")\n",
    "    ],\n",
    "    debug: bool = False,\n",
    "    frames_to_animate: list = None,\n",
    "    show_selected_metric: bool = False,\n",
    "    polar_plot: bool = True,\n",
    "    bar_plot: bool = True,\n",
    "    line_plot: bool = True,\n",
    "    bayesian_range_percentile: int = 10,\n",
    "    calculated_range_percentile: int = 10,\n",
    "    shap_range_percentile: int = 10,\n",
    "    update_percentiles: bool = False,\n",
    "    config: Optional[\"AppConfig\"] = None,\n",
    "    separate_display: bool = True,\n",
    "    save_path: Optional[str] = None,\n",
    "    # NEW: Pass notebook_mode so the pipeline can call the animation function appropriately.\n",
    "    notebook_mode: bool = False,\n",
    "    streamlit_app_paths: bool = False,\n",
    "    # Add new parameters at end:\n",
    "    elev: Optional[float] = None,\n",
    "    azim: Optional[float] = None,\n",
    "    data_zoom: float = 1.0\n",
    "):\n",
    "    import os\n",
    "    try:\n",
    "        if (bayesian_range_percentile != 10 or calculated_range_percentile != 10 or shap_range_percentile != 10):\n",
    "            update_percentiles = True\n",
    "            if debug:\n",
    "                print(\"Percentile values changed. Triggering update.\")\n",
    "        if streamlit_app_paths:\n",
    "            bayesian_metrics_file_path=\"data/predictions/bayesian_optimization_results/bayesian_optimization_results.csv\"\n",
    "            final_ml_file_path=\"data/processed/final_ml_dataset.csv\"\n",
    "            final_ml_with_predictions_path=\"data/predictions/shap_results/final_predictions_with_shap.csv\"\n",
    "            pickle_path=\"data/preprocessor/features_info/final_ml_df_selected_features_columns.pkl\"\n",
    "        else:\n",
    "            bayesian_metrics_file_path=\"../../data/predictions/bayesian_optimization_results/bayesian_optimization_results.csv\"\n",
    "            final_ml_file_path=\"../../data/processed/final_ml_dataset.csv\"\n",
    "            final_ml_with_predictions_path=\"../../data/predictions/shap_results/final_predictions_with_shap.csv\"\n",
    "            pickle_path=\"../../data/preprocessor/features_info/final_ml_df_selected_features_columns.pkl\"\n",
    "            \n",
    "        if update_percentiles:\n",
    "            if config is None:\n",
    "                raise ValueError(\"A valid AppConfig must be provided when updating percentiles.\")\n",
    "            merged_data, bayesian_metrics_dict, classification_summary = automated_bayes_shap_summary(\n",
    "                granular_data_path=merged_data_path,\n",
    "                release_angles_output_dir=os.path.dirname(merged_data_path),\n",
    "                max_angles_output_dir=os.path.dirname(merged_data_path),\n",
    "                bayesian_metrics_file_path=bayesian_metrics_file_path,\n",
    "                final_ml_file_path=final_ml_file_path,\n",
    "                final_ml_with_predictions_path=final_ml_with_predictions_path,\n",
    "                pickle_path=pickle_path,\n",
    "                y_variable=\"result\",\n",
    "                bayes_min_max_range_percentile=bayesian_range_percentile,\n",
    "                calc_feedback_range_percentile=calculated_range_percentile,\n",
    "                output_dir=os.path.dirname(merged_data_path),\n",
    "                output_filename=\"bayesian_shot_meter_granular_dataset.csv\",\n",
    "                debug=debug,\n",
    "                reload_shap_data=True,\n",
    "                new_shap_min_max_percentile=shap_range_percentile,\n",
    "                config=config,\n",
    "                streamlit_app_paths=streamlit_app_paths\n",
    "            )\n",
    "        else:\n",
    "            merged_data = pd.read_csv(merged_data_path)\n",
    "            bayesian_metrics_dict = load_bayesian_metrics_dict(json_path=bayesian_metrics_json_path, debug=debug)\n",
    "\n",
    "        trial_data = merged_data[merged_data['trial_id'] == trial_id].sort_values(by='frame_time').reset_index(drop=True)\n",
    "        print(\"DEBUG: trial_data.shape =\", trial_data.shape)\n",
    "        print(\"DEBUG: columns in trial_data =\", trial_data.columns.tolist())\n",
    "\n",
    "        if trial_data.empty:\n",
    "            raise ValueError(f\"No data found for trial_id {trial_id}.\")\n",
    "        # After processing merged data and trial data:\n",
    "        if debug:\n",
    "            print(f\"[run_shot_meter_animation] Trial data for {trial_id} contains {len(trial_data)} frames (shape {trial_data.shape}).\")\n",
    "        \n",
    "        metric_info = bayesian_metrics_dict.get(selected_metric)\n",
    "        if not metric_info:\n",
    "            raise ValueError(f\"Selected metric '{selected_metric}' not found in bayesian_metrics_dict.\")\n",
    "        selected_metric_filter_name = metric_info.get('filter_name', selected_metric)\n",
    "        if debug:\n",
    "            print(f\"[run_shot_meter_animation] Selected metric filter name: {selected_metric_filter_name}\")\n",
    "        \n",
    "        release_frames = trial_data.index[trial_data[\"release_point_filter\"] == 1].tolist()\n",
    "        release_frame = release_frames[0] if release_frames else None\n",
    "        if debug:\n",
    "            print(f\"[run_shot_meter_animation] Release frame for trial {trial_id} is {release_frame}.\")\n",
    "        \n",
    "        shooting_frames = trial_data[trial_data['shooting_motion'] == 1].index.tolist()\n",
    "        if release_frame is not None and release_frame not in shooting_frames:\n",
    "            shooting_frames.append(release_frame)\n",
    "            if debug:\n",
    "                print(f\"[run_shot_meter_animation] Added release_frame {release_frame} to shooting_frames.\")\n",
    "        if debug:\n",
    "            print(f\"[run_shot_meter_animation] Animating {len(shooting_frames)} frames.\")\n",
    "        \n",
    "        # --- NEW: Generate and validate the feedback table ---\n",
    "        feedback_table = generate_feedback_table_all_metrics(feedback_mode, bayesian_metrics_dict, trial_data, debug=debug)\n",
    "        feedback_table = pd.DataFrame(feedback_table)\n",
    "        print(\"feedback_table shape: %s\",feedback_table.shape)\n",
    "        print(\"feedback_table is type  %s\",type(feedback_table))\n",
    "        \n",
    "        # Pass notebook_mode to the animation function\n",
    "        animation_html = animate_trial_with_calc_bayes_shap_angle_meter(\n",
    "            df=trial_data,\n",
    "            release_frame=release_frame,\n",
    "            selected_metric=selected_metric,\n",
    "            bayesian_metrics_dict=bayesian_metrics_dict,\n",
    "            feedback_mode=feedback_mode,\n",
    "            viewpoint_name=viewpoint_name,\n",
    "            connections=connections,\n",
    "            debug=debug,\n",
    "            frames_to_animate=shooting_frames,\n",
    "            show_selected_metric=show_selected_metric,\n",
    "            polar_plot=polar_plot,\n",
    "            bar_plot=bar_plot,\n",
    "            line_plot=line_plot,\n",
    "            save_path=save_path,\n",
    "            notebook_mode=notebook_mode,\n",
    "            custom_elev=elev,\n",
    "            custom_azim=azim,\n",
    "            data_zoom=data_zoom,\n",
    "        )\n",
    "        \n",
    "        if separate_display:\n",
    "            display_separate_outputs(feedback_table, animation_html, feedback_mode)\n",
    "        else:\n",
    "            display_combined_output(feedback_table, animation_html, feedback_mode)\n",
    "            \n",
    "        if not debug:\n",
    "            print(\"Shot meter animation completed successfully.\")\n",
    "        \n",
    "        # Return the animation output (HTML object in notebook mode or raw string in Streamlit)\n",
    "        return animation_html, feedback_table\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"[run_shot_meter_animation] Error: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def initialize_bar_meter(ax_bar, min_val, max_val):\n",
    "    \"\"\"\n",
    "    Initialize a horizontal bar for the bar meter.\n",
    "    \"\"\"\n",
    "    ax_bar.set_xlim([min_val, max_val])\n",
    "    ax_bar.set_ylim([-0.5, 0.5])\n",
    "    ax_bar.set_xlabel(\"Angle (degrees)\")\n",
    "    ax_bar.set_yticks([])\n",
    "    bar_container = ax_bar.barh(y=0, width=0, height=0.4, color='red', align='center')\n",
    "    return bar_container\n",
    "\n",
    "def update_bar_meter(bar_container, current_angle, min_val=0, max_val=180):\n",
    "    \"\"\"\n",
    "    Update the bar meter width based on the current angle.\n",
    "    \"\"\"\n",
    "    bar = bar_container[0]\n",
    "    clipped_angle = max(min_val, min(current_angle, max_val))\n",
    "    bar.set_width(clipped_angle)\n",
    "\n",
    "def initialize_line_graph(ax_line, static_min: float, static_max: float,\n",
    "                          selected_metric_filter_name: str, selected_metric: str,\n",
    "                          feedback_mode: str, debug=False):\n",
    "    \"\"\"\n",
    "    Initialize the line graph subplot with dynamic metric tracking.\n",
    "    static_min and static_max are used for the static min/max lines.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ax_line.set_title(f\"Metric Over Time: {selected_metric}\", fontsize=14, pad=30)\n",
    "        ax_line.set_xlabel(\"Frame\", fontsize=12)\n",
    "        ax_line.set_ylabel(f\"{selected_metric} (degrees)\", fontsize=12)\n",
    "\n",
    "        line_metric, = ax_line.plot([], [], lw=2, color='red',\n",
    "                                    label=f\"{selected_metric_filter_name} Ongoing\")\n",
    "        if feedback_mode.lower() == \"shap\":\n",
    "            min_label = f\"{selected_metric} SHAP Min\"\n",
    "            max_label = f\"{selected_metric} SHAP Max\"\n",
    "        elif feedback_mode.lower() == \"calculated\":\n",
    "            min_label = f\"{selected_metric} Calc Min\"\n",
    "            max_label = f\"{selected_metric} Calc Max\"\n",
    "        else:\n",
    "            min_label = f\"{selected_metric} Bayes Min\"\n",
    "            max_label = f\"{selected_metric} Bayes Max\"\n",
    "\n",
    "        line_min = ax_line.axhline(y=static_min, color='blue', linestyle='--', label=min_label)\n",
    "        line_max = ax_line.axhline(y=static_max, color='green', linestyle='--', label=max_label)\n",
    "\n",
    "        line_trial_max, = ax_line.plot([], [], lw=2, color='red', linestyle='--',\n",
    "                                       label=f\"{selected_metric} Selected\")\n",
    "        line_trial_max.set_visible(False)\n",
    "\n",
    "        data_frames = []\n",
    "        data_values = []\n",
    "\n",
    "        initial_lower = static_min - 5\n",
    "        initial_upper = static_max + 5\n",
    "        ax_line.set_ylim(initial_lower, initial_upper)\n",
    "        ax_line.legend(loc='upper right')\n",
    "\n",
    "        if debug:\n",
    "            logger.debug(\"Line graph initialized with dynamic metric tracking.\")\n",
    "\n",
    "        return {\n",
    "            'line_metric': line_metric,\n",
    "            'line_min': line_min,\n",
    "            'line_max': line_max,\n",
    "            'line_trial_max': line_trial_max,\n",
    "            'data_frames': data_frames,\n",
    "            'data_values': data_values,\n",
    "            'current_ymin': initial_lower,\n",
    "            'current_ymax': initial_upper,\n",
    "            'current_trial_max': static_max,\n",
    "            'trial_max_reached': False\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error initializing line graph: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "    # # Feedback mode = shap: use shap_{selected_metric}_min, shap_{selected_metric}_max, and the {selected_metric} for lines on the graph. \n",
    "    # # Feedback mode = bayesian: use {selected_metric}_bayes_min, {selected_metric}_bayes_max, and the {selected_metric} for lines on the graph. \n",
    "    # # Feedback mode = calculated: use {selected_metric}_optimal_min, {selected_metric}_optimal_max, and the {selected_metric} for lines on the graph. \n",
    "\n",
    "    # # shap feedback mode:\n",
    "    # #     shap_{selected_metric}_unit_change\n",
    "    # #     shap_{selected_metric}_unit\n",
    "    # #     shap_{selected_metric}_direction\n",
    "    # #     shap_{selected_metric}_importance\n",
    "    # #     shap_{selected_metric}_goal\n",
    "    # #     shap_{selected_metric}_min\n",
    "    # #     shap_{selected_metric}_max\n",
    "    # #     shap_{selected_metric}_classification\n",
    "    # # calculated feedback mode:\n",
    "    # #     {selected_metric}_filtered_optimal_min\n",
    "    # #     {selected_metric}_filtered_optimal_max\n",
    "    # #     {selected_metric}_shot_classification\n",
    "    # # bayesian feedback mode:\n",
    "    # #     {selected_metric}_bayes_min\n",
    "    # #     {selected_metric}_bayes_max\n",
    "    # #     {selected_metric}_bayes_optimized\n",
    "    # #     {selected_metric}_bayes_classification\n",
    "    # #     {selected_metric}__bayes_unit_change  \n",
    "    # # **Select Feedback Mode**\n",
    "    # feedback_mode = \"shap\"  # Options: 'bayesian', 'shap', 'calculated'\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # # **Display the Feedback Table and Animation Together**\n",
    "    # display_combined_output(feedback_table, animation_html, feedback_mode)\n",
    "    config_path = Path('../../data/model/preprocessor_config/preprocessor_config.yaml')\n",
    "    try:\n",
    "        config: AppConfig = load_config(config_path)\n",
    "        print(f\"Configuration loaded successfully from {config_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to load configuration: {e}\")\n",
    "        exit(1)\n",
    "        \n",
    "    bayesian_metrics_json_path = \"../../data/model/shot_meter_docs/bayesian_metrics_dict.json\"\n",
    "    merged_data_path = \"../../data/processed/final_granular_dataset.csv\"\n",
    "    selected_trial_id = \"T0001\"\n",
    "    selected_metric = \"R_ELBOW_max_angle\"\n",
    "    \n",
    "    # Define connections for the player skeleton (example list)\n",
    "\n",
    "    elev = 30\n",
    "    azim = 45\n",
    "    data_zoom = 1.0\n",
    "    _ , feedback_table = run_shot_meter_animation(\n",
    "        bayesian_metrics_json_path=bayesian_metrics_json_path,\n",
    "        merged_data_path=merged_data_path,  # changed here\n",
    "        trial_id=\"T0001\",\n",
    "        selected_metric=\"R_ELBOW_max_angle\",\n",
    "        feedback_mode=\"shap\", # bayesian, calculated, shap\n",
    "        viewpoint_name=\"diagonal_player_centric\",\n",
    "        debug=True,\n",
    "        polar_plot=True,\n",
    "        bar_plot=True,\n",
    "        line_plot=True,\n",
    "        bayesian_range_percentile=10,\n",
    "        calculated_range_percentile=10,\n",
    "        shap_range_percentile=10,\n",
    "        update_percentiles=True,\n",
    "        save_path=None,\n",
    "        config=config,\n",
    "        streamlit_app_paths=False,\n",
    "        notebook_mode=True,\n",
    "        show_selected_metric=True,\n",
    "        # Existing arguments...\n",
    "        elev=elev,\n",
    "        azim=azim,\n",
    "        data_zoom=data_zoom,\n",
    "    )\n",
    "    print(\"Feedback TABLE ===============\", feedback_table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
